{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference trên Benchmark Dataset với Fine-tuned Model\n",
    "\n",
    "Notebook này chạy inference trên benchmark dataset sử dụng model đã fine-tune.\n",
    "Pipeline sử dụng fine-tuned model ở giai đoạn answering.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Cài đặt thư viện"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2026-01-03T15:31:23.268603Z",
     "iopub.status.busy": "2026-01-03T15:31:23.268470Z",
     "iopub.status.idle": "2026-01-03T15:31:33.974711Z",
     "shell.execute_reply": "2026-01-03T15:31:33.974219Z",
     "shell.execute_reply.started": "2026-01-03T15:31:23.268588Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.1/59.1 MB\u001b[0m \u001b[31m41.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.3/8.3 MB\u001b[0m \u001b[31m110.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m978.4/978.4 kB\u001b[0m \u001b[31m61.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m40.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.5/40.5 MB\u001b[0m \u001b[31m55.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Building wheel for wikipedia (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q transformers accelerate bitsandbytes qwen-vl-utils sentence-transformers rank-bm25 underthesea wikipedia pillow pandas tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Copy source code vào working directory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-03T15:31:33.975593Z",
     "iopub.status.busy": "2026-01-03T15:31:33.975445Z",
     "iopub.status.idle": "2026-01-03T15:31:34.105177Z",
     "shell.execute_reply": "2026-01-03T15:31:34.104770Z",
     "shell.execute_reply.started": "2026-01-03T15:31:33.975575Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Code copied to /kaggle/working/code\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "# Copy source code to Kaggle working directory\n",
    "if Path('/kaggle/working').exists():\n",
    "    # Option 1: Copy from input dataset (if you uploaded code as dataset)\n",
    "    code_source = Path(\"/kaggle/input/code-src/code\")  # Adjust path to your dataset\n",
    "    code_dest = Path('/kaggle/working/code')\n",
    "    \n",
    "    if code_source.exists():\n",
    "        if code_dest.exists():\n",
    "            shutil.rmtree(code_dest)\n",
    "        shutil.copytree(code_source, code_dest)\n",
    "        print(f\" Code copied to {code_dest}\")\n",
    "    else:\n",
    "        print(f\"  Code source not found at {code_source}\")\n",
    "        print(\"Creating src directory - you'll need to add your source files manually\")\n",
    "        # Create src directory structure manually\n",
    "        code_dest = Path('/kaggle/working/code/src')\n",
    "        code_dest.mkdir(parents=True, exist_ok=True)\n",
    "        print(f\"Created {code_dest}\")\n",
    "        print(\"Please add your source files (pipeline.py, vision.py, etc.) to this directory\")\n",
    "else:\n",
    "    print(\"Not running in Kaggle environment\")\n",
    "    code_dest = Path('../src')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Import thư viện và setup paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-03T15:31:34.106217Z",
     "iopub.status.busy": "2026-01-03T15:31:34.106088Z",
     "iopub.status.idle": "2026-01-03T15:31:40.632743Z",
     "shell.execute_reply": "2026-01-03T15:31:40.632285Z",
     "shell.execute_reply.started": "2026-01-03T15:31:34.106204Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# Add src to path\n",
    "if Path('/kaggle/working').exists():\n",
    "    sys.path.insert(0, '/kaggle/working/code/src')\n",
    "else:\n",
    "    sys.path.insert(0, '../src')\n",
    "    \n",
    "sys.path.insert(0, '/kaggle/working/code')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-03T15:31:40.633698Z",
     "iopub.status.busy": "2026-01-03T15:31:40.633379Z",
     "iopub.status.idle": "2026-01-03T15:32:09.246483Z",
     "shell.execute_reply": "2026-01-03T15:32:09.246015Z",
     "shell.execute_reply.started": "2026-01-03T15:31:40.633674Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-03 15:31:53.281983: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1767454313.684824     106 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1767454313.794068     106 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1767454314.710927     106 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1767454314.710956     106 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1767454314.710958     106 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1767454314.710960     106 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Pipeline imported successfully\n"
     ]
    }
   ],
   "source": [
    "# Import pipeline\n",
    "# Lưu ý: Nếu gặp lỗi \"unexpected keyword argument 'kb_path'\", \n",
    "# hãy chạy cell \"Force Reload Modules\" ở trên trước\n",
    "try:\n",
    "    from src.pipeline import RAGVQAPipeline\n",
    "    print(\" Pipeline imported successfully\")\n",
    "except ImportError as e:\n",
    "    print(f\" Error importing pipeline: {e}\")\n",
    "    print(\"Please make sure source files are in the correct location\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Force Reload Modules (nếu đã chạy trước đó)\n",
    "\n",
    "**Quan trọng**: Nếu bạn đã import pipeline trước đó và code đã được cập nhật, chạy cell này để reload:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-03T15:32:09.247513Z",
     "iopub.status.busy": "2026-01-03T15:32:09.247120Z",
     "iopub.status.idle": "2026-01-03T15:32:09.250841Z",
     "shell.execute_reply": "2026-01-03T15:32:09.250425Z",
     "shell.execute_reply.started": "2026-01-03T15:32:09.247496Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Cleared cache: src.pipeline\n",
      " Cleared cache: src.retrieval\n",
      " Cleared cache: src.vision\n",
      " Cleared cache: src.answering\n",
      " Cleared cache: src.config\n",
      " Cleared cache: src.prompts\n",
      "\n",
      " Modules cache cleared. Bây giờ chạy lại cell import ở dưới.\n"
     ]
    }
   ],
   "source": [
    "# Force reload all src modules (chỉ cần chạy nếu gặp lỗi \"unexpected keyword argument\")\n",
    "import sys\n",
    "import importlib\n",
    "\n",
    "# Danh sách modules cần reload\n",
    "modules_to_reload = [\n",
    "    'src.pipeline',\n",
    "    'src.retrieval',\n",
    "    'src.vision',\n",
    "    'src.answering',\n",
    "    'src.config',\n",
    "    'src.prompts'\n",
    "]\n",
    "\n",
    "# Xóa cached modules\n",
    "for module_name in modules_to_reload:\n",
    "    if module_name in sys.modules:\n",
    "        del sys.modules[module_name]\n",
    "        print(f\" Cleared cache: {module_name}\")\n",
    "\n",
    "print(\"\\n Modules cache cleared. Bây giờ chạy lại cell import ở dưới.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Cấu hình đường dẫn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-03T15:32:09.251572Z",
     "iopub.status.busy": "2026-01-03T15:32:09.251430Z",
     "iopub.status.idle": "2026-01-03T15:32:09.322680Z",
     "shell.execute_reply": "2026-01-03T15:32:09.322292Z",
     "shell.execute_reply.started": "2026-01-03T15:32:09.251557Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Loaded benchmark data: 60 samples\n",
      "  - Questions: 60\n",
      "  - Ground truth answers: 60\n",
      "\n",
      "Knowledge Base: /kaggle/input/knowledge-base/knowledge_base.json\n",
      "Benchmark Images Directory: /kaggle/input/dataset-benchmark/data/benchmark_images\n",
      "Benchmark JSON: /kaggle/input/dataset-benchmark/data/benchmark_60.json\n",
      "Fine-tuned Model Path: /kaggle/input/model-7b-tuned/models/qwen2vl-7b-vqa-grounded\n",
      "Vector DB Path: /kaggle/input/vector-db\n",
      "Output Directory: /kaggle/working/results\n",
      "\n",
      "Found 60 benchmark images\n",
      " Knowledge base found\n",
      " Vector DB found\n",
      " Fine-tuned model found\n"
     ]
    }
   ],
   "source": [
    "# Paths cho Kaggle\n",
    "if Path('/kaggle/working').exists():\n",
    "    # Kaggle paths - ĐIỀU CHỈNH THEO DATASET CỦA BẠN\n",
    "    KB_PATH = \"/kaggle/input/knowledge-base/knowledge_base.json\"\n",
    "    IMAGES_DIR = \"/kaggle/input/vqa-dataset/images_flat/images_flat\"\n",
    "    BENCHMARK_IMAGES_DIR = \"/kaggle/input/dataset-benchmark/data/benchmark_images\"\n",
    "    BENCHMARK_JSON_PATH = \"/kaggle/input/dataset-benchmark/data/benchmark_60.json\"  # File chứa questions + ground truth\n",
    "    FINETUNED_MODEL_PATH = \"/kaggle/input/model-7b-tuned/models/qwen2vl-7b-vqa-grounded\"\n",
    "    VECTOR_DB_PATH = \"/kaggle/input/vector-db\"\n",
    "    OUTPUT_DIR = \"/kaggle/working/results\"\n",
    "else:\n",
    "    # Local paths\n",
    "    KB_PATH = \"../../data/knowledge_base.json\"\n",
    "    IMAGES_DIR = \"../../data/images_flat\"\n",
    "    BENCHMARK_IMAGES_DIR = \"../../data/data-benchmark/benchmark_images\"\n",
    "    BENCHMARK_JSON_PATH = \"../../data/data-benchmark/benchmark_60.json\"  # File chứa questions + ground truth\n",
    "    FINETUNED_MODEL_PATH = \"../../models/qwen2vl-2b-vqa-grounded-merged\"\n",
    "    VECTOR_DB_PATH = \"../../models/vector_db\"\n",
    "    OUTPUT_DIR = \"../../results\"\n",
    "\n",
    "# Create output directory\n",
    "Path(OUTPUT_DIR).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Load benchmark data từ JSON (chứa cả image, question, answer)\n",
    "benchmark_data = []\n",
    "benchmark_questions = {}\n",
    "benchmark_ground_truth = {}\n",
    "\n",
    "if Path(BENCHMARK_JSON_PATH).exists():\n",
    "    with open(BENCHMARK_JSON_PATH, 'r', encoding='utf-8') as f:\n",
    "        benchmark_data = json.load(f)\n",
    "    \n",
    "    # Build dictionaries\n",
    "    for item in benchmark_data:\n",
    "        img_name = item.get('image', '')\n",
    "        benchmark_questions[img_name] = item.get('question', '')\n",
    "        benchmark_ground_truth[img_name] = item.get('answer', '')\n",
    "    \n",
    "    print(f\"✓ Loaded benchmark data: {len(benchmark_data)} samples\")\n",
    "    print(f\"  - Questions: {len(benchmark_questions)}\")\n",
    "    print(f\"  - Ground truth answers: {len(benchmark_ground_truth)}\")\n",
    "else:\n",
    "    print(f\"⚠ Benchmark JSON not found at {BENCHMARK_JSON_PATH}\")\n",
    "\n",
    "# Get list of benchmark images\n",
    "benchmark_images = list(benchmark_questions.keys())\n",
    "benchmark_images = sorted([img for img in benchmark_images if 'Zone.Identifier' not in img])\n",
    "\n",
    "print(f\"\\nKnowledge Base: {KB_PATH}\")\n",
    "print(f\"Benchmark Images Directory: {BENCHMARK_IMAGES_DIR}\")\n",
    "print(f\"Benchmark JSON: {BENCHMARK_JSON_PATH}\")\n",
    "print(f\"Fine-tuned Model Path: {FINETUNED_MODEL_PATH}\")\n",
    "print(f\"Vector DB Path: {VECTOR_DB_PATH}\")\n",
    "print(f\"Output Directory: {OUTPUT_DIR}\")\n",
    "print(f\"\\nFound {len(benchmark_images)} benchmark images\")\n",
    "\n",
    "# Verify paths exist\n",
    "if Path(KB_PATH).exists():\n",
    "    print(f\" Knowledge base found\")\n",
    "else:\n",
    "    print(f\" Knowledge base NOT found at {KB_PATH}\")\n",
    "\n",
    "if Path(VECTOR_DB_PATH).exists():\n",
    "    print(f\" Vector DB found\")\n",
    "else:\n",
    "    print(f\" Vector DB NOT found - will create embeddings from scratch\")\n",
    "\n",
    "if Path(FINETUNED_MODEL_PATH).exists():\n",
    "    print(f\" Fine-tuned model found\")\n",
    "else:\n",
    "    print(f\" Fine-tuned model NOT found - will use base model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Khởi tạo Pipeline với Fine-tuned Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-03T15:32:09.323352Z",
     "iopub.status.busy": "2026-01-03T15:32:09.323212Z",
     "iopub.status.idle": "2026-01-03T15:35:10.848377Z",
     "shell.execute_reply": "2026-01-03T15:35:10.847885Z",
     "shell.execute_reply.started": "2026-01-03T15:32:09.323336Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing pipeline with fine-tuned model...\n",
      "This may take a few minutes to load the models...\n",
      " Using fine-tuned model from: /kaggle/input/model-7b-tuned/models/qwen2vl-7b-vqa-grounded\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9add196f56347ebb844f498c356eb9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04914e34cec949f8b7b9d1c8c3c674f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8a44eb8334a4a6bbeb3372ded8fd886",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "787118c8c56a47a2a159e57c3bd3fc3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/3.99G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "389117538a66417184deb2eb47092fa3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/429M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aebed24f99a44572960fec04c26f2812",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a95c02e84184dc09fa5de036f95ec6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/272 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3408e658094d4606bbef043b1ab306c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/347 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The image processor of type `Qwen2VLImageProcessor` is now loaded as a fast processor by default, even if the model checkpoint was saved with a slow processor. This is a breaking change and may produce slightly different outputs. To continue using the slow processor, instantiate this class with `use_fast=False`. Note that this behavior will be extended to all models in a future release.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "140ecf7c81db40f6897fd8b0cf9b86ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84c70312174a4b948570cf20b5926502",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7facd91d767442eb5c411a3ff3fd998",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04bcbb5957a14279b36088833d193d16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bce4a15f3a548d4a756a0907fdb0439",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "chat_template.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.retrieval:faiss not available, falling back to creating embeddings\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ddb4bc5ed4e4cf5abfd4549481e01dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/229 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8341d9065131423abe599c842a52dc4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/122 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5e7c1098c1e4511a6c35ed36dc0784c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4344b328e08b480bb9e5a28cead219b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31c1e44030f94ba4834bbd1a5c71291a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/752 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b976aff4f39a47f3b6c6faaca45c8293",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/540M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd96bf4de4ae46b2a400a245b9e4f2e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/313 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96411d4637934735978d831724dd67dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d667adab4a994e82bcc6520ee1ea205f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/540M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca906ed239c84726b586cfb00dd69564",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "bpe.codes: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "763b605d90a2441aafcc3f6488cc4e9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/17.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac4598a4fd6f4d9781db414eebf9c9ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/150 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4478845e93114997bedbc269f9fbad5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3aa65f9e6a69462f89ec55ea976723d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05f4149c40ba4f3fab9cebc9cc912d84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c67da285ea549c9a01274c7c9e0e583",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6432b7136d84c699cba1c87d13e64eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "559c4a06e7f2442f81aae4d6623236dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00005.safetensors:   0%|          | 0.00/3.86G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9032ca71fa94d568bcf102367de4bf1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00005.safetensors:   0%|          | 0.00/3.86G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f18ceb1229bd4a6696344d4954575530",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00005-of-00005.safetensors:   0%|          | 0.00/1.09G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5483748ae36142f89a20423b338493c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00005.safetensors:   0%|          | 0.00/3.90G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0076d93ffa2f4ec58898bb1fbbec0c3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00004-of-00005.safetensors:   0%|          | 0.00/3.86G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4476271c7b144aa9124cac2c4784f25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "530ffc6fdab846329404d84c5f752aec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/244 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Pipeline ready!\n",
      "  - Vision: Qwen2-VL-2B (base)\n",
      "  - Answering: Fine-tuned model\n"
     ]
    }
   ],
   "source": [
    "print(\"Initializing pipeline with fine-tuned model...\")\n",
    "print(\"This may take a few minutes to load the models...\")\n",
    "\n",
    "# Kiểm tra xem fine-tuned model có tồn tại không\n",
    "if Path(FINETUNED_MODEL_PATH).exists():\n",
    "    print(f\" Using fine-tuned model from: {FINETUNED_MODEL_PATH}\")\n",
    "    answering_model = str(FINETUNED_MODEL_PATH)\n",
    "else:\n",
    "    print(f\" Fine-tuned model not found at: {FINETUNED_MODEL_PATH}\")\n",
    "    print(\"  Falling back to base model: Qwen/Qwen2-VL-2B-Instruct\")\n",
    "    answering_model = \"Qwen/Qwen2-VL-7B-Instruct\"\n",
    "\n",
    "# Initialize pipeline\n",
    "try:\n",
    "    pipeline = RAGVQAPipeline(\n",
    "        vision_model_name=\"Qwen/Qwen2-VL-2B-Instruct\",  # Base model for vision\n",
    "        answering_model_name=answering_model,  # Fine-tuned or base model\n",
    "        use_4bit=True,\n",
    "        kb_path=KB_PATH,\n",
    "        vector_db_path=VECTOR_DB_PATH\n",
    "    )\n",
    "    print(\"\\n Pipeline ready!\")\n",
    "    if answering_model != \"Qwen/Qwen2-VL-7B-Instruct\":\n",
    "        print(f\"  - Vision: Qwen2-VL-2B (base)\")\n",
    "        print(f\"  - Answering: Fine-tuned model\")\n",
    "    else:\n",
    "        print(f\"  - Vision: Qwen2-VL-2B (base)\")\n",
    "        print(f\"  - Answering: Qwen2-VL-7B (base)\")\n",
    "except Exception as e:\n",
    "    print(f\" Error initializing pipeline: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Load Benchmark Questions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-03T15:35:10.849619Z",
     "iopub.status.busy": "2026-01-03T15:35:10.849049Z",
     "iopub.status.idle": "2026-01-03T15:35:10.853261Z",
     "shell.execute_reply": "2026-01-03T15:35:10.852870Z",
     "shell.execute_reply.started": "2026-01-03T15:35:10.849601Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Sample Benchmark Questions ===\n",
      "\n",
      "1. Image: 000000.jpg\n",
      "   Question: Chiếc nón truyền thống mà các liền chị đang đội trong bức ảnh có tên gọi là gì và thường xuất hiện t...\n",
      "   GT Answer: Chiếc nón các liền chị đang đội là Nón quai thao. Đây là một biểu tượng đặc trưng của văn hóa Quan h...\n",
      "\n",
      "2. Image: 000001.jpg\n",
      "   Question: Hình tượng rồng được trang trí trên mũi thuyền trong bức ảnh này mang những ý nghĩa biểu trưng sâu s...\n",
      "   GT Answer: Biểu tượng của sức mạnh, quyền uy và thịnh vượng. Trong văn hóa và tín ngưỡng Việt Nam, rồng là một ...\n",
      "\n",
      "3. Image: 000002.jpg\n",
      "   Question: Trong quần thể di tích lịch sử và văn hóa nổi tiếng của Việt Nam, công trình kiến trúc được nhìn thấ...\n",
      "   GT Answer: Khuê Văn Các. Đây là một trong những công trình kiến trúc tiêu biểu thuộc quần thể di tích Văn Miếu ...\n"
     ]
    }
   ],
   "source": [
    "# Hiển thị một số câu hỏi mẫu từ benchmark\n",
    "print(\"=== Sample Benchmark Questions ===\")\n",
    "for i, img in enumerate(benchmark_images[:3]):\n",
    "    print(f\"\\n{i+1}. Image: {img}\")\n",
    "    print(f\"   Question: {benchmark_questions[img][:100]}...\")\n",
    "    print(f\"   GT Answer: {benchmark_ground_truth[img][:100]}...\")\n",
    "\n",
    "# Default question (fallback nếu không có trong benchmark)\n",
    "DEFAULT_QUESTION = \"Đây là gì? Hãy mô tả chi tiết hình ảnh này và giải thích ý nghĩa văn hóa nếu có.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Chạy inference trên Benchmark Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-03T15:35:10.855115Z",
     "iopub.status.busy": "2026-01-03T15:35:10.854955Z",
     "iopub.status.idle": "2026-01-03T15:48:29.318774Z",
     "shell.execute_reply": "2026-01-03T15:48:29.318299Z",
     "shell.execute_reply.started": "2026-01-03T15:35:10.855100Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Running Inference on 60 Benchmark Images\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:   0%|          | 0/60 [00:00<?, ?it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Processing images:  15%|█▌        | 9/60 [01:55<11:57, 14.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[10/60] Processing: 000009.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  32%|███▏      | 19/60 [04:03<09:03, 13.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[20/60] Processing: 000019.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  48%|████▊     | 29/60 [06:19<07:05, 13.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[30/60] Processing: 000029.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  65%|██████▌   | 39/60 [08:22<04:20, 12.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[40/60] Processing: 000039.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  82%|████████▏ | 49/60 [10:44<02:31, 13.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[50/60] Processing: 000049.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  98%|█████████▊| 59/60 [12:55<00:12, 12.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[60/60] Processing: 000059.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images: 100%|██████████| 60/60 [13:04<00:00, 13.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      " Completed inference on 60 images\n",
      "  - Successful: 60\n",
      "  - Errors: 0\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"Running Inference on {len(benchmark_images)} Benchmark Images\")\n",
    "print(f\"{'='*80}\\n\")\n",
    "\n",
    "for idx, image_name in enumerate(tqdm(benchmark_images, desc=\"Processing images\")):\n",
    "    try:\n",
    "        # Load image\n",
    "        image_path = Path(BENCHMARK_IMAGES_DIR) / image_name\n",
    "        \n",
    "        if not image_path.exists():\n",
    "            print(f\" Image not found: {image_path}\")\n",
    "            continue\n",
    "        \n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        \n",
    "        # Get question from benchmark (có sẵn từ cell trước)\n",
    "        question = benchmark_questions.get(image_name, DEFAULT_QUESTION)\n",
    "        \n",
    "        # Print progress every 10 images\n",
    "        if (idx + 1) % 10 == 0:\n",
    "            print(f\"\\n[{idx+1}/{len(benchmark_images)}] Processing: {image_name}\")\n",
    "        \n",
    "        # Get prediction\n",
    "        result = pipeline.process(\n",
    "            image=image,\n",
    "            question=question,\n",
    "            return_intermediate=True\n",
    "        )\n",
    "        \n",
    "        # Separate retrieved docs by source\n",
    "        retrieved_docs = result.get('retrieved_docs', [])\n",
    "        kb_docs = [doc for doc in retrieved_docs if doc.get('source', '').startswith('kb_')]\n",
    "        wiki_docs = [doc for doc in retrieved_docs if doc.get('source') == 'wikipedia']\n",
    "        \n",
    "        # Extract Wikipedia search keywords (if any)\n",
    "        wiki_keywords = None\n",
    "        if wiki_docs and len(wiki_docs) > 0:\n",
    "            wiki_keywords = wiki_docs[0].get('keywords_used', None)\n",
    "        \n",
    "        # Store results\n",
    "        results.append({\n",
    "            'image': image_name,\n",
    "            'question': question,\n",
    "            'answer': result['answer'],\n",
    "            'ground_truth': benchmark_ground_truth.get(image_name, ''),  # Lưu ground truth để so sánh\n",
    "            'caption': result.get('caption', ''),\n",
    "            'ocr': result.get('ocr', ''),\n",
    "            'num_retrieved': len(retrieved_docs),\n",
    "            'num_kb_docs': len(kb_docs),\n",
    "            'num_wiki_docs': len(wiki_docs),\n",
    "            'wiki_keywords': wiki_keywords,\n",
    "            'context': result.get('context', '')[:500]  # Truncate for display\n",
    "        })\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n✗ Error processing {image_name}: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        results.append({\n",
    "            'image': image_name,\n",
    "            'question': benchmark_questions.get(image_name, ''),\n",
    "            'answer': f'ERROR: {str(e)}',\n",
    "            'ground_truth': benchmark_ground_truth.get(image_name, ''),\n",
    "            'caption': '',\n",
    "            'ocr': '',\n",
    "            'num_retrieved': 0,\n",
    "            'num_kb_docs': 0,\n",
    "            'num_wiki_docs': 0,\n",
    "            'wiki_keywords': None,\n",
    "            'context': ''\n",
    "        })\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\" Completed inference on {len(results)} images\")\n",
    "print(f\"  - Successful: {sum(1 for r in results if 'ERROR' not in r['answer'])}\")\n",
    "print(f\"  - Errors: {sum(1 for r in results if 'ERROR' in r['answer'])}\")\n",
    "print(f\"{'='*80}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Lưu kết quả\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-03T15:48:29.319595Z",
     "iopub.status.busy": "2026-01-03T15:48:29.319430Z",
     "iopub.status.idle": "2026-01-03T15:48:29.368238Z",
     "shell.execute_reply": "2026-01-03T15:48:29.367796Z",
     "shell.execute_reply.started": "2026-01-03T15:48:29.319579Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Results saved to /kaggle/working/results/benchmark_inference_results_finetuned.json\n",
      " Results saved to /kaggle/working/results/benchmark_inference_results_finetuned.csv\n",
      "\n",
      "=== Inference Summary ===\n",
      "Total images processed: 60\n",
      "Average retrieved docs: 3.00\n",
      "Images with caption: 60\n",
      "Images with OCR: 1\n",
      "Images with KB docs: 60\n",
      "Images with Wikipedia docs: 0\n"
     ]
    }
   ],
   "source": [
    "# Save to JSON\n",
    "output_json = f\"{OUTPUT_DIR}/benchmark_inference_results_finetuned.json\"\n",
    "with open(output_json, 'w', encoding='utf-8') as f:\n",
    "    json.dump(results, f, ensure_ascii=False, indent=2)\n",
    "print(f\" Results saved to {output_json}\")\n",
    "\n",
    "# Save to CSV for easy viewing\n",
    "df = pd.DataFrame(results)\n",
    "output_csv = f\"{OUTPUT_DIR}/benchmark_inference_results_finetuned.csv\"\n",
    "df.to_csv(output_csv, index=False, encoding='utf-8-sig')\n",
    "print(f\" Results saved to {output_csv}\")\n",
    "\n",
    "# Display summary\n",
    "print(\"\\n=== Inference Summary ===\")\n",
    "print(f\"Total images processed: {len(results)}\")\n",
    "if len(results) > 0:\n",
    "    print(f\"Average retrieved docs: {df['num_retrieved'].mean():.2f}\")\n",
    "    print(f\"Images with caption: {(df['caption'] != '').sum()}\")\n",
    "    print(f\"Images with OCR: {(df['ocr'] != '').sum()}\")\n",
    "    print(f\"Images with KB docs: {(df['num_kb_docs'] > 0).sum()}\")\n",
    "    print(f\"Images with Wikipedia docs: {(df['num_wiki_docs'] > 0).sum()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Hiển thị một vài kết quả mẫu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-03T15:48:29.368985Z",
     "iopub.status.busy": "2026-01-03T15:48:29.368810Z",
     "iopub.status.idle": "2026-01-03T15:48:29.373010Z",
     "shell.execute_reply": "2026-01-03T15:48:29.372605Z",
     "shell.execute_reply.started": "2026-01-03T15:48:29.368969Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Sample 1: 000000.jpg\n",
      "================================================================================\n",
      "Question: Chiếc nón truyền thống mà các liền chị đang đội trong bức ảnh có tên gọi là gì và thường xuất hiện trong loại hình nghệ thuật dân gian nào của Việt Nam, đặc biệt là ở vùng châu thổ sông Hồng?\n",
      "\n",
      "Answer:\n",
      "Nón lá\n",
      "\n",
      "Đây là nón lá, một loại mũ được làm từ lá chuối hoặc mít, rất phổ biến ở miền Bắc Việt Nam. Nó thường xuất hiện nhiều trong các tác phẩm nghệ thuật dân tộc, đặc biệt trong các lễ hội, biểu diễn nghệ thuật truyền thống như hát chầu văn, múa rối nước... Nón lá cũng là một phần không thể thiếu trong đời sống hàng ngày của người dân vùng nông thôn.\n",
      "\n",
      "Caption: Hình ảnh này mô tả một nhóm người mặc trang phục truyền thống Việt Nam đang đứng trước cổng một ngôi đền. Họ đang cầm những chiếc khăn tròn màu đỏ, vàng, trắng và đỏ, mang màu sắc và hình thức khác nhau. Một người đang cầm một chiếc khăn màu đỏ có một dây màu vàng. Họ đang đứng trước một cổng có một...\n",
      "\n",
      "Retrieved docs: 3 (KB: 3, Wiki: 0)\n",
      "\n",
      "================================================================================\n",
      "Sample 2: 000001.jpg\n",
      "================================================================================\n",
      "Question: Hình tượng rồng được trang trí trên mũi thuyền trong bức ảnh này mang những ý nghĩa biểu trưng sâu sắc nào trong văn hóa và tín ngưỡng của người Việt Nam?\n",
      "\n",
      "Answer:\n",
      "Rồng là linh vật thiêng liêng, biểu tượng cho sức mạnh, quyền lực và sự may mắn.\n",
      "\n",
      "Trong văn hóa Việt, rồng là biểu tượng của sức mạnh, sự may mắn và thịnh vượng. Việc trang trí hình rồng trên thuyền thể hiện mong muốn cầu may, bình an và phát triển cho cuộc sống. Sự xuất hiện của rồng cũng gắn liền với tín ngưỡng thờ thần, cầu nguyện cho mưa thuận gió hòa, mùa màng bội thu.\n",
      "\n",
      "Caption: Hình ảnh này mô tả một cảnh quay ở một hồ nước xanh ngắt. Trong hình, có một chiếc thuyền dài và ngang, có hình vẽ rồng trên mặt nước. Trên thuyền, có một nhóm người mặc trang phục truyền thống Việt Nam, có màu đỏ, xanh, và đen. Họ đang cầm những chiếc dùa màu đen và đang đứng trên thuyền. Một người...\n",
      "\n",
      "Retrieved docs: 3 (KB: 3, Wiki: 0)\n",
      "\n",
      "================================================================================\n",
      "Sample 3: 000002.jpg\n",
      "================================================================================\n",
      "Question: Trong quần thể di tích lịch sử và văn hóa nổi tiếng của Việt Nam, công trình kiến trúc được nhìn thấy trong bức ảnh này có tên gọi là gì và mang ý nghĩa biểu tượng sâu sắc nào đối với nền văn hiến dân tộc?\n",
      "\n",
      "Answer:\n",
      "Đền thờ\n",
      "\n",
      "Đây là một công trình kiến ​​trúc mang đậm chất Á Đông, có lẽ là một phần của hệ thống đền miếu, chùa chiền, hoặc khu tưởng niệm. Nó thể hiện kỹ thuật xây dựng và nghệ thuật điêu khắc thời xưa.\n",
      "\n",
      "Caption: Hình ảnh này mô tả một cổng cổ truyền ở Việt Nam. Cổng được thiết kế với một cấu trúc trung tâm với một mái vòm và một tháp hình chữ nhật. Cổng được làm từ gỗ và đá, có một cửa chính mở rộng. Cổng được trang trí với các bức tượng và các biểu tượng văn hóa Việt Nam. Cổng nằm ở giữa một khu vườn nhỏ v...\n",
      "\n",
      "Retrieved docs: 3 (KB: 3, Wiki: 0)\n",
      "\n",
      "================================================================================\n",
      "Sample 4: 000003.jpg\n",
      "================================================================================\n",
      "Question: Cổng kiến trúc độc đáo với cửa sổ tròn trong bức ảnh này được biết đến với tên gọi chính xác là gì, và nó tượng trưng cho giá trị văn hóa, giáo dục nào trong lịch sử Việt Nam?\n",
      "\n",
      "Answer:\n",
      "Cổng Ngọ Munakan\n",
      "\n",
      "Cổng này là Ngọ Munan - một phần của hệ thống tường thành và cổng thành tại Hà Nội. Nó nổi bật với kiến trúc đặc trưng của các công trình thời Trần, với cửa sổ trời hình tròn tạo nên vẻ đẹp hài hòa và uy nghiêm. Ngọ Munda đóng vai trò quan trọng là biểu tượng của quyền lực và sự tôn kính đối với tri thức.\n",
      "\n",
      "Caption: Hình ảnh này mô tả một cổng cổ truyền ở Việt Nam. Cổng được thiết kế với một mái vòm và một bức tượng lớn ở giữa. Cổng được xây dựng từ gỗ và có một mái vòm màu đỏ và vàng. Cổng có một bức tượng lớn ở giữa, có hình dạng giống như một con chim. Cổng được xây dựng ở một khu vườn xanh mát với nhiều cây...\n",
      "\n",
      "Retrieved docs: 3 (KB: 3, Wiki: 0)\n",
      "\n",
      "================================================================================\n",
      "Sample 5: 000004.jpg\n",
      "================================================================================\n",
      "Question: Bức họa kiến trúc được vẽ trên tà áo dài trong ảnh mô tả quần thể di tích nổi tiếng nào của Việt Nam, và địa danh này gắn liền với truyền thuyết lịch sử trọng đại nào?\n",
      "\n",
      "Answer:\n",
      "Bức họa miêu tả Khuê Anh - một phần của khu di tích Chùa Một Cột, thuộc phố cổ Hà Nội.\n",
      "\n",
      "Khuê An là một phần quan trọng của Chùa One Cột, một di tích lịch sử nổi bật ở Hà Nội. Nó nằm bên cạnh dòng sông Hồng, tạo nên vẻ đẹp thơ mộng.  Địa điểm này thường được nhắc đến trong nhiều tác phẩm nghệ thuật vì vẻ đẹp và giá trị lịch sử của nó.\n",
      "\n",
      "Caption: Hình ảnh này mô tả một người phụ nữ đang mặc một bộ áo dài màu hồng đỏ. Cô ấy đang cầm một chiếc mũ màu hồng lớn và đang đứng trước một bức tường trắng. Cô ấy có mái tóc đen dài và đang đeo một tai nghe. Cô ấy đang nắm một chiếc mũ màu hồng lớn trong tay và đang nhìn về phía trước. Cô ấy đang đứng t...\n",
      "\n",
      "Retrieved docs: 3 (KB: 3, Wiki: 0)\n"
     ]
    }
   ],
   "source": [
    "# Display first 5 results\n",
    "num_samples = min(5, len(results))\n",
    "for i in range(num_samples):\n",
    "    result = results[i]\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Sample {i+1}: {result['image']}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"Question: {result['question']}\")\n",
    "    print(f\"\\nAnswer:\")\n",
    "    print(result['answer'])\n",
    "    if result['caption']:\n",
    "        print(f\"\\nCaption: {result['caption'][:300]}...\" if len(result['caption']) > 300 else f\"\\nCaption: {result['caption']}\")\n",
    "    if result['ocr']:\n",
    "        print(f\"\\nOCR: {result['ocr'][:200]}...\" if len(result['ocr']) > 200 else f\"\\nOCR: {result['ocr']}\")\n",
    "    print(f\"\\nRetrieved docs: {result['num_retrieved']} (KB: {result['num_kb_docs']}, Wiki: {result['num_wiki_docs']})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# PHẦN 2: SO SÁNH HIỆU SUẤT FINE-TUNED VS BASE MODEL\n",
    "\n",
    "So sánh hiệu suất giữa:\n",
    "1. **Fine-tuned Qwen2-VL-7B** (model đã train)\n",
    "2. **Base Qwen2-VL-7B-Instruct** (model gốc)\n",
    "\n",
    "Các metrics đánh giá:\n",
    "- **BERTScore**: Đánh giá semantic similarity\n",
    "- **ROUGE-L**: Đánh giá overlap n-gram (longest common subsequence)\n",
    "- **Faithfulness**: Đánh giá mức độ trung thực với context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Cài đặt thư viện đánh giá"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-03T15:48:29.373669Z",
     "iopub.status.busy": "2026-01-03T15:48:29.373526Z",
     "iopub.status.idle": "2026-01-03T15:48:29.740024Z",
     "shell.execute_reply": "2026-01-03T15:48:29.739545Z",
     "shell.execute_reply.started": "2026-01-03T15:48:29.373653Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " NLTK punkt downloaded\n"
     ]
    }
   ],
   "source": [
    "# Packages đã được cài đặt ở cell đầu tiên\n",
    "# Chỉ cần import\n",
    "import nltk\n",
    "nltk.download('punkt', quiet=True)\n",
    "print(\" NLTK punkt downloaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Lưu kết quả Fine-tuned model và giải phóng bộ nhớ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-03T15:48:29.740863Z",
     "iopub.status.busy": "2026-01-03T15:48:29.740684Z",
     "iopub.status.idle": "2026-01-03T15:48:30.222557Z",
     "shell.execute_reply": "2026-01-03T15:48:30.222097Z",
     "shell.execute_reply.started": "2026-01-03T15:48:29.740826Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Đã lưu 60 kết quả từ Fine-tuned model\n",
      " Đã giải phóng bộ nhớ GPU\n",
      "  VRAM available: 79.4 GB\n"
     ]
    }
   ],
   "source": [
    "# Lưu kết quả fine-tuned model để dùng cho so sánh\n",
    "finetuned_results = results.copy()\n",
    "print(f\"✓ Đã lưu {len(finetuned_results)} kết quả từ Fine-tuned model\")\n",
    "\n",
    "# Giải phóng bộ nhớ GPU\n",
    "import gc\n",
    "import torch\n",
    "\n",
    "# Xóa pipeline cũ\n",
    "if 'pipeline' in dir():\n",
    "    del pipeline\n",
    "gc.collect()\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "    print(f\" Đã giải phóng bộ nhớ GPU\")\n",
    "    print(f\"  VRAM available: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Khởi tạo Pipeline với Base Model (Qwen2-VL-7B-Instruct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-03T15:48:30.223360Z",
     "iopub.status.busy": "2026-01-03T15:48:30.223196Z",
     "iopub.status.idle": "2026-01-03T15:50:52.328535Z",
     "shell.execute_reply": "2026-01-03T15:50:52.328057Z",
     "shell.execute_reply.started": "2026-01-03T15:48:30.223343Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing pipeline with BASE model (Qwen2-VL-2B-Instruct)...\n",
      "This will be used for comparison with fine-tuned model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f92ac6535ff5445fa21b2f8a6b121d99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:src.retrieval:faiss not available, falling back to creating embeddings\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "183f6160a6e6441e9187e765287a7b11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13e6570205304a43858813a0759a77c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6aceec40f2e41f2bcb02da41f8b2985",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/347 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d41bf1bedd914670aad6d23971643f85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1529a3135b764946bc4c2a228ae0793c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78da8d0c778147c2984d409f828a205d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f42417e3bd314017aa9267247a670b2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b75471363a7f454e8c596a14e4594fb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "chat_template.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Pipeline with BASE model ready!\n"
     ]
    }
   ],
   "source": [
    "print(\"Initializing pipeline with BASE model (Qwen2-VL-2B-Instruct)...\")\n",
    "print(\"This will be used for comparison with fine-tuned model\")\n",
    "\n",
    "# Reload modules để đảm bảo dùng code mới nhất\n",
    "import sys\n",
    "modules_to_reload = ['src.pipeline', 'src.retrieval', 'src.vision', 'src.answering', 'src.config', 'src.prompts']\n",
    "for module_name in modules_to_reload:\n",
    "    if module_name in sys.modules:\n",
    "        del sys.modules[module_name]\n",
    "\n",
    "from src.pipeline import RAGVQAPipeline\n",
    "\n",
    "# Define base model ID for later use\n",
    "BASE_MODEL_ID = \"Qwen/Qwen2-VL-7B-Instruct\"\n",
    "\n",
    "# Initialize pipeline với BASE model (không phải fine-tuned)\n",
    "try:\n",
    "    pipeline_base = RAGVQAPipeline(\n",
    "        vision_model_name=\"Qwen/Qwen2-VL-2B-Instruct\",  # Base model for vision\n",
    "        answering_model_name=BASE_MODEL_ID,  # Base model for answering (KHÔNG FINE-TUNED)\n",
    "        use_4bit=True,\n",
    "        kb_path=KB_PATH,\n",
    "        vector_db_path=VECTOR_DB_PATH\n",
    "    )\n",
    "    print(\" Pipeline with BASE model ready!\")\n",
    "except Exception as e:\n",
    "    print(f\" Error initializing BASE pipeline: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Chạy inference với Base Model trên cùng benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-03T15:50:52.329347Z",
     "iopub.status.busy": "2026-01-03T15:50:52.329202Z",
     "iopub.status.idle": "2026-01-03T16:05:03.305808Z",
     "shell.execute_reply": "2026-01-03T16:05:03.305343Z",
     "shell.execute_reply.started": "2026-01-03T15:50:52.329327Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Running Inference with BASE MODEL on 60 Benchmark Images\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing with BASE model:  15%|█▌        | 9/60 [01:59<11:49, 13.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[10/60] Processing: 000009.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing with BASE model:  32%|███▏      | 19/60 [04:28<10:39, 15.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[20/60] Processing: 000019.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing with BASE model:  48%|████▊     | 29/60 [06:53<07:48, 15.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[30/60] Processing: 000029.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing with BASE model:  65%|██████▌   | 39/60 [09:09<04:39, 13.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[40/60] Processing: 000039.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing with BASE model:  82%|████████▏ | 49/60 [11:35<02:47, 15.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[50/60] Processing: 000049.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing with BASE model:  98%|█████████▊| 59/60 [13:58<00:14, 14.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[60/60] Processing: 000059.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing with BASE model: 100%|██████████| 60/60 [14:10<00:00, 14.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      " Completed BASE model inference on 60 images\n",
      "  - Successful: 60\n",
      "  - Errors: 0\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "base_results = []\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"Running Inference with BASE MODEL on {len(benchmark_images)} Benchmark Images\")\n",
    "print(f\"{'='*80}\\n\")\n",
    "\n",
    "for idx, image_name in enumerate(tqdm(benchmark_images, desc=\"Processing with BASE model\")):\n",
    "    try:\n",
    "        # Load image\n",
    "        image_path = Path(BENCHMARK_IMAGES_DIR) / image_name\n",
    "        \n",
    "        if not image_path.exists():\n",
    "            print(f\"⚠ Image not found: {image_path}\")\n",
    "            continue\n",
    "        \n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        \n",
    "        # Get question (dùng cùng câu hỏi như fine-tuned)\n",
    "        question = benchmark_questions.get(image_name, DEFAULT_QUESTION)\n",
    "        \n",
    "        # Print progress every 10 images\n",
    "        if (idx + 1) % 10 == 0:\n",
    "            print(f\"\\n[{idx+1}/{len(benchmark_images)}] Processing: {image_name}\")\n",
    "        \n",
    "        # Get prediction from BASE model\n",
    "        result = pipeline_base.process(\n",
    "            image=image,\n",
    "            question=question,\n",
    "            return_intermediate=True\n",
    "        )\n",
    "        \n",
    "        # Separate retrieved docs\n",
    "        retrieved_docs = result.get('retrieved_docs', [])\n",
    "        kb_docs = [doc for doc in retrieved_docs if doc.get('source', '').startswith('kb_')]\n",
    "        wiki_docs = [doc for doc in retrieved_docs if doc.get('source') == 'wikipedia']\n",
    "        \n",
    "        wiki_keywords = None\n",
    "        if wiki_docs and len(wiki_docs) > 0:\n",
    "            wiki_keywords = wiki_docs[0].get('keywords_used', None)\n",
    "        \n",
    "        # Store results\n",
    "        base_results.append({\n",
    "            'image': image_name,\n",
    "            'question': question,\n",
    "            'answer': result['answer'],\n",
    "            'ground_truth': benchmark_ground_truth.get(image_name, ''),\n",
    "            'caption': result.get('caption', ''),\n",
    "            'ocr': result.get('ocr', ''),\n",
    "            'num_retrieved': len(retrieved_docs),\n",
    "            'num_kb_docs': len(kb_docs),\n",
    "            'num_wiki_docs': len(wiki_docs),\n",
    "            'wiki_keywords': wiki_keywords,\n",
    "            'context': result.get('context', '')[:500]\n",
    "        })\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n✗ Error processing {image_name}: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        base_results.append({\n",
    "            'image': image_name,\n",
    "            'question': benchmark_questions.get(image_name, ''),\n",
    "            'answer': f'ERROR: {str(e)}',\n",
    "            'ground_truth': benchmark_ground_truth.get(image_name, ''),\n",
    "            'caption': '',\n",
    "            'ocr': '',\n",
    "            'num_retrieved': 0,\n",
    "            'num_kb_docs': 0,\n",
    "            'num_wiki_docs': 0,\n",
    "            'wiki_keywords': None,\n",
    "            'context': ''\n",
    "        })\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\" Completed BASE model inference on {len(base_results)} images\")\n",
    "print(f\"  - Successful: {sum(1 for r in base_results if 'ERROR' not in r['answer'])}\")\n",
    "print(f\"  - Errors: {sum(1 for r in base_results if 'ERROR' in r['answer'])}\")\n",
    "print(f\"{'='*80}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Lưu kết quả Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-03T16:05:03.306601Z",
     "iopub.status.busy": "2026-01-03T16:05:03.306447Z",
     "iopub.status.idle": "2026-01-03T16:05:03.317672Z",
     "shell.execute_reply": "2026-01-03T16:05:03.317249Z",
     "shell.execute_reply.started": "2026-01-03T16:05:03.306586Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Base model results saved to /kaggle/working/results/benchmark_inference_results_base.json\n",
      " Base model results saved to /kaggle/working/results/benchmark_inference_results_base.csv\n"
     ]
    }
   ],
   "source": [
    "# Save base model results to JSON\n",
    "output_json_base = f\"{OUTPUT_DIR}/benchmark_inference_results_base.json\"\n",
    "with open(output_json_base, 'w', encoding='utf-8') as f:\n",
    "    json.dump(base_results, f, ensure_ascii=False, indent=2)\n",
    "print(f\" Base model results saved to {output_json_base}\")\n",
    "\n",
    "# Save to CSV\n",
    "df_base = pd.DataFrame(base_results)\n",
    "output_csv_base = f\"{OUTPUT_DIR}/benchmark_inference_results_base.csv\"\n",
    "df_base.to_csv(output_csv_base, index=False, encoding='utf-8-sig')\n",
    "print(f\" Base model results saved to {output_csv_base}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# PHẦN 3: SO SÁNH VỚI QWEN2-VL-2B ZERO-SHOT\n",
    "\n",
    "Thêm 2 baseline nữa để so sánh:\n",
    "1. **Qwen2-VL-2B Zero-shot**: Model Qwen2-VL-2B KHÔNG sử dụng RAG (trả lời trực tiếp từ ảnh)\n",
    "\n",
    "Tổng cộng 3 models để so sánh:\n",
    "- RAG Pipeline + Fine-tuned Qwen2-VL-2B\n",
    "- RAG Pipeline + Base Qwen2-VL-2B  \n",
    "- Qwen2-VL-2B Zero-shot (không RAG)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14.1. Giải phóng bộ nhớ cho Base Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-03T16:05:03.318375Z",
     "iopub.status.busy": "2026-01-03T16:05:03.318227Z",
     "iopub.status.idle": "2026-01-03T16:05:03.943621Z",
     "shell.execute_reply": "2026-01-03T16:05:03.943139Z",
     "shell.execute_reply.started": "2026-01-03T16:05:03.318360Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Đã giải phóng bộ nhớ GPU từ Base Pipeline\n"
     ]
    }
   ],
   "source": [
    "# Giải phóng bộ nhớ từ base pipeline\n",
    "import gc\n",
    "import torch\n",
    "\n",
    "if 'pipeline_base' in dir():\n",
    "    del pipeline_base\n",
    "gc.collect()\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "print(\" Đã giải phóng bộ nhớ GPU từ Base Pipeline\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14.2. Qwen2-VL-2B Zero-shot (Không RAG)\n",
    "\n",
    "Chạy inference trực tiếp với Qwen2-VL-2B **KHÔNG** sử dụng RAG pipeline.\n",
    "Model chỉ dựa vào visual understanding để trả lời câu hỏi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-03T16:05:03.944457Z",
     "iopub.status.busy": "2026-01-03T16:05:03.944312Z",
     "iopub.status.idle": "2026-01-03T16:05:07.889124Z",
     "shell.execute_reply": "2026-01-03T16:05:07.888644Z",
     "shell.execute_reply.started": "2026-01-03T16:05:03.944442Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Qwen2-VL-2B for Zero-shot inference...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cae9098baff44b72923543c4db964ee4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Qwen2-VL-2B Zero-shot model loaded!\n",
      " Zero-shot inference function ready!\n"
     ]
    }
   ],
   "source": [
    "from transformers import Qwen2VLForConditionalGeneration, AutoProcessor, BitsAndBytesConfig\n",
    "from qwen_vl_utils import process_vision_info\n",
    "\n",
    "# Load Qwen2-VL-2B for zero-shot inference\n",
    "print(\"Loading Qwen2-VL-2B for Zero-shot inference...\")\n",
    "\n",
    "QWEN_ZEROSHOT_MODEL = \"Qwen/Qwen2-VL-2B-Instruct\"\n",
    "\n",
    "# Quantization config\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    "    bnb_4bit_use_double_quant=True\n",
    ")\n",
    "\n",
    "# Load model\n",
    "qwen_zeroshot_model = Qwen2VLForConditionalGeneration.from_pretrained(\n",
    "    QWEN_ZEROSHOT_MODEL,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.float16\n",
    ")\n",
    "qwen_zeroshot_processor = AutoProcessor.from_pretrained(QWEN_ZEROSHOT_MODEL)\n",
    "\n",
    "print(f\" Qwen2-VL-2B Zero-shot model loaded!\")\n",
    "\n",
    "\n",
    "def qwen_zeroshot_inference(image, question):\n",
    "    \"\"\"\n",
    "    Run zero-shot inference with Qwen2-VL-2B (no RAG)\n",
    "    \"\"\"\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"image\", \"image\": image},\n",
    "                {\"type\": \"text\", \"text\": f\"Hãy trả lời câu hỏi sau bằng tiếng Việt dựa trên hình ảnh:\\n\\nCâu hỏi: {question}\"}\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    # Prepare input\n",
    "    text = qwen_zeroshot_processor.apply_chat_template(\n",
    "        messages, tokenize=False, add_generation_prompt=True\n",
    "    )\n",
    "    image_inputs, video_inputs = process_vision_info(messages)\n",
    "    inputs = qwen_zeroshot_processor(\n",
    "        text=[text],\n",
    "        images=image_inputs,\n",
    "        videos=video_inputs,\n",
    "        padding=True,\n",
    "        return_tensors=\"pt\"\n",
    "    ).to(qwen_zeroshot_model.device)\n",
    "    \n",
    "    # Generate\n",
    "    with torch.no_grad():\n",
    "        generated_ids = qwen_zeroshot_model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=512,\n",
    "            do_sample=False\n",
    "        )\n",
    "    \n",
    "    # Decode\n",
    "    generated_ids_trimmed = [\n",
    "        out_ids[len(in_ids):] \n",
    "        for in_ids, out_ids in zip(inputs.input_ids, generated_ids)\n",
    "    ]\n",
    "    output_text = qwen_zeroshot_processor.batch_decode(\n",
    "        generated_ids_trimmed, \n",
    "        skip_special_tokens=True, \n",
    "        clean_up_tokenization_spaces=False\n",
    "    )[0]\n",
    "    \n",
    "    return output_text\n",
    "\n",
    "print(\" Zero-shot inference function ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14.3. Chạy inference Qwen2-VL-2B Zero-shot trên benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-03T16:05:07.889943Z",
     "iopub.status.busy": "2026-01-03T16:05:07.889787Z",
     "iopub.status.idle": "2026-01-03T16:08:16.662463Z",
     "shell.execute_reply": "2026-01-03T16:08:16.662010Z",
     "shell.execute_reply.started": "2026-01-03T16:05:07.889927Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Running ZERO-SHOT Inference with Qwen2-VL-2B on 60 Images\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Zero-shot inference:  15%|█▌        | 9/60 [00:33<02:14,  2.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[10/60] Processing: 000009.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Zero-shot inference:  32%|███▏      | 19/60 [01:00<02:07,  3.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[20/60] Processing: 000019.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Zero-shot inference:  48%|████▊     | 29/60 [01:29<00:59,  1.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[30/60] Processing: 000029.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Zero-shot inference:  65%|██████▌   | 39/60 [01:53<00:49,  2.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[40/60] Processing: 000039.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Zero-shot inference:  82%|████████▏ | 49/60 [02:12<00:20,  1.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[50/60] Processing: 000049.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Zero-shot inference:  98%|█████████▊| 59/60 [03:07<00:06,  6.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[60/60] Processing: 000059.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Zero-shot inference: 100%|██████████| 60/60 [03:08<00:00,  3.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      " Completed Zero-shot inference on 60 images\n",
      "  - Successful: 60\n",
      "  - Errors: 0\n",
      "================================================================================\n",
      " Zero-shot results saved to /kaggle/working/results/benchmark_inference_results_zeroshot.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "zeroshot_results = []\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"Running ZERO-SHOT Inference with Qwen2-VL-2B on {len(benchmark_images)} Images\")\n",
    "print(f\"{'='*80}\\n\")\n",
    "\n",
    "for idx, image_name in enumerate(tqdm(benchmark_images, desc=\"Zero-shot inference\")):\n",
    "    try:\n",
    "        # Load image\n",
    "        image_path = Path(BENCHMARK_IMAGES_DIR) / image_name\n",
    "        \n",
    "        if not image_path.exists():\n",
    "            continue\n",
    "        \n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        \n",
    "        # Get question\n",
    "        question = benchmark_questions.get(image_name, DEFAULT_QUESTION)\n",
    "        \n",
    "        # Print progress\n",
    "        if (idx + 1) % 10 == 0:\n",
    "            print(f\"\\n[{idx+1}/{len(benchmark_images)}] Processing: {image_name}\")\n",
    "        \n",
    "        # Get zero-shot prediction\n",
    "        answer = qwen_zeroshot_inference(image, question)\n",
    "        \n",
    "        zeroshot_results.append({\n",
    "            'image': image_name,\n",
    "            'question': question,\n",
    "            'answer': answer,\n",
    "            'ground_truth': benchmark_ground_truth.get(image_name, ''),\n",
    "            'context': ''  # No RAG context\n",
    "        })\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n✗ Error processing {image_name}: {e}\")\n",
    "        zeroshot_results.append({\n",
    "            'image': image_name,\n",
    "            'question': benchmark_questions.get(image_name, ''),\n",
    "            'answer': f'ERROR: {str(e)}',\n",
    "            'ground_truth': benchmark_ground_truth.get(image_name, ''),\n",
    "            'context': ''\n",
    "        })\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\" Completed Zero-shot inference on {len(zeroshot_results)} images\")\n",
    "print(f\"  - Successful: {sum(1 for r in zeroshot_results if 'ERROR' not in r['answer'])}\")\n",
    "print(f\"  - Errors: {sum(1 for r in zeroshot_results if 'ERROR' in r['answer'])}\")\n",
    "print(f\"{'='*80}\")\n",
    "\n",
    "# Save results\n",
    "output_json_zs = f\"{OUTPUT_DIR}/benchmark_inference_results_zeroshot.json\"\n",
    "with open(output_json_zs, 'w', encoding='utf-8') as f:\n",
    "    json.dump(zeroshot_results, f, ensure_ascii=False, indent=2)\n",
    "print(f\" Zero-shot results saved to {output_json_zs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14.4. Giải phóng bộ nhớ Qwen Zero-shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-03T16:08:16.663225Z",
     "iopub.status.busy": "2026-01-03T16:08:16.663072Z",
     "iopub.status.idle": "2026-01-03T16:08:17.151241Z",
     "shell.execute_reply": "2026-01-03T16:08:17.150764Z",
     "shell.execute_reply.started": "2026-01-03T16:08:16.663210Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Đã giải phóng bộ nhớ Qwen Zero-shot\n"
     ]
    }
   ],
   "source": [
    "# Giải phóng Qwen Zero-shot model\n",
    "del qwen_zeroshot_model\n",
    "del qwen_zeroshot_processor\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "print(\" Đã giải phóng bộ nhớ Qwen Zero-shot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15. Định nghĩa các hàm tính metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-03T16:26:03.864810Z",
     "iopub.status.busy": "2026-01-03T16:26:03.864574Z",
     "iopub.status.idle": "2026-01-03T16:26:05.034333Z",
     "shell.execute_reply": "2026-01-03T16:26:05.033746Z",
     "shell.execute_reply.started": "2026-01-03T16:26:03.864793Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bert_score in /usr/local/lib/python3.12/dist-packages (0.3.13)\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement rough_score (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for rough_score\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install bert_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-03T16:26:32.735908Z",
     "iopub.status.busy": "2026-01-03T16:26:32.735667Z",
     "iopub.status.idle": "2026-01-03T16:26:36.538730Z",
     "shell.execute_reply": "2026-01-03T16:26:36.538193Z",
     "shell.execute_reply.started": "2026-01-03T16:26:32.735890Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rouge_score\n",
      "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: absl-py in /usr/local/lib/python3.12/dist-packages (from rouge_score) (1.4.0)\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (from rouge_score) (3.9.2)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from rouge_score) (2.0.2)\n",
      "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.12/dist-packages (from rouge_score) (1.17.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk->rouge_score) (8.3.1)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk->rouge_score) (1.5.3)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk->rouge_score) (2025.11.3)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk->rouge_score) (4.67.1)\n",
      "Building wheels for collected packages: rouge_score\n",
      "  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24934 sha256=8dc91322573104bfe2ee3e649367e00f74a043e93450f791b8bc2b0cb1acbd40\n",
      "  Stored in directory: /root/.cache/pip/wheels/85/9d/af/01feefbe7d55ef5468796f0c68225b6788e85d9d0a281e7a70\n",
      "Successfully built rouge_score\n",
      "Installing collected packages: rouge_score\n",
      "Successfully installed rouge_score-0.1.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install rouge_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-03T16:26:42.279385Z",
     "iopub.status.busy": "2026-01-03T16:26:42.279149Z",
     "iopub.status.idle": "2026-01-03T16:26:42.295597Z",
     "shell.execute_reply": "2026-01-03T16:26:42.295158Z",
     "shell.execute_reply.started": "2026-01-03T16:26:42.279364Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Đã định nghĩa các hàm tính metrics:\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from bert_score import score as bert_score\n",
    "from rouge_score import rouge_scorer\n",
    "import re\n",
    "\n",
    "def compute_bertscore(predictions, references, lang='vi'):\n",
    "    \"\"\"\n",
    "    Compute BERTScore for Vietnamese text\n",
    "    \n",
    "    Args:\n",
    "        predictions: List of predicted answers\n",
    "        references: List of reference answers\n",
    "        lang: Language code ('vi' for Vietnamese)\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with P, R, F1 scores\n",
    "    \"\"\"\n",
    "    # Check for empty lists\n",
    "    if not predictions or not references:\n",
    "        print(f\"WARNING: Empty list detected - predictions: {len(predictions) if predictions else 0}, references: {len(references) if references else 0}\")\n",
    "        return {\n",
    "            'precision': 0.0,\n",
    "            'recall': 0.0,\n",
    "            'f1': 0.0,\n",
    "            'precision_std': 0.0,\n",
    "            'recall_std': 0.0,\n",
    "            'f1_std': 0.0,\n",
    "            'individual_f1': []\n",
    "        }\n",
    "    \n",
    "    # BERTScore với multilingual model\n",
    "    P, R, F1 = bert_score(\n",
    "        predictions, \n",
    "        references, \n",
    "        lang=lang,\n",
    "        verbose=True\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        'precision': P.mean().item(),\n",
    "        'recall': R.mean().item(),\n",
    "        'f1': F1.mean().item(),\n",
    "        'precision_std': P.std().item(),\n",
    "        'recall_std': R.std().item(),\n",
    "        'f1_std': F1.std().item(),\n",
    "        'individual_f1': F1.tolist()\n",
    "    }\n",
    "\n",
    "def compute_rouge_l(predictions, references):\n",
    "    \"\"\"\n",
    "    Compute ROUGE-L score\n",
    "    \n",
    "    Args:\n",
    "        predictions: List of predicted answers\n",
    "        references: List of reference answers\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with ROUGE-L scores\n",
    "    \"\"\"\n",
    "    # Check for empty lists\n",
    "    if not predictions or not references:\n",
    "        print(f\"WARNING: Empty list detected - predictions: {len(predictions) if predictions else 0}, references: {len(references) if references else 0}\")\n",
    "        return {\n",
    "            'precision': 0.0,\n",
    "            'recall': 0.0,\n",
    "            'f1': 0.0,\n",
    "            'precision_std': 0.0,\n",
    "            'recall_std': 0.0,\n",
    "            'f1_std': 0.0,\n",
    "            'individual_f1': []\n",
    "        }\n",
    "    \n",
    "    scorer = rouge_scorer.RougeScorer(['rougeL'], use_stemmer=False)\n",
    "    \n",
    "    scores = []\n",
    "    for pred, ref in zip(predictions, references):\n",
    "        # Compute score for each pair\n",
    "        score = scorer.score(ref, pred)\n",
    "        scores.append({\n",
    "            'precision': score['rougeL'].precision,\n",
    "            'recall': score['rougeL'].recall,\n",
    "            'fmeasure': score['rougeL'].fmeasure\n",
    "        })\n",
    "    \n",
    "    # Aggregate scores\n",
    "    avg_precision = np.mean([s['precision'] for s in scores])\n",
    "    avg_recall = np.mean([s['recall'] for s in scores])\n",
    "    avg_fmeasure = np.mean([s['fmeasure'] for s in scores])\n",
    "    \n",
    "    return {\n",
    "        'precision': avg_precision,\n",
    "        'recall': avg_recall,\n",
    "        'f1': avg_fmeasure,\n",
    "        'precision_std': np.std([s['precision'] for s in scores]),\n",
    "        'recall_std': np.std([s['recall'] for s in scores]),\n",
    "        'f1_std': np.std([s['fmeasure'] for s in scores]),\n",
    "        'individual_f1': [s['fmeasure'] for s in scores]\n",
    "    }\n",
    "\n",
    "def compute_faithfulness(predictions, contexts):\n",
    "    \"\"\"\n",
    "    Compute Faithfulness score - đo mức độ answer dựa trên context\n",
    "    \n",
    "    Faithfulness = số lượng claims trong answer có thể verify từ context / tổng số claims\n",
    "    \n",
    "    Simplified version: Đo overlap của n-grams giữa answer và context\n",
    "    \n",
    "    Args:\n",
    "        predictions: List of predicted answers\n",
    "        contexts: List of contexts used for generation\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with faithfulness scores\n",
    "    \"\"\"\n",
    "    # Check for empty lists\n",
    "    if not predictions or not contexts:\n",
    "        print(f\"WARNING: Empty list detected - predictions: {len(predictions) if predictions else 0}, contexts: {len(contexts) if contexts else 0}\")\n",
    "        return {\n",
    "            'mean': 0.0,\n",
    "            'std': 0.0,\n",
    "            'individual': []\n",
    "        }\n",
    "    \n",
    "    def tokenize(text):\n",
    "        \"\"\"Simple tokenization\"\"\"\n",
    "        if not text:\n",
    "            return []\n",
    "        # Remove punctuation and lowercase\n",
    "        text = re.sub(r'[^\\w\\s]', ' ', text.lower())\n",
    "        return text.split()\n",
    "    \n",
    "    def get_ngrams(tokens, n):\n",
    "        \"\"\"Get n-grams from tokens\"\"\"\n",
    "        if len(tokens) < n:\n",
    "            return set()\n",
    "        return set([' '.join(tokens[i:i+n]) for i in range(len(tokens)-n+1)])\n",
    "    \n",
    "    def compute_overlap(answer, context, n=2):\n",
    "        \"\"\"Compute n-gram overlap ratio\"\"\"\n",
    "        answer_tokens = tokenize(answer)\n",
    "        context_tokens = tokenize(context)\n",
    "        \n",
    "        if not answer_tokens:\n",
    "            return 0.0\n",
    "        \n",
    "        answer_ngrams = get_ngrams(answer_tokens, n)\n",
    "        context_ngrams = get_ngrams(context_tokens, n)\n",
    "        \n",
    "        if not answer_ngrams:\n",
    "            return 0.0\n",
    "        \n",
    "        overlap = answer_ngrams.intersection(context_ngrams)\n",
    "        return len(overlap) / len(answer_ngrams)\n",
    "    \n",
    "    scores = []\n",
    "    for pred, ctx in zip(predictions, contexts):\n",
    "        if not ctx or ctx == 'None' or 'không tìm thấy' in ctx.lower():\n",
    "            # Nếu không có context, không thể đánh giá faithfulness\n",
    "            scores.append(0.0)\n",
    "        else:\n",
    "            # Compute overlap với bigrams và trigrams\n",
    "            bigram_overlap = compute_overlap(pred, ctx, n=2)\n",
    "            trigram_overlap = compute_overlap(pred, ctx, n=3)\n",
    "            # Average\n",
    "            scores.append((bigram_overlap + trigram_overlap) / 2)\n",
    "    \n",
    "    return {\n",
    "        'mean': np.mean(scores),\n",
    "        'std': np.std(scores),\n",
    "        'individual': scores\n",
    "    }\n",
    "\n",
    "print(\" Đã định nghĩa các hàm tính metrics:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16. Chuẩn bị dữ liệu để so sánh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-03T16:26:53.626377Z",
     "iopub.status.busy": "2026-01-03T16:26:53.626144Z",
     "iopub.status.idle": "2026-01-03T16:26:53.638295Z",
     "shell.execute_reply": "2026-01-03T16:26:53.637791Z",
     "shell.execute_reply.started": "2026-01-03T16:26:53.626356Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Ground truth available: 60 samples\n",
      "\n",
      "Debug - Number of results per model:\n",
      "  - Fine-tuned: 60\n",
      "  - Base: 60\n",
      "  - Zero-shot: 60\n",
      "  - Ground truth: 60\n",
      "\n",
      "Debug - Valid (non-ERROR) results per model:\n",
      "  - Fine-tuned: 60/60\n",
      "  - Base: 60/60\n",
      "  - Zero-shot: 60/60\n",
      "\n",
      "Số lượng images chung: 60\n",
      "Số lượng images valid (không có lỗi): 60\n",
      "\n",
      "============================================================\n",
      "Đã chuẩn bị dữ liệu cho 3 MODELS:\n",
      "============================================================\n",
      "  - RAG + Fine-tuned answers: 60\n",
      "  - RAG + Base answers: 60\n",
      "  - Qwen2-VL-7B Zero-shot answers: 60\n",
      "  - Ground truth answers: 60\n"
     ]
    }
   ],
   "source": [
    "# Ground truth đã được load từ đầu (benchmark_ground_truth)\n",
    "print(f\" Ground truth available: {len(benchmark_ground_truth)} samples\")\n",
    "\n",
    "# Match by image name - tạo dict cho 3 models\n",
    "finetuned_dict = {r['image']: r for r in finetuned_results}\n",
    "base_dict = {r['image']: r for r in base_results}\n",
    "zeroshot_dict = {r['image']: r for r in zeroshot_results}\n",
    "\n",
    "# Debug: Print number of results from each model\n",
    "print(f\"\\nDebug - Number of results per model:\")\n",
    "print(f\"  - Fine-tuned: {len(finetuned_dict)}\")\n",
    "print(f\"  - Base: {len(base_dict)}\")\n",
    "print(f\"  - Zero-shot: {len(zeroshot_dict)}\")\n",
    "print(f\"  - Ground truth: {len(benchmark_ground_truth)}\")\n",
    "\n",
    "# Check how many valid (non-ERROR) results each model has\n",
    "def count_valid_results(model_dict):\n",
    "    return sum(1 for r in model_dict.values() if 'ERROR' not in r.get('answer', 'ERROR'))\n",
    "\n",
    "ft_valid = count_valid_results(finetuned_dict)\n",
    "base_valid = count_valid_results(base_dict)\n",
    "zs_valid = count_valid_results(zeroshot_dict)\n",
    "\n",
    "print(f\"\\nDebug - Valid (non-ERROR) results per model:\")\n",
    "print(f\"  - Fine-tuned: {ft_valid}/{len(finetuned_dict)}\")\n",
    "print(f\"  - Base: {base_valid}/{len(base_dict)}\")\n",
    "print(f\"  - Zero-shot: {zs_valid}/{len(zeroshot_dict)}\")\n",
    "\n",
    "# Get common images (3 models + ground truth)\n",
    "common_images = (set(finetuned_dict.keys()) & set(base_dict.keys()) & \n",
    "                 set(zeroshot_dict.keys()) & set(benchmark_ground_truth.keys()))\n",
    "\n",
    "print(f\"\\nSố lượng images chung: {len(common_images)}\")\n",
    "\n",
    "# Filter out ERROR results\n",
    "valid_images = []\n",
    "skipped_count = {'finetuned': 0, 'base': 0, 'zeroshot': 0}\n",
    "\n",
    "for img in common_images:\n",
    "    has_error = False\n",
    "    \n",
    "    if 'ERROR' in finetuned_dict[img]['answer']:\n",
    "        has_error = True\n",
    "        skipped_count['finetuned'] += 1\n",
    "    if 'ERROR' in base_dict[img]['answer']:\n",
    "        has_error = True\n",
    "        skipped_count['base'] += 1\n",
    "    if 'ERROR' in zeroshot_dict[img]['answer']:\n",
    "        has_error = True\n",
    "        skipped_count['zeroshot'] += 1\n",
    "    \n",
    "    if not has_error:\n",
    "        valid_images.append(img)\n",
    "\n",
    "valid_images = sorted(valid_images)\n",
    "print(f\"Số lượng images valid (không có lỗi): {len(valid_images)}\")\n",
    "\n",
    "if any(skipped_count.values()):\n",
    "    print(f\"\\nSkipped images by model:\")\n",
    "    for model, count in skipped_count.items():\n",
    "        if count > 0:\n",
    "            print(f\"  - {model}: {count} images with ERROR\")\n",
    "\n",
    "# Check if valid_images is empty\n",
    "if len(valid_images) == 0:\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"ERROR: No valid images found for evaluation!\")\n",
    "    print(\"=\"*80)\n",
    "    raise ValueError(\"No valid images found for evaluation.\")\n",
    "\n",
    "# Prepare lists for comparison (3 models only)\n",
    "finetuned_answers = [finetuned_dict[img]['answer'] for img in valid_images]\n",
    "base_answers = [base_dict[img]['answer'] for img in valid_images]\n",
    "zeroshot_answers = [zeroshot_dict[img]['answer'] for img in valid_images]\n",
    "ground_truth_answers = [benchmark_ground_truth[img] for img in valid_images]\n",
    "\n",
    "# Contexts\n",
    "finetuned_contexts = [finetuned_dict[img].get('context', '') for img in valid_images]\n",
    "base_contexts = [base_dict[img].get('context', '') for img in valid_images]\n",
    "zeroshot_contexts = ['' for _ in valid_images]\n",
    "\n",
    "questions = [benchmark_questions[img] for img in valid_images]\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"Đã chuẩn bị dữ liệu cho 3 MODELS:\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"  - RAG + Fine-tuned answers: {len(finetuned_answers)}\")\n",
    "print(f\"  - RAG + Base answers: {len(base_answers)}\")\n",
    "print(f\"  - Qwen2-VL-7B Zero-shot answers: {len(zeroshot_answers)}\")\n",
    "print(f\"  - Ground truth answers: {len(ground_truth_answers)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 17. Tính BERTScore\n",
    "\n",
    "So sánh answers của **3 MODELS** với **Ground Truth**:\n",
    "1. RAG Pipeline + Fine-tuned Qwen2-VL-2B\n",
    "2. RAG Pipeline + Base Qwen2-VL-2B\n",
    "3. Qwen2-VL-2B Zero-shot (không RAG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-03T16:26:53.639288Z",
     "iopub.status.busy": "2026-01-03T16:26:53.639130Z",
     "iopub.status.idle": "2026-01-03T16:26:58.662400Z",
     "shell.execute_reply": "2026-01-03T16:26:58.661971Z",
     "shell.execute_reply.started": "2026-01-03T16:26:53.639272Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "COMPUTING BERTScore (so với Ground Truth) - 3 MODELS\n",
      "================================================================================\n",
      "\n",
      "1. BERTScore: RAG + Fine-tuned vs Ground Truth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a0447f7e7c0417284fc04a49e3070cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3f91002d9964149a9fb13e64697959c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/625 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5083f5065ff4eefad48c8ba52035786",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/996k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee3642625b16498398afa42e6241a3bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.96M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fce65e9e98054b6f89175c0f64af1728",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/714M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b826d1f36e1049938b8f0197731c9160",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79950ce1064e40b89d7bfa2e39d4a982",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.32 seconds, 188.62 sentences/sec\n",
      "   F1: 0.7415 ± 0.0301\n",
      "\n",
      "2. BERTScore: RAG + Base vs Ground Truth\n",
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af3f7625d5a945f781f296fc8ea192a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "217a6579eae24983b8a4635b05ed4639",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.28 seconds, 216.88 sentences/sec\n",
      "   F1: 0.7179 ± 0.0301\n",
      "\n",
      "3. BERTScore: Qwen2-VL-7B Zero-shot vs Ground Truth\n",
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f09ca1d21a4d4cf9998951995d0c37ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57ea0c5b568746ddabeeb214f11bd1e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.28 seconds, 214.96 sentences/sec\n",
      "   F1: 0.7125 ± 0.0500\n",
      "\n",
      "================================================================================\n",
      "BERTScore F1 RANKING:\n",
      "================================================================================\n",
      "  1. RAG + Fine-tuned: 0.7415\n",
      "  2. RAG + Base: 0.7179\n",
      "  3. Qwen2-VL-7B Zero-shot: 0.7125\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"COMPUTING BERTScore (so với Ground Truth) - 3 MODELS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# 1. BERTScore: RAG + Fine-tuned vs Ground Truth\n",
    "print(\"\\n1. BERTScore: RAG + Fine-tuned vs Ground Truth\")\n",
    "bertscore_ft_gt = compute_bertscore(finetuned_answers, ground_truth_answers, lang='vi')\n",
    "print(f\"   F1: {bertscore_ft_gt['f1']:.4f} ± {bertscore_ft_gt['f1_std']:.4f}\")\n",
    "\n",
    "# 2. BERTScore: RAG + Base vs Ground Truth\n",
    "print(\"\\n2. BERTScore: RAG + Base vs Ground Truth\")\n",
    "bertscore_base_gt = compute_bertscore(base_answers, ground_truth_answers, lang='vi')\n",
    "print(f\"   F1: {bertscore_base_gt['f1']:.4f} ± {bertscore_base_gt['f1_std']:.4f}\")\n",
    "\n",
    "# 3. BERTScore: Zero-shot vs Ground Truth\n",
    "print(\"\\n3. BERTScore: Qwen2-VL-7B Zero-shot vs Ground Truth\")\n",
    "bertscore_zs_gt = compute_bertscore(zeroshot_answers, ground_truth_answers, lang='vi')\n",
    "print(f\"   F1: {bertscore_zs_gt['f1']:.4f} ± {bertscore_zs_gt['f1_std']:.4f}\")\n",
    "\n",
    "# Summary ranking\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"BERTScore F1 RANKING:\")\n",
    "print(\"=\"*80)\n",
    "bert_rankings = [\n",
    "    ('RAG + Fine-tuned', bertscore_ft_gt['f1']),\n",
    "    ('RAG + Base', bertscore_base_gt['f1']),\n",
    "    ('Qwen2-VL-7B Zero-shot', bertscore_zs_gt['f1']),\n",
    "]\n",
    "\n",
    "bert_rankings.sort(key=lambda x: x[1], reverse=True)\n",
    "for i, (name, score) in enumerate(bert_rankings, 1):\n",
    "    print(f\"  {i}. {name}: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 18. Tính ROUGE-L Score\n",
    "\n",
    "So sánh answers của **3 MODELS** với **Ground Truth** sử dụng ROUGE-L."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-03T16:26:58.663193Z",
     "iopub.status.busy": "2026-01-03T16:26:58.663040Z",
     "iopub.status.idle": "2026-01-03T16:26:59.337816Z",
     "shell.execute_reply": "2026-01-03T16:26:59.337384Z",
     "shell.execute_reply.started": "2026-01-03T16:26:58.663177Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "COMPUTING ROUGE-L Score (so với Ground Truth) - 3 MODELS\n",
      "================================================================================\n",
      "\n",
      "1. ROUGE-L: RAG + Fine-tuned vs Ground Truth\n",
      "\n",
      "   Fine-tuned vs. Ground Truth:\n",
      "   Precision: 0.4074 ± 0.0736\n",
      "   Recall:    0.3394 ± 0.0538\n",
      "   F1:        0.3641 ± 0.0379\n",
      "\n",
      "2. ROUGE-L: RAG + Base vs Ground Truth\n",
      "\n",
      "   Base vs. Ground Truth:\n",
      "   Precision: 0.2497 ± 0.0564\n",
      "   Recall:    0.4628 ± 0.0954\n",
      "   F1:        0.3158 ± 0.0466\n",
      "\n",
      "3. ROUGE-L: Qwen2-VL-2B Zero-shot vs Ground Truth\n",
      "\n",
      "   Zero-shot vs. Ground Truth:\n",
      "   Precision: 0.4611 ± 0.1438\n",
      "   Recall:    0.2815 ± 0.1098\n",
      "   F1:        0.3161 ± 0.0662\n",
      "\n",
      "================================================================================\n",
      "ROUGE-L F1 RANKING:\n",
      "================================================================================\n",
      "  1. RAG + Fine-tuned: 0.3641\n",
      "  2. Qwen2-VL-2B Zero-shot: 0.3161\n",
      "  3. RAG + Base: 0.3158\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"COMPUTING ROUGE-L Score (so với Ground Truth) - 3 MODELS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# ROUGE-L: Fine-tuned vs Ground Truth\n",
    "print(\"\\n1. ROUGE-L: RAG + Fine-tuned vs Ground Truth\")\n",
    "rouge_ft_gt = compute_rouge_l(finetuned_answers, ground_truth_answers)\n",
    "\n",
    "print(f\"\\n   Fine-tuned vs. Ground Truth:\")\n",
    "print(f\"   Precision: {rouge_ft_gt['precision']:.4f} ± {rouge_ft_gt['precision_std']:.4f}\")\n",
    "print(f\"   Recall:    {rouge_ft_gt['recall']:.4f} ± {rouge_ft_gt['recall_std']:.4f}\")\n",
    "print(f\"   F1:        {rouge_ft_gt['f1']:.4f} ± {rouge_ft_gt['f1_std']:.4f}\")\n",
    "\n",
    "# ROUGE-L: Base vs Ground Truth\n",
    "print(\"\\n2. ROUGE-L: RAG + Base vs Ground Truth\")\n",
    "rouge_base_gt = compute_rouge_l(base_answers, ground_truth_answers)\n",
    "\n",
    "print(f\"\\n   Base vs. Ground Truth:\")\n",
    "print(f\"   Precision: {rouge_base_gt['precision']:.4f} ± {rouge_base_gt['precision_std']:.4f}\")\n",
    "print(f\"   Recall:    {rouge_base_gt['recall']:.4f} ± {rouge_base_gt['recall_std']:.4f}\")\n",
    "print(f\"   F1:        {rouge_base_gt['f1']:.4f} ± {rouge_base_gt['f1_std']:.4f}\")\n",
    "\n",
    "# ROUGE-L: Zero-shot vs Ground Truth\n",
    "print(\"\\n3. ROUGE-L: Qwen2-VL-2B Zero-shot vs Ground Truth\")\n",
    "rouge_zs_gt = compute_rouge_l(zeroshot_answers, ground_truth_answers)\n",
    "\n",
    "print(f\"\\n   Zero-shot vs. Ground Truth:\")\n",
    "print(f\"   Precision: {rouge_zs_gt['precision']:.4f} ± {rouge_zs_gt['precision_std']:.4f}\")\n",
    "print(f\"   Recall:    {rouge_zs_gt['recall']:.4f} ± {rouge_zs_gt['recall_std']:.4f}\")\n",
    "print(f\"   F1:        {rouge_zs_gt['f1']:.4f} ± {rouge_zs_gt['f1_std']:.4f}\")\n",
    "\n",
    "# Summary ranking\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ROUGE-L F1 RANKING:\")\n",
    "print(\"=\"*80)\n",
    "rouge_rankings = [\n",
    "    ('RAG + Fine-tuned', rouge_ft_gt['f1']),\n",
    "    ('RAG + Base', rouge_base_gt['f1']),\n",
    "    ('Qwen2-VL-2B Zero-shot', rouge_zs_gt['f1']),\n",
    "]\n",
    "\n",
    "rouge_rankings.sort(key=lambda x: x[1], reverse=True)\n",
    "for i, (name, score) in enumerate(rouge_rankings, 1):\n",
    "    print(f\"  {i}. {name}: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 19. Tính Faithfulness Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-03T16:26:59.338980Z",
     "iopub.status.busy": "2026-01-03T16:26:59.338804Z",
     "iopub.status.idle": "2026-01-03T16:26:59.367230Z",
     "shell.execute_reply": "2026-01-03T16:26:59.366823Z",
     "shell.execute_reply.started": "2026-01-03T16:26:59.338964Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "COMPUTING Faithfulness Score\n",
      "================================================================================\n",
      "\n",
      "Faithfulness đo mức độ answer dựa trên retrieved context\n",
      "(Score cao = answer sử dụng nhiều thông tin từ context)\n",
      "\n",
      "1. Fine-tuned Model Faithfulness:\n",
      "   Mean: 0.0138 ± 0.0157\n",
      "\n",
      "2. Base Model Faithfulness:\n",
      "   Mean: 0.0114 ± 0.0096\n",
      "\n",
      "3. Comparison:\n",
      "   Fine-tuned model có Faithfulness CAO HƠN: +0.0024\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"COMPUTING Faithfulness Score\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nFaithfulness đo mức độ answer dựa trên retrieved context\")\n",
    "print(\"(Score cao = answer sử dụng nhiều thông tin từ context)\")\n",
    "\n",
    "# Faithfulness: Fine-tuned\n",
    "faith_ft = compute_faithfulness(finetuned_answers, finetuned_contexts)\n",
    "print(f\"\\n1. Fine-tuned Model Faithfulness:\")\n",
    "print(f\"   Mean: {faith_ft['mean']:.4f} ± {faith_ft['std']:.4f}\")\n",
    "\n",
    "# Faithfulness: Base\n",
    "faith_base = compute_faithfulness(base_answers, base_contexts)\n",
    "print(f\"\\n2. Base Model Faithfulness:\")\n",
    "print(f\"   Mean: {faith_base['mean']:.4f} ± {faith_base['std']:.4f}\")\n",
    "\n",
    "# Comparison\n",
    "print(f\"\\n3. Comparison:\")\n",
    "diff = faith_ft['mean'] - faith_base['mean']\n",
    "if diff > 0:\n",
    "    print(f\"   Fine-tuned model có Faithfulness CAO HƠN: +{diff:.4f}\")\n",
    "else:\n",
    "    print(f\"   Base model có Faithfulness CAO HƠN: {abs(diff):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 20. Tổng hợp kết quả so sánh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-03T16:26:59.367958Z",
     "iopub.status.busy": "2026-01-03T16:26:59.367807Z",
     "iopub.status.idle": "2026-01-03T16:26:59.409252Z",
     "shell.execute_reply": "2026-01-03T16:26:59.408805Z",
     "shell.execute_reply.started": "2026-01-03T16:26:59.367944Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "TỔNG HỢP KẾT QUẢ SO SÁNH - 3 MODELS\n",
      "================================================================================\n",
      "\n",
      "\n",
      "                   Metric RAG + Fine-tuned      RAG + Base        Zero-shot\n",
      "     BERTScore F1 (vs GT)  0.7415 ± 0.0301 0.7179 ± 0.0301  0.7125 ± 0.0500\n",
      "       ROUGE-L F1 (vs GT)  0.3641 ± 0.0379 0.3158 ± 0.0466  0.3161 ± 0.0662\n",
      "Faithfulness (vs Context)  0.0138 ± 0.0157 0.0114 ± 0.0096 N/A (no context)\n",
      "\n",
      "================================================================================\n",
      "RANKING BY METRIC\n",
      "================================================================================\n",
      "\n",
      "BERTScore F1:\n",
      "  1. RAG + Fine-tuned: 0.7415\n",
      "  2. RAG + Base: 0.7179\n",
      "  3. Zero-shot: 0.7125\n",
      "\n",
      "ROUGE-L F1:\n",
      "  1. RAG + Fine-tuned: 0.3641\n",
      "  2. Zero-shot: 0.3161\n",
      "  3. RAG + Base: 0.3158\n",
      "\n",
      "Faithfulness (RAG models only):\n",
      "  1. RAG + Fine-tuned: 0.0138\n",
      "  2. RAG + Base: 0.0114\n",
      "\n",
      "================================================================================\n",
      "FINAL VERDICT\n",
      "================================================================================\n",
      " BERTScore: RAG + Fine-tuned WINS (0.7415)\n",
      " ROUGE-L: RAG + Fine-tuned WINS (0.3641)\n",
      " Faithfulness: RAG + Fine-tuned WINS (0.0138)\n",
      "\n",
      "================================================================================\n",
      " OVERALL WINNER: RAG + Fine-tuned (3/3 metrics)\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"TỔNG HỢP KẾT QUẢ SO SÁNH - 3 MODELS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Create comparison table for 3 models\n",
    "comparison_data = {\n",
    "    'Metric': [\n",
    "        'BERTScore F1 (vs GT)',\n",
    "        'ROUGE-L F1 (vs GT)',\n",
    "        'Faithfulness (vs Context)'\n",
    "    ],\n",
    "    'RAG + Fine-tuned': [\n",
    "        f\"{bertscore_ft_gt['f1']:.4f} ± {bertscore_ft_gt['f1_std']:.4f}\",\n",
    "        f\"{rouge_ft_gt['f1']:.4f} ± {rouge_ft_gt['f1_std']:.4f}\",\n",
    "        f\"{faith_ft['mean']:.4f} ± {faith_ft['std']:.4f}\"\n",
    "    ],\n",
    "    'RAG + Base': [\n",
    "        f\"{bertscore_base_gt['f1']:.4f} ± {bertscore_base_gt['f1_std']:.4f}\",\n",
    "        f\"{rouge_base_gt['f1']:.4f} ± {rouge_base_gt['f1_std']:.4f}\",\n",
    "        f\"{faith_base['mean']:.4f} ± {faith_base['std']:.4f}\"\n",
    "    ],\n",
    "    'Zero-shot': [\n",
    "        f\"{bertscore_zs_gt['f1']:.4f} ± {bertscore_zs_gt['f1_std']:.4f}\",\n",
    "        f\"{rouge_zs_gt['f1']:.4f} ± {rouge_zs_gt['f1_std']:.4f}\",\n",
    "        \"N/A (no context)\"  # Zero-shot không có context nên không tính Faithfulness\n",
    "    ]\n",
    "}\n",
    "\n",
    "df_comparison = pd.DataFrame(comparison_data)\n",
    "print(\"\\n\")\n",
    "print(df_comparison.to_string(index=False))\n",
    "\n",
    "# Summary ranking for each metric\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RANKING BY METRIC\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# BERTScore ranking\n",
    "bert_scores = [\n",
    "    ('RAG + Fine-tuned', bertscore_ft_gt['f1']),\n",
    "    ('RAG + Base', bertscore_base_gt['f1']),\n",
    "    ('Zero-shot', bertscore_zs_gt['f1'])\n",
    "]\n",
    "bert_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "print(\"\\nBERTScore F1:\")\n",
    "for i, (name, score) in enumerate(bert_scores, 1):\n",
    "    print(f\"  {i}. {name}: {score:.4f}\")\n",
    "\n",
    "# ROUGE-L ranking\n",
    "rouge_scores = [\n",
    "    ('RAG + Fine-tuned', rouge_ft_gt['f1']),\n",
    "    ('RAG + Base', rouge_base_gt['f1']),\n",
    "    ('Zero-shot', rouge_zs_gt['f1'])\n",
    "]\n",
    "rouge_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "print(\"\\nROUGE-L F1:\")\n",
    "for i, (name, score) in enumerate(rouge_scores, 1):\n",
    "    print(f\"  {i}. {name}: {score:.4f}\")\n",
    "\n",
    "# Faithfulness ranking (only RAG models)\n",
    "faith_scores = [\n",
    "    ('RAG + Fine-tuned', faith_ft['mean']),\n",
    "    ('RAG + Base', faith_base['mean'])\n",
    "]\n",
    "faith_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "print(\"\\nFaithfulness (RAG models only):\")\n",
    "for i, (name, score) in enumerate(faith_scores, 1):\n",
    "    print(f\"  {i}. {name}: {score:.4f}\")\n",
    "\n",
    "# Overall winner\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FINAL VERDICT\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Count wins across BERTScore and ROUGE-L\n",
    "model_wins = {'RAG + Fine-tuned': 0, 'RAG + Base': 0, 'Zero-shot': 0}\n",
    "\n",
    "# BERTScore winner\n",
    "if bertscore_ft_gt['f1'] >= bertscore_base_gt['f1'] and bertscore_ft_gt['f1'] >= bertscore_zs_gt['f1']:\n",
    "    model_wins['RAG + Fine-tuned'] += 1\n",
    "    print(f\" BERTScore: RAG + Fine-tuned WINS ({bertscore_ft_gt['f1']:.4f})\")\n",
    "elif bertscore_base_gt['f1'] >= bertscore_ft_gt['f1'] and bertscore_base_gt['f1'] >= bertscore_zs_gt['f1']:\n",
    "    model_wins['RAG + Base'] += 1\n",
    "    print(f\" BERTScore: RAG + Base WINS ({bertscore_base_gt['f1']:.4f})\")\n",
    "else:\n",
    "    model_wins['Zero-shot'] += 1\n",
    "    print(f\" BERTScore: Zero-shot WINS ({bertscore_zs_gt['f1']:.4f})\")\n",
    "\n",
    "# ROUGE-L winner\n",
    "if rouge_ft_gt['f1'] >= rouge_base_gt['f1'] and rouge_ft_gt['f1'] >= rouge_zs_gt['f1']:\n",
    "    model_wins['RAG + Fine-tuned'] += 1\n",
    "    print(f\" ROUGE-L: RAG + Fine-tuned WINS ({rouge_ft_gt['f1']:.4f})\")\n",
    "elif rouge_base_gt['f1'] >= rouge_ft_gt['f1'] and rouge_base_gt['f1'] >= rouge_zs_gt['f1']:\n",
    "    model_wins['RAG + Base'] += 1\n",
    "    print(f\" ROUGE-L: RAG + Base WINS ({rouge_base_gt['f1']:.4f})\")\n",
    "else:\n",
    "    model_wins['Zero-shot'] += 1\n",
    "    print(f\" ROUGE-L: Zero-shot WINS ({rouge_zs_gt['f1']:.4f})\")\n",
    "\n",
    "# Faithfulness winner (only RAG models)\n",
    "if faith_ft['mean'] > faith_base['mean']:\n",
    "    model_wins['RAG + Fine-tuned'] += 1\n",
    "    print(f\" Faithfulness: RAG + Fine-tuned WINS ({faith_ft['mean']:.4f})\")\n",
    "else:\n",
    "    model_wins['RAG + Base'] += 1\n",
    "    print(f\" Faithfulness: RAG + Base WINS ({faith_base['mean']:.4f})\")\n",
    "\n",
    "# Overall winner\n",
    "winner = max(model_wins, key=model_wins.get)\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\" OVERALL WINNER: {winner} ({model_wins[winner]}/3 metrics)\")\n",
    "print(f\"{'='*80}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 21. Visualize kết quả"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-03T16:26:59.409971Z",
     "iopub.status.busy": "2026-01-03T16:26:59.409823Z",
     "iopub.status.idle": "2026-01-03T16:26:59.918523Z",
     "shell.execute_reply": "2026-01-03T16:26:59.918067Z",
     "shell.execute_reply.started": "2026-01-03T16:26:59.409957Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1600x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Chart saved to /kaggle/working/results/model_comparison_chart_3models.png\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Prepare data for visualization - 3 MODELS\n",
    "metrics_names = ['BERTScore F1', 'ROUGE-L F1']\n",
    "ft_scores = [bertscore_ft_gt['f1'], rouge_ft_gt['f1']]\n",
    "base_scores = [bertscore_base_gt['f1'], rouge_base_gt['f1']]\n",
    "zs_scores = [bertscore_zs_gt['f1'], rouge_zs_gt['f1']]\n",
    "\n",
    "ft_stds = [bertscore_ft_gt['f1_std'], rouge_ft_gt['f1_std']]\n",
    "base_stds = [bertscore_base_gt['f1_std'], rouge_base_gt['f1_std']]\n",
    "zs_stds = [bertscore_zs_gt['f1_std'], rouge_zs_gt['f1_std']]\n",
    "\n",
    "# Create figure with 2 subplots\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Subplot 1: Bar chart comparison - 3 MODELS\n",
    "x = np.arange(len(metrics_names))\n",
    "width = 0.25\n",
    "\n",
    "bars1 = axes[0].bar(x - width, ft_scores, width, label='RAG + Fine-tuned', color='#2ecc71', yerr=ft_stds, capsize=4)\n",
    "bars2 = axes[0].bar(x, base_scores, width, label='RAG + Base', color='#3498db', yerr=base_stds, capsize=4)\n",
    "bars3 = axes[0].bar(x + width, zs_scores, width, label='Zero-shot', color='#e74c3c', yerr=zs_stds, capsize=4)\n",
    "\n",
    "axes[0].set_ylabel('Score')\n",
    "axes[0].set_title('So sánh Metrics: 3 Models vs Ground Truth')\n",
    "axes[0].set_xticks(x)\n",
    "axes[0].set_xticklabels(metrics_names)\n",
    "axes[0].legend(loc='lower right')\n",
    "axes[0].set_ylim(0, 1)\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar, score in zip(bars1, ft_scores):\n",
    "    axes[0].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.02, \n",
    "                 f'{score:.3f}', ha='center', va='bottom', fontsize=8)\n",
    "for bar, score in zip(bars2, base_scores):\n",
    "    axes[0].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.02, \n",
    "                 f'{score:.3f}', ha='center', va='bottom', fontsize=8)\n",
    "for bar, score in zip(bars3, zs_scores):\n",
    "    axes[0].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.02, \n",
    "                 f'{score:.3f}', ha='center', va='bottom', fontsize=8)\n",
    "\n",
    "# Subplot 2: Faithfulness comparison (only RAG models) + RAG improvement over Zero-shot\n",
    "# Show improvement of RAG models over Zero-shot baseline\n",
    "improvement_names = ['BERTScore\\n(FT vs ZS)', 'BERTScore\\n(Base vs ZS)', 'ROUGE-L\\n(FT vs ZS)', 'ROUGE-L\\n(Base vs ZS)', 'Faithfulness\\n(FT vs Base)']\n",
    "improvements = [\n",
    "    bertscore_ft_gt['f1'] - bertscore_zs_gt['f1'],  # Fine-tuned vs Zero-shot\n",
    "    bertscore_base_gt['f1'] - bertscore_zs_gt['f1'],  # Base vs Zero-shot\n",
    "    rouge_ft_gt['f1'] - rouge_zs_gt['f1'],  # Fine-tuned vs Zero-shot\n",
    "    rouge_base_gt['f1'] - rouge_zs_gt['f1'],  # Base vs Zero-shot\n",
    "    faith_ft['mean'] - faith_base['mean']  # Fine-tuned vs Base (Faithfulness)\n",
    "]\n",
    "\n",
    "colors = ['#2ecc71' if d > 0 else '#e74c3c' for d in improvements]\n",
    "bars4 = axes[1].bar(improvement_names, improvements, color=colors)\n",
    "axes[1].axhline(y=0, color='black', linestyle='-', linewidth=0.5)\n",
    "axes[1].set_ylabel('Improvement')\n",
    "axes[1].set_title('Improvement: RAG vs Zero-shot & Fine-tuned vs Base')\n",
    "axes[1].tick_params(axis='x', rotation=15)\n",
    "\n",
    "# Add value labels\n",
    "for bar, diff in zip(bars4, improvements):\n",
    "    va = 'bottom' if diff >= 0 else 'top'\n",
    "    axes[1].text(bar.get_x() + bar.get_width()/2, diff, \n",
    "                 f'{diff:+.4f}', ha='center', va=va, fontsize=9, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{OUTPUT_DIR}/model_comparison_chart_3models.png\", dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n✓ Chart saved to {OUTPUT_DIR}/model_comparison_chart_3models.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 22. Phân tích chi tiết từng sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-03T16:26:59.919302Z",
     "iopub.status.busy": "2026-01-03T16:26:59.919150Z",
     "iopub.status.idle": "2026-01-03T16:27:02.162695Z",
     "shell.execute_reply": "2026-01-03T16:27:02.162269Z",
     "shell.execute_reply.started": "2026-01-03T16:26:59.919287Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "TOP 5 SAMPLES: RAG + Fine-tuned performs BEST\n",
      "======================================================================\n",
      "\n",
      " Question: Hình tượng rồng được trang trí trên mũi thuyền trong bức ảnh này mang những ý nghĩa biểu trưng sâu s...\n",
      "   Ground Truth: Biểu tượng của sức mạnh, quyền uy và thịnh vượng. Trong văn hóa và tín ngưỡng Việt Nam, rồng là một linh vật thiêng liên...\n",
      "   Fine-tuned: Rồng là linh vật thiêng liêng, biểu tượng cho sức mạnh, quyền lực và sự may mắn.\n",
      "\n",
      "Trong văn hóa Việt, rồng là biểu tượng...\n",
      "   Base: Hình tượng rồng trên mũi thuyền tại bức ảnh này có nhiều ý nghĩa biểu tượng sâu sắc trong văn hóa Việt. Rồng thường được...\n",
      "   Zero-shot: Rồng là một biểu tượng quan trọng trong văn hóa và tín ngưỡng của người Việt Nam. Rồng được trang trí trên mũi thuyền có...\n",
      "   BERTScore: FT=0.8089, Base=0.7400, ZS=0.6387\n",
      "\n",
      " Question: Cây cột được trang trí bằng các hình cắt giấy và các vật phẩm sặc sỡ ở trung tâm bức ảnh có tên gọi ...\n",
      "   Ground Truth: Đây là một loại cột lễ hay cây nghi lễ quan trọng trong các nghi thức tín ngưỡng của người Dao Đỏ. Cây cột này được tran...\n",
      "   Fine-tuned: Đây là cây cột thần linh hoặc cây cờ, thường được làm từ gỗ và được trang hoàng cầu kỳ. Nó đóng vai trò trung tâm trong ...\n",
      "   Base: Trong bức ảnh, cây cột được gọi là \"cột rồng\" hoặc \"cột thần rồng\", đây là một phần quan trọng trong nghi lễ tôn giáo củ...\n",
      "   Zero-shot: Cây cột được trang trí bằng các hình cắt giấy và các vật phẩm sặc sỡ ở trung tâm bức ảnh có tên gọi là \"Cây cột của ngườ...\n",
      "   BERTScore: FT=0.8028, Base=0.7341, ZS=0.7736\n",
      "\n",
      " Question: Thị trấn cổ xuất hiện trong bức ảnh này có phải là Di sản Văn hóa Thế giới được UNESCO công nhận khô...\n",
      "   Ground Truth: Có, đây là Phố cổ Hội An, Di sản Văn hóa Thế giới được UNESCO công nhận vào năm 1999. Giá trị nổi bật toàn cầu của Hội A...\n",
      "   Fine-tuned: Có, đó là Hội An - Di sản Văn hoá thế giới.\n",
      "\n",
      "Bức ảnh chụp tại Hội An, một thị trấn cổ nằm ở tỉnh Quảng Nam, thuộc vùng m...\n",
      "   Base: Xin lỗi, nhưng tôi không thể trả lời câu hỏi của bạn vì không có đủ thông tin từ hình ảnh để xác định rằng thị trấn cổ t...\n",
      "   Zero-shot: Xin lỗi, nhưng tôi không thể trả lời câu hỏi này vì tôi không có thông tin về bức ảnh cụ thể mà bạn đang nói. Bạn nên ki...\n",
      "   BERTScore: FT=0.7970, Base=0.6795, ZS=0.6243\n",
      "\n",
      " Question: Công trình kiến trúc tôn giáo nổi bật trong ảnh có tên gọi chính thức là gì và đã được Giáo hội Công...\n",
      "   Ground Truth: Nhà thờ Chính tòa Đức Bà Sài Gòn. Tên gọi chính thức của công trình là Vương cung thánh đường Chính tòa Đức Mẹ Vô Nhiễm ...\n",
      "   Fine-tuned: Nhà thờ Đức Bà Sài Gòn - Thánh thất Sài Gòn\n",
      "\n",
      "Đây là Nhà thờ Đức Bà, còn được biết đến với tên gọi Thánh thất Sài Gòn. Nó...\n",
      "   Base: Công trình kiến trúc nổi bật trong hình ảnh này là Nhà thờ Đức Bà Sài Gòn. Đây là một trong những công trình kiến trúc t...\n",
      "   Zero-shot: Công trình kiến trúc tôn giáo nổi bật trong ảnh là Nhà thờ Đức Bà Saigon, còn được gọi là Nhà thờ Đức Bà. Nó đã được Giá...\n",
      "   BERTScore: FT=0.7872, Base=0.7513, ZS=0.7368\n",
      "\n",
      " Question: Nghệ thuật múa rối nước, loại hình biểu diễn dân gian được thể hiện trong bức ảnh, có nguồn gốc từ k...\n",
      "   Ground Truth: Múa rối nước. Loại hình nghệ thuật này đã xuất hiện từ khoảng thế kỷ XI, dưới thời nhà Lý, và gắn liền mật thiết với nền...\n",
      "   Fine-tuned: Năm 1684; phản ánh đời sống nông nghiệp và tín ngưỡng dân gian.\n",
      "\n",
      "Múa rối nước xuất hiện đầu tiên ở Việt Nam năm 1668, nh...\n",
      "   Base: Nghệ thuật múa quay nước, loại biểu diễn dân dã được thể hiện ở bức ảnh này có nguồn gốc rất lâu đời tại Việt Nam. Theo ...\n",
      "   Zero-shot: Câu hỏi này không có đáp án chính xác vì nó liên quan đến nghệ thuật múa rối nước mà không có thông tin cụ thể về nguồn ...\n",
      "   BERTScore: FT=0.7864, Base=0.7393, ZS=0.7068\n",
      "\n",
      "======================================================================\n",
      "TOP 5 SAMPLES: Fine-tuned >> Base (biggest fine-tuning gain)\n",
      "======================================================================\n",
      "\n",
      " Question: Thị trấn cổ xuất hiện trong bức ảnh này có phải là Di sản Văn hóa Thế giới được UNESCO công nhận khô...\n",
      "   Ground Truth: Có, đây là Phố cổ Hội An, Di sản Văn hóa Thế giới được UNESCO công nhận vào năm 1999. Giá trị nổi bật toàn cầu của Hội A...\n",
      "   Fine-tuned: Có, đó là Hội An - Di sản Văn hoá thế giới.\n",
      "\n",
      "Bức ảnh chụp tại Hội An, một thị trấn cổ nằm ở tỉnh Quảng Nam, thuộc vùng m...\n",
      "   Base: Xin lỗi, nhưng tôi không thể trả lời câu hỏi của bạn vì không có đủ thông tin từ hình ảnh để xác định rằng thị trấn cổ t...\n",
      "   Improvement: FT=0.7970, Base=0.6795, Diff=+0.1175\n",
      "\n",
      " Question: Dựa trên các đặc điểm trong ảnh, chiếc khăn này có tên gọi phổ biến trong văn hóa Việt Nam là gì và ...\n",
      "   Ground Truth: Chiếc khăn trong ảnh được gọi là khăn rằn. Đây là một biểu tượng văn hóa đặc trưng của người dân Nam Bộ Việt Nam, đặc bi...\n",
      "   Fine-tuned: Khăn lụa\n",
      "\n",
      "Chiếc khăn trong ảnh có vẻ là khăn lụа, một loại vật dụng quen thuộc trong nhiều vùng miền Việt Nam.  Tuy nhiê...\n",
      "   Base: The image shows a red and white striped scarf that is placed on a white table. There are three different images of how t...\n",
      "   Improvement: FT=0.7129, Base=0.6009, Diff=+0.1120\n",
      "\n",
      " Question: Tên gọi \"Bánh Xèo\" của món ăn truyền thống trong hình có nguồn gốc và ý nghĩa văn hóa như thế nào tr...\n",
      "   Ground Truth: Tên gọi \"Bánh Xèo\" xuất phát từ âm thanh đặc trưng trong quá trình chế biến. Cụ thể, âm \"xèo\" là tiếng dầu mỡ nóng gặp b...\n",
      "   Fine-tuned: Tên gọi \"BÁNH XÈO\"\n",
      "\n",
      "Tên gọi \"bánh xèo\" xuất phát từ tiếng Việt, có lẽ đến từ việc bánh được nướng nhừ, tạo nên lớp vỏ gi...\n",
      "   Base: \"Bánh Xèо\" là một món ăn truyền统 trong ẩm thức Việt Nam, đặc biệt nổi tiếng ở miền Nam nước này. Món này có nguồn gốc từ...\n",
      "   Improvement: FT=0.7571, Base=0.6733, Diff=+0.0838\n",
      "\n",
      " Question: Hình tượng rồng được trang trí trên mũi thuyền trong bức ảnh này mang những ý nghĩa biểu trưng sâu s...\n",
      "   Ground Truth: Biểu tượng của sức mạnh, quyền uy và thịnh vượng. Trong văn hóa và tín ngưỡng Việt Nam, rồng là một linh vật thiêng liên...\n",
      "   Fine-tuned: Rồng là linh vật thiêng liêng, biểu tượng cho sức mạnh, quyền lực và sự may mắn.\n",
      "\n",
      "Trong văn hóa Việt, rồng là biểu tượng...\n",
      "   Base: Hình tượng rồng trên mũi thuyền tại bức ảnh này có nhiều ý nghĩa biểu tượng sâu sắc trong văn hóa Việt. Rồng thường được...\n",
      "   Improvement: FT=0.8089, Base=0.7400, Diff=+0.0690\n",
      "\n",
      " Question: Cây cột được trang trí bằng các hình cắt giấy và các vật phẩm sặc sỡ ở trung tâm bức ảnh có tên gọi ...\n",
      "   Ground Truth: Đây là một loại cột lễ hay cây nghi lễ quan trọng trong các nghi thức tín ngưỡng của người Dao Đỏ. Cây cột này được tran...\n",
      "   Fine-tuned: Đây là cây cột thần linh hoặc cây cờ, thường được làm từ gỗ và được trang hoàng cầu kỳ. Nó đóng vai trò trung tâm trong ...\n",
      "   Base: Trong bức ảnh, cây cột được gọi là \"cột rồng\" hoặc \"cột thần rồng\", đây là một phần quan trọng trong nghi lễ tôn giáo củ...\n",
      "   Improvement: FT=0.8028, Base=0.7341, Diff=+0.0687\n",
      "\n",
      "======================================================================\n",
      "TOP 5 SAMPLES: RAG + Fine-tuned >> Zero-shot (RAG helps most)\n",
      "======================================================================\n",
      "\n",
      " Question: Tên gọi \"Bánh Xèo\" của món ăn truyền thống trong hình có nguồn gốc và ý nghĩa văn hóa như thế nào tr...\n",
      "   Ground Truth: Tên gọi \"Bánh Xèo\" xuất phát từ âm thanh đặc trưng trong quá trình chế biến. Cụ thể, âm \"xèo\" là tiếng dầu mỡ nóng gặp b...\n",
      "   Fine-tuned (RAG): Tên gọi \"BÁNH XÈO\"\n",
      "\n",
      "Tên gọi \"bánh xèo\" xuất phát từ tiếng Việt, có lẽ đến từ việc bánh được nướng nhừ, tạo nên lớp vỏ gi...\n",
      "   Zero-shot: Bánh Xèo là một món ăn truyền thống ở Việt Nam được chế biến từ các loại bánh mì, bánh mỳ, bánh mì, bánh mì, bánh mì, bá...\n",
      "   RAG Improvement: FT=0.7571, ZS=0.5504, Diff=+0.2067\n",
      "\n",
      " Question: Thị trấn cổ xuất hiện trong bức ảnh này có phải là Di sản Văn hóa Thế giới được UNESCO công nhận khô...\n",
      "   Ground Truth: Có, đây là Phố cổ Hội An, Di sản Văn hóa Thế giới được UNESCO công nhận vào năm 1999. Giá trị nổi bật toàn cầu của Hội A...\n",
      "   Fine-tuned (RAG): Có, đó là Hội An - Di sản Văn hoá thế giới.\n",
      "\n",
      "Bức ảnh chụp tại Hội An, một thị trấn cổ nằm ở tỉnh Quảng Nam, thuộc vùng m...\n",
      "   Zero-shot: Xin lỗi, nhưng tôi không thể trả lời câu hỏi này vì tôi không có thông tin về bức ảnh cụ thể mà bạn đang nói. Bạn nên ki...\n",
      "   RAG Improvement: FT=0.7970, ZS=0.6243, Diff=+0.1728\n",
      "\n",
      " Question: Hình tượng rồng được trang trí trên mũi thuyền trong bức ảnh này mang những ý nghĩa biểu trưng sâu s...\n",
      "   Ground Truth: Biểu tượng của sức mạnh, quyền uy và thịnh vượng. Trong văn hóa và tín ngưỡng Việt Nam, rồng là một linh vật thiêng liên...\n",
      "   Fine-tuned (RAG): Rồng là linh vật thiêng liêng, biểu tượng cho sức mạnh, quyền lực và sự may mắn.\n",
      "\n",
      "Trong văn hóa Việt, rồng là biểu tượng...\n",
      "   Zero-shot: Rồng là một biểu tượng quan trọng trong văn hóa và tín ngưỡng của người Việt Nam. Rồng được trang trí trên mũi thuyền có...\n",
      "   RAG Improvement: FT=0.8089, ZS=0.6387, Diff=+0.1702\n",
      "\n",
      " Question: Món ăn đặc trưng được trình bày trong bức ảnh này, một biểu tượng của ẩm thực Việt Nam, được biết đế...\n",
      "   Ground Truth: Phở bò. Phở là món ăn tiêu biểu của ẩm thực Việt Nam, có nguồn gốc từ miền Bắc vào khoảng cuối thế kỷ 19, đầu thế kỷ 20,...\n",
      "   Fine-tuned (RAG): Phở bò\n",
      "\n",
      "Đây là phở bò, một món pho mát nổi tiếng khắp cả nước Việt Nam.  Nguyên liệu chính là sợi bò tươi, xương bò nấu ...\n",
      "   Zero-shot: Món ăn đặc trưng được trình bày trong bức ảnh này, một biểu tượng của ẩm thực Việt Nam, được biết đến với tên gọi phổ bi...\n",
      "   RAG Improvement: FT=0.7193, ZS=0.5986, Diff=+0.1206\n",
      "\n",
      " Question: Khu phố cổ trong bức ảnh này có phải là một Di sản Văn hóa Thế giới được UNESCO công nhận không, và ...\n",
      "   Ground Truth: Có, đây là Di sản Văn hóa Thế giới. Phố cổ Hội An được UNESCO công nhận vào năm 1999. Nơi đây nổi bật với quần thể kiến ...\n",
      "   Fine-tuned (RAG): Có, đây là Hội An - một Di sản văn hóa thế giới.\n",
      "\n",
      "Hội An là một ví dụ điển hình về sự hòa quyện giữa thiên nhiên và con ...\n",
      "   Zero-shot: Câu hỏi này không có đáp án chính xác vì không có hình ảnh cụ thể để trả lời....\n",
      "   RAG Improvement: FT=0.7499, ZS=0.6299, Diff=+0.1200\n"
     ]
    }
   ],
   "source": [
    "# Create detailed comparison dataframe with ground truth - 3 MODELS\n",
    "df_detailed = pd.DataFrame({\n",
    "    'question': questions,\n",
    "    'ground_truth': ground_truth_answers,\n",
    "    'finetuned_answer': finetuned_answers,\n",
    "    'base_answer': base_answers,\n",
    "    'zeroshot_answer': zeroshot_answers,\n",
    "})\n",
    "\n",
    "# Add BERTScore for each sample - 3 MODELS\n",
    "from bert_score import score as bert_score_fn\n",
    "\n",
    "# Compute per-sample BERTScore\n",
    "_, _, ft_f1_scores = bert_score_fn(finetuned_answers, ground_truth_answers, lang='vi', verbose=False)\n",
    "_, _, base_f1_scores = bert_score_fn(base_answers, ground_truth_answers, lang='vi', verbose=False)\n",
    "_, _, zs_f1_scores = bert_score_fn(zeroshot_answers, ground_truth_answers, lang='vi', verbose=False)\n",
    "\n",
    "df_detailed['bertscore_ft'] = ft_f1_scores.numpy()\n",
    "df_detailed['bertscore_base'] = base_f1_scores.numpy()\n",
    "df_detailed['bertscore_zs'] = zs_f1_scores.numpy()\n",
    "df_detailed['bertscore_diff_ft_base'] = df_detailed['bertscore_ft'] - df_detailed['bertscore_base']\n",
    "df_detailed['bertscore_diff_ft_zs'] = df_detailed['bertscore_ft'] - df_detailed['bertscore_zs']\n",
    "\n",
    "# Show samples where RAG + Fine-tuned is best\n",
    "print(\"=\" * 70)\n",
    "print(\"TOP 5 SAMPLES: RAG + Fine-tuned performs BEST\")\n",
    "print(\"=\" * 70)\n",
    "top_ft = df_detailed.nlargest(5, 'bertscore_ft')\n",
    "for i, row in top_ft.iterrows():\n",
    "    print(f\"\\n Question: {row['question'][:100]}...\")\n",
    "    print(f\"   Ground Truth: {row['ground_truth'][:120]}...\")\n",
    "    print(f\"   Fine-tuned: {row['finetuned_answer'][:120]}...\")\n",
    "    print(f\"   Base: {row['base_answer'][:120]}...\")\n",
    "    print(f\"   Zero-shot: {row['zeroshot_answer'][:120]}...\")\n",
    "    print(f\"   BERTScore: FT={row['bertscore_ft']:.4f}, Base={row['bertscore_base']:.4f}, ZS={row['bertscore_zs']:.4f}\")\n",
    "\n",
    "# Show samples where Fine-tuned >> Base (biggest improvement from fine-tuning)\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"TOP 5 SAMPLES: Fine-tuned >> Base (biggest fine-tuning gain)\")\n",
    "print(\"=\" * 70)\n",
    "top_ft_vs_base = df_detailed.nlargest(5, 'bertscore_diff_ft_base')\n",
    "for i, row in top_ft_vs_base.iterrows():\n",
    "    print(f\"\\n Question: {row['question'][:100]}...\")\n",
    "    print(f\"   Ground Truth: {row['ground_truth'][:120]}...\")\n",
    "    print(f\"   Fine-tuned: {row['finetuned_answer'][:120]}...\")\n",
    "    print(f\"   Base: {row['base_answer'][:120]}...\")\n",
    "    print(f\"   Improvement: FT={row['bertscore_ft']:.4f}, Base={row['bertscore_base']:.4f}, Diff={row['bertscore_diff_ft_base']:+.4f}\")\n",
    "\n",
    "# Show samples where RAG >> Zero-shot (biggest RAG improvement)\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"TOP 5 SAMPLES: RAG + Fine-tuned >> Zero-shot (RAG helps most)\")\n",
    "print(\"=\" * 70)\n",
    "top_rag_vs_zs = df_detailed.nlargest(5, 'bertscore_diff_ft_zs')\n",
    "for i, row in top_rag_vs_zs.iterrows():\n",
    "    print(f\"\\n Question: {row['question'][:100]}...\")\n",
    "    print(f\"   Ground Truth: {row['ground_truth'][:120]}...\")\n",
    "    print(f\"   Fine-tuned (RAG): {row['finetuned_answer'][:120]}...\")\n",
    "    print(f\"   Zero-shot: {row['zeroshot_answer'][:120]}...\")\n",
    "    print(f\"   RAG Improvement: FT={row['bertscore_ft']:.4f}, ZS={row['bertscore_zs']:.4f}, Diff={row['bertscore_diff_ft_zs']:+.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 23. Lưu kết quả"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-03T16:27:02.163485Z",
     "iopub.status.busy": "2026-01-03T16:27:02.163325Z",
     "iopub.status.idle": "2026-01-03T16:27:02.174671Z",
     "shell.execute_reply": "2026-01-03T16:27:02.174256Z",
     "shell.execute_reply.started": "2026-01-03T16:27:02.163468Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Detailed results saved to /kaggle/working/results/model_comparison_detailed.csv\n",
      " Summary metrics saved to /kaggle/working/results/model_comparison_metrics.json\n",
      "\n",
      "================================================================================\n",
      " EVALUATION COMPLETE - 3 MODELS!\n",
      "================================================================================\n",
      "\n",
      "Output files:\n",
      "   /kaggle/working/results/benchmark_inference_results_finetuned.json\n",
      "   /kaggle/working/results/benchmark_inference_results_base.json\n",
      "   /kaggle/working/results/benchmark_inference_results_zeroshot.json\n",
      "   /kaggle/working/results/model_comparison_detailed.csv\n",
      "   /kaggle/working/results/model_comparison_metrics.json\n",
      "   /kaggle/working/results/model_comparison_chart_3models.png\n"
     ]
    }
   ],
   "source": [
    "# Save detailed results to CSV - 3 MODELS\n",
    "output_csv = f\"{OUTPUT_DIR}/model_comparison_detailed.csv\"\n",
    "df_detailed.to_csv(output_csv, index=False, encoding='utf-8')\n",
    "print(f\" Detailed results saved to {output_csv}\")\n",
    "\n",
    "# Save summary metrics to JSON - 3 MODELS\n",
    "summary_metrics = {\n",
    "    \"fine_tuned_model\": str(FINETUNED_MODEL_PATH),\n",
    "    \"base_model\": BASE_MODEL_ID,\n",
    "    \"zeroshot_model\": \"Qwen/Qwen2-VL-2B-Instruct\",\n",
    "    \"num_samples\": len(valid_images),\n",
    "    \"metrics_vs_ground_truth\": {\n",
    "        \"finetuned\": {\n",
    "            \"bertscore_f1\": bertscore_ft_gt['f1'],\n",
    "            \"bertscore_f1_std\": bertscore_ft_gt['f1_std'],\n",
    "            \"rouge_l_f1\": rouge_ft_gt['f1'],\n",
    "            \"rouge_l_f1_std\": rouge_ft_gt['f1_std'],\n",
    "            \"faithfulness_mean\": faith_ft['mean'],\n",
    "            \"faithfulness_std\": faith_ft['std']\n",
    "        },\n",
    "        \"base\": {\n",
    "            \"bertscore_f1\": bertscore_base_gt['f1'],\n",
    "            \"bertscore_f1_std\": bertscore_base_gt['f1_std'],\n",
    "            \"rouge_l_f1\": rouge_base_gt['f1'],\n",
    "            \"rouge_l_f1_std\": rouge_base_gt['f1_std'],\n",
    "            \"faithfulness_mean\": faith_base['mean'],\n",
    "            \"faithfulness_std\": faith_base['std']\n",
    "        },\n",
    "        \"zeroshot\": {\n",
    "            \"bertscore_f1\": bertscore_zs_gt['f1'],\n",
    "            \"bertscore_f1_std\": bertscore_zs_gt['f1_std'],\n",
    "            \"rouge_l_f1\": rouge_zs_gt['f1'],\n",
    "            \"rouge_l_f1_std\": rouge_zs_gt['f1_std'],\n",
    "            \"faithfulness_mean\": None,  # Zero-shot không có context\n",
    "            \"faithfulness_std\": None\n",
    "        }\n",
    "    },\n",
    "    \"improvement_finetuned_vs_base\": {\n",
    "        \"bertscore_f1\": bertscore_ft_gt['f1'] - bertscore_base_gt['f1'],\n",
    "        \"rouge_l_f1\": rouge_ft_gt['f1'] - rouge_base_gt['f1'],\n",
    "        \"faithfulness\": faith_ft['mean'] - faith_base['mean']\n",
    "    },\n",
    "    \"improvement_rag_vs_zeroshot\": {\n",
    "        \"finetuned_vs_zeroshot\": {\n",
    "            \"bertscore_f1\": bertscore_ft_gt['f1'] - bertscore_zs_gt['f1'],\n",
    "            \"rouge_l_f1\": rouge_ft_gt['f1'] - rouge_zs_gt['f1']\n",
    "        },\n",
    "        \"base_vs_zeroshot\": {\n",
    "            \"bertscore_f1\": bertscore_base_gt['f1'] - bertscore_zs_gt['f1'],\n",
    "            \"rouge_l_f1\": rouge_base_gt['f1'] - rouge_zs_gt['f1']\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "output_json = f\"{OUTPUT_DIR}/model_comparison_metrics.json\"\n",
    "with open(output_json, 'w', encoding='utf-8') as f:\n",
    "    json.dump(summary_metrics, f, indent=2, ensure_ascii=False)\n",
    "print(f\" Summary metrics saved to {output_json}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\" EVALUATION COMPLETE - 3 MODELS!\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nOutput files:\")\n",
    "print(f\"   {OUTPUT_DIR}/benchmark_inference_results_finetuned.json\")\n",
    "print(f\"   {OUTPUT_DIR}/benchmark_inference_results_base.json\")\n",
    "print(f\"   {OUTPUT_DIR}/benchmark_inference_results_zeroshot.json\")\n",
    "print(f\"   {OUTPUT_DIR}/model_comparison_detailed.csv\")\n",
    "print(f\"   {OUTPUT_DIR}/model_comparison_metrics.json\")\n",
    "print(f\"   {OUTPUT_DIR}/model_comparison_chart_3models.png\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 14559231,
     "sourceId": 118448,
     "sourceType": "competition"
    },
    {
     "datasetId": 9177038,
     "sourceId": 14370802,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 9178622,
     "sourceId": 14377153,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 9181652,
     "sourceId": 14377286,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 9182115,
     "sourceId": 14378025,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 9181596,
     "sourceId": 14382835,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31236,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
