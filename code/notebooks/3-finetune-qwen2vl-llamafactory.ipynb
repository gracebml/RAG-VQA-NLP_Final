{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f014ef98",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2026-01-02T18:34:25.239528Z",
     "iopub.status.busy": "2026-01-02T18:34:25.238920Z",
     "iopub.status.idle": "2026-01-02T18:34:25.244986Z",
     "shell.execute_reply": "2026-01-02T18:34:25.244592Z"
    },
    "papermill": {
     "duration": 0.01052,
     "end_time": "2026-01-02T18:34:25.245792",
     "exception": false,
     "start_time": "2026-01-02T18:34:25.235272",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Running on Kaggle\n",
      "Base directory: /kaggle/working\n",
      " Directories created\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Kaggle environment setup\n",
    "IS_KAGGLE = os.path.exists('/kaggle')\n",
    "\n",
    "if IS_KAGGLE:\n",
    "    # Running on Kaggle\n",
    "    BASE_DIR = Path('/kaggle/working')\n",
    "    os.chdir(BASE_DIR)\n",
    "    print(\" Running on Kaggle\")\n",
    "else:\n",
    "    # Running locally\n",
    "    BASE_DIR = Path.cwd().parent.parent\n",
    "    print(\" Running locally\")\n",
    "\n",
    "print(f\"Base directory: {BASE_DIR}\")\n",
    "\n",
    "# Create necessary directories\n",
    "(BASE_DIR / \"models\").mkdir(exist_ok=True)\n",
    "(BASE_DIR / \"config\").mkdir(exist_ok=True)\n",
    "print(\" Directories created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21f33d1b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-02T18:34:25.249952Z",
     "iopub.status.busy": "2026-01-02T18:34:25.249793Z",
     "iopub.status.idle": "2026-01-02T18:34:55.758946Z",
     "shell.execute_reply": "2026-01-02T18:34:55.758432Z"
    },
    "papermill": {
     "duration": 30.512908,
     "end_time": "2026-01-02T18:34:55.760500",
     "exception": false,
     "start_time": "2026-01-02T18:34:25.247592",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.7/73.7 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h\u001b[33mWARNING: llamafactory 0.9.4 does not provide the extra 'torch'\u001b[0m\u001b[33m\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.3/43.3 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.6/68.6 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m494.8/494.8 kB\u001b[0m \u001b[31m33.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m444.8/444.8 kB\u001b[0m \u001b[31m37.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m76.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m423.1/423.1 kB\u001b[0m \u001b[31m43.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.8/109.8 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.5/40.5 MB\u001b[0m \u001b[31m45.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.9/115.9 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m398.5/398.5 kB\u001b[0m \u001b[31m44.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.1/6.1 MB\u001b[0m \u001b[31m136.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m146.7/146.7 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "bigframes 2.26.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\r\n",
      "langchain 0.3.27 requires SQLAlchemy<3,>=1.4, but you have sqlalchemy 1.2.19 which is incompatible.\r\n",
      "cudf-cu12 25.6.0 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\r\n",
      "bigframes 2.26.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m65.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.1/59.1 MB\u001b[0m \u001b[31m42.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.0/54.0 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Building wheel for deepspeed (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n"
     ]
    }
   ],
   "source": [
    "# Install LLaMA Factory nếu chưa có\n",
    "!pip install \"llamafactory[torch,metrics]\" -q\n",
    "!pip install deepspeed accelerate bitsandbytes peft -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b4ac5ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-02T18:34:55.765868Z",
     "iopub.status.busy": "2026-01-02T18:34:55.765728Z",
     "iopub.status.idle": "2026-01-02T18:35:13.983967Z",
     "shell.execute_reply": "2026-01-02T18:35:13.983447Z"
    },
    "papermill": {
     "duration": 18.222889,
     "end_time": "2026-01-02T18:35:13.985826",
     "exception": false,
     "start_time": "2026-01-02T18:34:55.762937",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-02 18:35:02.431130: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\r\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\r\n",
      "E0000 00:00:1767378902.556716     289 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\r\n",
      "E0000 00:00:1767378902.591967     289 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\r\n",
      "W0000 00:00:1767378902.886626     289 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\r\n",
      "W0000 00:00:1767378902.886655     289 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\r\n",
      "W0000 00:00:1767378902.886658     289 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\r\n",
      "W0000 00:00:1767378902.886660     289 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\r\n",
      "----------------------------------------------------------\r\n",
      "| Welcome to LLaMA Factory, version 0.9.4                |\r\n",
      "|                                                        |\r\n",
      "| Project page: https://github.com/hiyouga/LLaMA-Factory |\r\n",
      "----------------------------------------------------------\r\n"
     ]
    }
   ],
   "source": [
    "# Verify installation\n",
    "!llamafactory-cli version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "caa3ddb4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-02T18:35:13.992251Z",
     "iopub.status.busy": "2026-01-02T18:35:13.992085Z",
     "iopub.status.idle": "2026-01-02T18:35:14.347729Z",
     "shell.execute_reply": "2026-01-02T18:35:14.347319Z"
    },
    "papermill": {
     "duration": 0.35992,
     "end_time": "2026-01-02T18:35:14.348620",
     "exception": false,
     "start_time": "2026-01-02T18:35:13.988700",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Data paths:\n",
      "  Train: /kaggle/input/data-llama/llama-dataset/vqa_vietnamese_train.json - Found\n",
      "  Eval: /kaggle/input/data-llama/llama-dataset/vqa_vietnamese_test.json - Found\n",
      "  Images: /kaggle/input/vqa-dataset/images_flat/images_flat - Found\n",
      "\n",
      " Dataset size:\n",
      "  Train samples: 7598\n",
      "  Eval samples: 60\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Dataset paths - adjust based on environment\n",
    "if IS_KAGGLE:\n",
    "    # On Kaggle: assume data uploaded as a dataset\n",
    "    # IMPORTANT: Change this to match your Kaggle dataset name!\n",
    "    DATA_INPUT = Path('/kaggle/input/data-llama/llama-dataset')\n",
    "    TRAIN_DATA = Path(DATA_INPUT / \"vqa_vietnamese_train.json\")\n",
    "    EVAL_DATA = Path(DATA_INPUT / \"vqa_vietnamese_test.json\")\n",
    "    IMAGE_DIR = Path(\"/kaggle/input/vqa-dataset/images_flat/images_flat\")\n",
    "else:\n",
    "    # Local paths\n",
    "    DATA_INPUT = BASE_DIR / \"llama-dataset\"\n",
    "    TRAIN_DATA = DATA_INPUT / \"vqa_vietnamese_train.json\"\n",
    "    # EVAL_DATA = DATA_INPUT / \"vqa_vietnamese_test.json\"\n",
    "    IMAGE_DIR = BASE_DIR / \"data\" / \"raw\" / \"images_flat\"\n",
    "\n",
    "# Verify files exist\n",
    "print(f\"\\n Data paths:\")\n",
    "print(f\"  Train: {TRAIN_DATA} - {'Found' if TRAIN_DATA.exists() else 'NOT FOUND'}\")\n",
    "print(f\"  Eval: {EVAL_DATA} - {'Found' if EVAL_DATA.exists() else 'NOT FOUND'}\")\n",
    "print(f\"  Images: {IMAGE_DIR} - {'Found' if IMAGE_DIR.exists() else 'NOT FOUND'}\")\n",
    "\n",
    "# Load data\n",
    "with open(TRAIN_DATA, 'r', encoding='utf-8') as f:\n",
    "    train_data = json.load(f)\n",
    "\n",
    "with open(EVAL_DATA, 'r', encoding='utf-8') as f:\n",
    "    eval_data = json.load(f)\n",
    "\n",
    "print(f\"\\n Dataset size:\")\n",
    "print(f\"  Train samples: {len(train_data)}\")\n",
    "print(f\"  Eval samples: {len(eval_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f3a4de0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-02T18:35:14.355040Z",
     "iopub.status.busy": "2026-01-02T18:35:14.354896Z",
     "iopub.status.idle": "2026-01-02T18:35:14.358344Z",
     "shell.execute_reply": "2026-01-02T18:35:14.357892Z"
    },
    "papermill": {
     "duration": 0.007709,
     "end_time": "2026-01-02T18:35:14.359209",
     "exception": false,
     "start_time": "2026-01-02T18:35:14.351500",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "SAMPLE TRAINING EXAMPLE\n",
      "================================================================================\n",
      "\n",
      "Image: ['005000.jpg']\n",
      "\n",
      "system: Bạn là trợ lý VQA chuyên về lịch sử và văn hóa Việt Nam. Trả lời câu hỏi dựa trên HÌNH ẢNH là chính. Mô tả hình ảnh và văn bản OCR chỉ là thông tin tham khảo, có thể không chính xác. Kiến thức bổ sung...\n",
      "\n",
      "human: <image>\n",
      "\n",
      "Dựa vào mô tả hình ảnh: Hình ảnh cho thấy một bé gái trẻ đang sử dụng một chiếc cột bắc bằng nhựa màu xanh dương nhạt. Cột bắc có hai đầu được gắn vào hai chân của bé gái, giúp bé gái đứng thẳng. Bé gái mặc áo thun kẻ sọc xanh trắng, quần màu xám, mang giày thể thao màu hồng. Bé gái đang đứng thẳng, hai chân của bé gái được giữ chắc chắn bởi hai đầu cột bắc.\n",
      "\n",
      "Thông tin văn bản trong ảnh: ...\n",
      "\n",
      "gpt: Cà kheo trong ảnh hiện đại hơn.\n",
      "\n",
      "Cà kheo truyền thống thường được làm từ gỗ hoặc tre, có thiết kế đơn giản hơn.  Cà kheo trong hình ảnh có vẻ được làm từ kim loại, thiết kế chắc chắn và an toàn hơn, có thể đáp ứng tiêu chuẩn an toàn hiện đại. Sự khác biệt này phản ánh sự phát triển và thích ứng của ...\n"
     ]
    }
   ],
   "source": [
    "# Display sample\n",
    "sample = train_data[0]\n",
    "print(\"=\"*80)\n",
    "print(\"SAMPLE TRAINING EXAMPLE\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nImage: {sample['images']}\")\n",
    "print(f\"\\n{sample['conversations'][0]['from']}: {sample['conversations'][0]['value'][:200]}...\")\n",
    "print(f\"\\n{sample['conversations'][1]['from']}: {sample['conversations'][1]['value'][:400]}...\")\n",
    "print(f\"\\n{sample['conversations'][2]['from']}: {sample['conversations'][2]['value'][:300]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe84ed13",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-02T18:35:14.365461Z",
     "iopub.status.busy": "2026-01-02T18:35:14.365319Z",
     "iopub.status.idle": "2026-01-02T18:35:14.685973Z",
     "shell.execute_reply": "2026-01-02T18:35:14.685286Z"
    },
    "papermill": {
     "duration": 0.325051,
     "end_time": "2026-01-02T18:35:14.687039",
     "exception": false,
     "start_time": "2026-01-02T18:35:14.361988",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Converted train data: /kaggle/working/data/vqa_train_abs.json\n",
      "\n",
      " Sample image path (before): ['005000.jpg']\n",
      " Sample image path (after): ['/kaggle/input/vqa-dataset/images_flat/images_flat/005000.jpg']\n",
      "\n",
      " Image exists: True\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "def convert_to_absolute_paths(data, image_dir):\n",
    "    \"\"\"Convert image filenames to absolute paths\"\"\"\n",
    "    new_data = []\n",
    "    for item in data:\n",
    "        new_item = copy.deepcopy(item)\n",
    "        # Convert images list to absolute paths\n",
    "        if 'images' in new_item:\n",
    "            new_item['images'] = [str(image_dir / img) for img in new_item['images']]\n",
    "        new_data.append(new_item)\n",
    "    return new_data\n",
    "\n",
    "# Convert train and test data\n",
    "train_data_abs = convert_to_absolute_paths(train_data, IMAGE_DIR)\n",
    "eval_data_abs = convert_to_absolute_paths(eval_data, IMAGE_DIR)\n",
    "\n",
    "# Save converted data to working directory\n",
    "DATA_OUT = BASE_DIR / \"data\"\n",
    "DATA_OUT.mkdir(exist_ok=True)\n",
    "TRAIN_DATA_ABS = DATA_OUT / \"vqa_train_abs.json\"\n",
    "EVAL_DATA_ABS = DATA_OUT / \"vqa_eval_abs.json\"\n",
    "\n",
    "with open(TRAIN_DATA_ABS, 'w', encoding='utf-8') as f:\n",
    "    json.dump(train_data_abs, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "with open(EVAL_DATA_ABS, 'w', encoding='utf-8') as f:\n",
    "    json.dump(eval_data_abs, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\" Converted train data: {TRAIN_DATA_ABS}\")\n",
    "# print(f\" Converted test data: {EVAL_DATA_ABS}\")\n",
    "\n",
    "# Verify conversion\n",
    "print(f\"\\n Sample image path (before): {train_data[0]['images']}\")\n",
    "print(f\" Sample image path (after): {train_data_abs[0]['images']}\")\n",
    "\n",
    "# Check if image exists\n",
    "sample_img = train_data_abs[0]['images'][0]\n",
    "print(f\"\\n Image exists: {Path(sample_img).exists()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a843738",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-02T18:35:14.693941Z",
     "iopub.status.busy": "2026-01-02T18:35:14.693786Z",
     "iopub.status.idle": "2026-01-02T18:35:14.784296Z",
     "shell.execute_reply": "2026-01-02T18:35:14.783872Z"
    },
    "papermill": {
     "duration": 0.095179,
     "end_time": "2026-01-02T18:35:14.785261",
     "exception": false,
     "start_time": "2026-01-02T18:35:14.690082",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Saved dataset_info.json to /kaggle/working/config/dataset_info.json\n",
      "\n",
      " Dataset info:\n",
      "{\n",
      "  \"vqa_vietnamese_train\": {\n",
      "    \"file_name\": \"/kaggle/working/data/vqa_train_abs.json\",\n",
      "    \"formatting\": \"sharegpt\",\n",
      "    \"columns\": {\n",
      "      \"messages\": \"conversations\",\n",
      "      \"images\": \"images\"\n",
      "    },\n",
      "    \"tags\": {\n",
      "      \"role_tag\": \"from\",\n",
      "      \"content_tag\": \"value\",\n",
      "      \"user_tag\": \"human\",\n",
      "      \"assistant_tag\": \"gpt\",\n",
      "      \"system_tag\": \"system\"\n",
      "    }\n",
      "  },\n",
      "  \"vqa_vietnamese_test\": {\n",
      "    \"file_name\": \"/kaggle/working/data/vqa_eval_abs.json\",\n",
      "    \"formatting\": \"sharegpt\",\n",
      "    \"columns\": {\n",
      "      \"messages\": \"conversations\",\n",
      "      \"images\": \"images\"\n",
      "    },\n",
      "    \"tags\": {\n",
      "      \"role_tag\": \"from\",\n",
      "      \"content_tag\": \"value\",\n",
      "      \"user_tag\": \"human\",\n",
      "      \"assistant_tag\": \"gpt\",\n",
      "      \"system_tag\": \"system\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      " Image folder: /kaggle/input/vqa-dataset/images_flat/images_flat\n",
      "   Exists: True\n",
      "   Sample files: ['004725.png', '001183.png', '001506.jpg']\n"
     ]
    }
   ],
   "source": [
    "# Tạo dataset_info.json với paths MỚI\n",
    "dataset_info = {\n",
    "    \"vqa_vietnamese_train\": {\n",
    "        \"file_name\": str(TRAIN_DATA_ABS),  # Use converted file\n",
    "        \"formatting\": \"sharegpt\",\n",
    "        \"columns\": {\n",
    "            \"messages\": \"conversations\",\n",
    "            \"images\": \"images\"\n",
    "        },\n",
    "        \"tags\": {\n",
    "            \"role_tag\": \"from\",\n",
    "            \"content_tag\": \"value\",\n",
    "            \"user_tag\": \"human\",\n",
    "            \"assistant_tag\": \"gpt\",\n",
    "            \"system_tag\": \"system\"\n",
    "        }\n",
    "    },\n",
    "    \"vqa_vietnamese_test\": {\n",
    "        \"file_name\": str(EVAL_DATA_ABS),  # Use converted file\n",
    "        \"formatting\": \"sharegpt\",\n",
    "        \"columns\": {\n",
    "            \"messages\": \"conversations\",\n",
    "            \"images\": \"images\"\n",
    "        },\n",
    "        \"tags\": {\n",
    "            \"role_tag\": \"from\",\n",
    "            \"content_tag\": \"value\",\n",
    "            \"user_tag\": \"human\",\n",
    "            \"assistant_tag\": \"gpt\",\n",
    "            \"system_tag\": \"system\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "DATASET_INFO_PATH = BASE_DIR / \"config\" / \"dataset_info.json\"\n",
    "\n",
    "with open(DATASET_INFO_PATH, 'w', encoding='utf-8') as f:\n",
    "    json.dump(dataset_info, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"\\n Saved dataset_info.json to {DATASET_INFO_PATH}\")\n",
    "print(f\"\\n Dataset info:\")\n",
    "print(json.dumps(dataset_info, indent=2, ensure_ascii=False))\n",
    "\n",
    "# Verify image folder exists\n",
    "print(f\"\\n Image folder: {IMAGE_DIR}\")\n",
    "print(f\"   Exists: {IMAGE_DIR.exists()}\")\n",
    "if IMAGE_DIR.exists():\n",
    "    sample_files = list(IMAGE_DIR.iterdir())[:3]\n",
    "    print(f\"   Sample files: {[f.name for f in sample_files]}\")\n",
    "\n",
    "# print(f\" Saved dataset_info.json to {DATASET_INFO_PATH}\")\n",
    "# print(f\"\\n Dataset info:\")\n",
    "# print(json.dumps(dataset_info, indent=2, ensure_ascii=False))\n",
    "# print(f\"\\n Dataset info:\")\n",
    "# print(json.dumps(dataset_info, indent=2, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f9e27e50",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-02T18:35:14.791919Z",
     "iopub.status.busy": "2026-01-02T18:35:14.791773Z",
     "iopub.status.idle": "2026-01-02T18:35:14.795839Z",
     "shell.execute_reply": "2026-01-02T18:35:14.795369Z"
    },
    "papermill": {
     "duration": 0.008529,
     "end_time": "2026-01-02T18:35:14.796708",
     "exception": false,
     "start_time": "2026-01-02T18:35:14.788179",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Saved config to /kaggle/working/config/qwen2vl_7b_grounded.yaml\n",
      "\n",
      "============================================================\n",
      " TRAINING CONFIG\n",
      "============================================================\n",
      "### Model\n",
      "model_name_or_path: Qwen/Qwen2-VL-7B-Instruct\n",
      "trust_remote_code: true\n",
      "\n",
      "### Method\n",
      "stage: sft\n",
      "do_train: true\n",
      "finetuning_type: lora\n",
      "lora_target: all\n",
      "lora_rank: 64\n",
      "lora_alpha: 128\n",
      "lora_dropout: 0.05\n",
      "\n",
      "### Dataset\n",
      "dataset: vqa_vietnamese_train\n",
      "dataset_dir: /kaggle/working/config\n",
      "template: qwen2_vl\n",
      "cutoff_len: 2048\n",
      "overwrite_cache: true\n",
      "preprocessing_num_workers: 4\n",
      "\n",
      "### Image settings\n",
      "freeze_vision_tower: true\n",
      "\n",
      "### Output\n",
      "output_dir: /kaggle/working/models/qwen2vl-7b-vqa-grounded\n",
      "logging_steps: 10\n",
      "save_steps: 100\n",
      "save_total_limit: 3\n",
      "plot_loss: true\n",
      "overwrite_output_dir: true\n",
      "\n",
      "### Training hyperparameters\n",
      "per_device_train_batch_size: 4\n",
      "gradient_accumulation_steps: 4\n",
      "learning_rate: 5.0e-5\n",
      "num_train_epochs: 3\n",
      "lr_scheduler_type: cosine\n",
      "warmup_ratio: 0.1\n",
      "bf16: false\n",
      "fp16: true\n",
      "\n",
      "### Optimization\n",
      "gradient_checkpointing: true\n",
      "optim: adamw_torch\n",
      "\n",
      "### Quantization \n",
      "quantization_bit: 4\n",
      "quantization_method: bitsandbytes\n",
      "\n",
      "### Evaluation - QUAN TRỌNG: eval_steps = save_steps\n",
      "do_eval: true\n",
      "eval_dataset: vqa_vietnamese_test\n",
      "eval_strategy: steps\n",
      "eval_steps: 100\n",
      "per_device_eval_batch_size: 1\n",
      "load_best_model_at_end: true\n",
      "metric_for_best_model: eval_loss\n",
      "greater_is_better: false\n",
      "\n",
      "### Logging\n",
      "report_to: none\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Training config with dynamic paths\n",
    "OUTPUT_DIR = BASE_DIR / 'models' / 'qwen2vl-7b-vqa-grounded'\n",
    "CONFIG_DIR = BASE_DIR / 'config'\n",
    "\n",
    "config_yaml = f\"\"\"### Model\n",
    "model_name_or_path: Qwen/Qwen2-VL-7B-Instruct\n",
    "trust_remote_code: true\n",
    "\n",
    "### Method\n",
    "stage: sft\n",
    "do_train: true\n",
    "finetuning_type: lora\n",
    "lora_target: all\n",
    "lora_rank: 64\n",
    "lora_alpha: 128\n",
    "lora_dropout: 0.05\n",
    "\n",
    "### Dataset\n",
    "dataset: vqa_vietnamese_train\n",
    "dataset_dir: /kaggle/working/config\n",
    "template: qwen2_vl\n",
    "cutoff_len: 2048\n",
    "overwrite_cache: true\n",
    "preprocessing_num_workers: 4\n",
    "\n",
    "### Image settings\n",
    "freeze_vision_tower: true\n",
    "\n",
    "### Output\n",
    "output_dir: /kaggle/working/models/qwen2vl-7b-vqa-grounded\n",
    "logging_steps: 10\n",
    "save_steps: 100\n",
    "save_total_limit: 3\n",
    "plot_loss: true\n",
    "overwrite_output_dir: true\n",
    "\n",
    "### Training hyperparameters\n",
    "per_device_train_batch_size: 4\n",
    "gradient_accumulation_steps: 4\n",
    "learning_rate: 5.0e-5\n",
    "num_train_epochs: 3\n",
    "lr_scheduler_type: cosine\n",
    "warmup_ratio: 0.1\n",
    "bf16: false\n",
    "fp16: true\n",
    "\n",
    "### Optimization\n",
    "gradient_checkpointing: true\n",
    "optim: adamw_torch\n",
    "\n",
    "### Quantization \n",
    "quantization_bit: 4\n",
    "quantization_method: bitsandbytes\n",
    "\n",
    "### Evaluation - QUAN TRỌNG: eval_steps = save_steps\n",
    "do_eval: true\n",
    "eval_dataset: vqa_vietnamese_test\n",
    "eval_strategy: steps\n",
    "eval_steps: 100\n",
    "per_device_eval_batch_size: 1\n",
    "load_best_model_at_end: true\n",
    "metric_for_best_model: eval_loss\n",
    "greater_is_better: false\n",
    "\n",
    "### Logging\n",
    "report_to: none\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "CONFIG_PATH = CONFIG_DIR / \"qwen2vl_7b_grounded.yaml\"\n",
    "\n",
    "with open(CONFIG_PATH, 'w', encoding='utf-8') as f:\n",
    "    f.write(config_yaml)\n",
    "\n",
    "print(f\" Saved config to {CONFIG_PATH}\")\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\" TRAINING CONFIG\")\n",
    "print(\"=\"*60)\n",
    "print(config_yaml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ea511682",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-02T18:35:14.803377Z",
     "iopub.status.busy": "2026-01-02T18:35:14.803238Z",
     "iopub.status.idle": "2026-01-02T18:35:15.922316Z",
     "shell.execute_reply": "2026-01-02T18:35:15.921848Z"
    },
    "papermill": {
     "duration": 1.123398,
     "end_time": "2026-01-02T18:35:15.923247",
     "exception": false,
     "start_time": "2026-01-02T18:35:14.799849",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "CUDA version: 12.6\n",
      "GPU count: 1\n",
      "\n",
      "GPU 0: NVIDIA H100 80GB HBM3\n",
      "  Memory: 79.44 GB\n",
      "  Allocated: 0.00 GB\n",
      "  Cached: 0.00 GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA version:\", torch.version.cuda)\n",
    "    print(\"GPU count:\", torch.cuda.device_count())\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        print(f\"\\nGPU {i}: {torch.cuda.get_device_name(i)}\")\n",
    "        print(f\"  Memory: {torch.cuda.get_device_properties(i).total_memory / 1024**3:.2f} GB\")\n",
    "        print(f\"  Allocated: {torch.cuda.memory_allocated(i) / 1024**3:.2f} GB\")\n",
    "        print(f\"  Cached: {torch.cuda.memory_reserved(i) / 1024**3:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5820b8b2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-02T18:35:15.930288Z",
     "iopub.status.busy": "2026-01-02T18:35:15.930041Z",
     "iopub.status.idle": "2026-01-02T18:35:15.932556Z",
     "shell.execute_reply": "2026-01-02T18:35:15.932198Z"
    },
    "papermill": {
     "duration": 0.006836,
     "end_time": "2026-01-02T18:35:15.933292",
     "exception": false,
     "start_time": "2026-01-02T18:35:15.926456",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "821f94bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-02T18:35:15.939828Z",
     "iopub.status.busy": "2026-01-02T18:35:15.939677Z",
     "iopub.status.idle": "2026-01-02T20:37:46.292801Z",
     "shell.execute_reply": "2026-01-02T20:37:46.292296Z"
    },
    "papermill": {
     "duration": 7350.358059,
     "end_time": "2026-01-02T20:37:46.294251",
     "exception": false,
     "start_time": "2026-01-02T18:35:15.936192",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Starting fine-tuning...\n",
      "   Config: /kaggle/working/config/qwen2vl_7b_grounded.yaml\n",
      "   Output: /kaggle/working/models/qwen2vl-7b-vqa-grounded\n",
      "\n",
      "2026-01-02 18:35:19.992003: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\r\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\r\n",
      "E0000 00:00:1767378920.007841     358 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\r\n",
      "E0000 00:00:1767378920.012469     358 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\r\n",
      "W0000 00:00:1767378920.024161     358 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\r\n",
      "W0000 00:00:1767378920.024189     358 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\r\n",
      "W0000 00:00:1767378920.024192     358 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\r\n",
      "W0000 00:00:1767378920.024194     358 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\r\n",
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\r\n",
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\r\n",
      "/usr/local/lib/python3.12/dist-packages/jieba/__init__.py:44: SyntaxWarning: invalid escape sequence '\\.'\r\n",
      "  re_han_default = re.compile(\"([\\u4E00-\\u9FD5a-zA-Z0-9+#&\\._%\\-]+)\", re.U)\r\n",
      "/usr/local/lib/python3.12/dist-packages/jieba/__init__.py:46: SyntaxWarning: invalid escape sequence '\\s'\r\n",
      "  re_skip_default = re.compile(\"(\\r\\n|\\s)\", re.U)\r\n",
      "/usr/local/lib/python3.12/dist-packages/jieba/finalseg/__init__.py:78: SyntaxWarning: invalid escape sequence '\\.'\r\n",
      "  re_skip = re.compile(\"([a-zA-Z0-9]+(?:\\.\\d+)?%?)\")\r\n",
      "[WARNING|2026-01-02 18:35:28] llamafactory.hparams.parser:148 >> We recommend enable `upcast_layernorm` in quantized training.\r\n",
      "[INFO|2026-01-02 18:35:28] llamafactory.hparams.parser:465 >> Process rank: 0, world size: 1, device: cuda:0, distributed training: False, compute dtype: torch.float16\r\n",
      "tokenizer_config.json: 4.19kB [00:00, 16.2MB/s]\r\n",
      "vocab.json: 2.78MB [00:00, 118MB/s]\r\n",
      "merges.txt: 1.67MB [00:00, 144MB/s]\r\n",
      "tokenizer.json: 7.03MB [00:00, 206MB/s]\r\n",
      "[INFO|tokenization_utils_base.py:2095] 2026-01-02 18:35:28,876 >> loading file vocab.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2-VL-7B-Instruct/snapshots/eed13092ef92e448dd6875b2a00151bd3f7db0ac/vocab.json\r\n",
      "[INFO|tokenization_utils_base.py:2095] 2026-01-02 18:35:28,876 >> loading file merges.txt from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2-VL-7B-Instruct/snapshots/eed13092ef92e448dd6875b2a00151bd3f7db0ac/merges.txt\r\n",
      "[INFO|tokenization_utils_base.py:2095] 2026-01-02 18:35:28,877 >> loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2-VL-7B-Instruct/snapshots/eed13092ef92e448dd6875b2a00151bd3f7db0ac/tokenizer.json\r\n",
      "[INFO|tokenization_utils_base.py:2095] 2026-01-02 18:35:28,877 >> loading file added_tokens.json from cache at None\r\n",
      "[INFO|tokenization_utils_base.py:2095] 2026-01-02 18:35:28,877 >> loading file special_tokens_map.json from cache at None\r\n",
      "[INFO|tokenization_utils_base.py:2095] 2026-01-02 18:35:28,877 >> loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2-VL-7B-Instruct/snapshots/eed13092ef92e448dd6875b2a00151bd3f7db0ac/tokenizer_config.json\r\n",
      "[INFO|tokenization_utils_base.py:2095] 2026-01-02 18:35:28,877 >> loading file chat_template.jinja from cache at None\r\n",
      "[INFO|tokenization_utils_base.py:2364] 2026-01-02 18:35:29,118 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\r\n",
      "preprocessor_config.json: 100%|████████████████| 347/347 [00:00<00:00, 3.74MB/s]\r\n",
      "[INFO|image_processing_base.py:383] 2026-01-02 18:35:29,220 >> loading configuration file preprocessor_config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2-VL-7B-Instruct/snapshots/eed13092ef92e448dd6875b2a00151bd3f7db0ac/preprocessor_config.json\r\n",
      "[INFO|image_processing_base.py:383] 2026-01-02 18:35:29,263 >> loading configuration file preprocessor_config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2-VL-7B-Instruct/snapshots/eed13092ef92e448dd6875b2a00151bd3f7db0ac/preprocessor_config.json\r\n",
      "[INFO|image_processing_base.py:428] 2026-01-02 18:35:29,273 >> Image processor Qwen2VLImageProcessorFast {\r\n",
      "  \"crop_size\": null,\r\n",
      "  \"data_format\": \"channels_first\",\r\n",
      "  \"default_to_square\": true,\r\n",
      "  \"device\": null,\r\n",
      "  \"disable_grouping\": null,\r\n",
      "  \"do_center_crop\": null,\r\n",
      "  \"do_convert_rgb\": true,\r\n",
      "  \"do_normalize\": true,\r\n",
      "  \"do_pad\": null,\r\n",
      "  \"do_rescale\": true,\r\n",
      "  \"do_resize\": true,\r\n",
      "  \"image_mean\": [\r\n",
      "    0.48145466,\r\n",
      "    0.4578275,\r\n",
      "    0.40821073\r\n",
      "  ],\r\n",
      "  \"image_processor_type\": \"Qwen2VLImageProcessorFast\",\r\n",
      "  \"image_std\": [\r\n",
      "    0.26862954,\r\n",
      "    0.26130258,\r\n",
      "    0.27577711\r\n",
      "  ],\r\n",
      "  \"input_data_format\": null,\r\n",
      "  \"max_pixels\": 12845056,\r\n",
      "  \"merge_size\": 2,\r\n",
      "  \"min_pixels\": 3136,\r\n",
      "  \"pad_size\": null,\r\n",
      "  \"patch_size\": 14,\r\n",
      "  \"processor_class\": \"Qwen2VLProcessor\",\r\n",
      "  \"resample\": 3,\r\n",
      "  \"rescale_factor\": 0.00392156862745098,\r\n",
      "  \"return_tensors\": null,\r\n",
      "  \"size\": {\r\n",
      "    \"longest_edge\": 12845056,\r\n",
      "    \"shortest_edge\": 3136\r\n",
      "  },\r\n",
      "  \"temporal_patch_size\": 2\r\n",
      "}\r\n",
      "\r\n",
      "[INFO|tokenization_utils_base.py:2095] 2026-01-02 18:35:29,312 >> loading file vocab.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2-VL-7B-Instruct/snapshots/eed13092ef92e448dd6875b2a00151bd3f7db0ac/vocab.json\r\n",
      "[INFO|tokenization_utils_base.py:2095] 2026-01-02 18:35:29,312 >> loading file merges.txt from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2-VL-7B-Instruct/snapshots/eed13092ef92e448dd6875b2a00151bd3f7db0ac/merges.txt\r\n",
      "[INFO|tokenization_utils_base.py:2095] 2026-01-02 18:35:29,312 >> loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2-VL-7B-Instruct/snapshots/eed13092ef92e448dd6875b2a00151bd3f7db0ac/tokenizer.json\r\n",
      "[INFO|tokenization_utils_base.py:2095] 2026-01-02 18:35:29,312 >> loading file added_tokens.json from cache at None\r\n",
      "[INFO|tokenization_utils_base.py:2095] 2026-01-02 18:35:29,312 >> loading file special_tokens_map.json from cache at None\r\n",
      "[INFO|tokenization_utils_base.py:2095] 2026-01-02 18:35:29,312 >> loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2-VL-7B-Instruct/snapshots/eed13092ef92e448dd6875b2a00151bd3f7db0ac/tokenizer_config.json\r\n",
      "[INFO|tokenization_utils_base.py:2095] 2026-01-02 18:35:29,312 >> loading file chat_template.jinja from cache at None\r\n",
      "[INFO|tokenization_utils_base.py:2364] 2026-01-02 18:35:29,537 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\r\n",
      "[INFO|video_processing_utils.py:726] 2026-01-02 18:35:29,598 >> loading configuration file video_preprocessor_config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2-VL-7B-Instruct/snapshots/eed13092ef92e448dd6875b2a00151bd3f7db0ac/preprocessor_config.json\r\n",
      "[INFO|video_processing_utils.py:770] 2026-01-02 18:35:29,603 >> Video processor Qwen2VLVideoProcessor {\r\n",
      "  \"crop_size\": null,\r\n",
      "  \"data_format\": \"channels_first\",\r\n",
      "  \"default_to_square\": true,\r\n",
      "  \"device\": null,\r\n",
      "  \"do_center_crop\": null,\r\n",
      "  \"do_convert_rgb\": true,\r\n",
      "  \"do_normalize\": true,\r\n",
      "  \"do_rescale\": true,\r\n",
      "  \"do_resize\": true,\r\n",
      "  \"do_sample_frames\": false,\r\n",
      "  \"fps\": null,\r\n",
      "  \"image_mean\": [\r\n",
      "    0.48145466,\r\n",
      "    0.4578275,\r\n",
      "    0.40821073\r\n",
      "  ],\r\n",
      "  \"image_std\": [\r\n",
      "    0.26862954,\r\n",
      "    0.26130258,\r\n",
      "    0.27577711\r\n",
      "  ],\r\n",
      "  \"input_data_format\": null,\r\n",
      "  \"max_frames\": 768,\r\n",
      "  \"max_pixels\": 12845056,\r\n",
      "  \"merge_size\": 2,\r\n",
      "  \"min_frames\": 4,\r\n",
      "  \"min_pixels\": 3136,\r\n",
      "  \"num_frames\": null,\r\n",
      "  \"pad_size\": null,\r\n",
      "  \"patch_size\": 14,\r\n",
      "  \"processor_class\": \"Qwen2VLProcessor\",\r\n",
      "  \"resample\": 3,\r\n",
      "  \"rescale_factor\": 0.00392156862745098,\r\n",
      "  \"return_metadata\": false,\r\n",
      "  \"size\": {\r\n",
      "    \"longest_edge\": 12845056,\r\n",
      "    \"shortest_edge\": 3136\r\n",
      "  },\r\n",
      "  \"temporal_patch_size\": 2,\r\n",
      "  \"video_metadata\": null,\r\n",
      "  \"video_processor_type\": \"Qwen2VLVideoProcessor\"\r\n",
      "}\r\n",
      "\r\n",
      "chat_template.json: 1.05kB [00:00, 8.67MB/s]\r\n",
      "[INFO|processing_utils.py:1116] 2026-01-02 18:35:29,706 >> loading configuration file processor_config.json from cache at None\r\n",
      "[INFO|processing_utils.py:1199] 2026-01-02 18:35:30,097 >> Processor Qwen2VLProcessor:\r\n",
      "- image_processor: Qwen2VLImageProcessorFast {\r\n",
      "  \"crop_size\": null,\r\n",
      "  \"data_format\": \"channels_first\",\r\n",
      "  \"default_to_square\": true,\r\n",
      "  \"device\": null,\r\n",
      "  \"disable_grouping\": null,\r\n",
      "  \"do_center_crop\": null,\r\n",
      "  \"do_convert_rgb\": true,\r\n",
      "  \"do_normalize\": true,\r\n",
      "  \"do_pad\": null,\r\n",
      "  \"do_rescale\": true,\r\n",
      "  \"do_resize\": true,\r\n",
      "  \"image_mean\": [\r\n",
      "    0.48145466,\r\n",
      "    0.4578275,\r\n",
      "    0.40821073\r\n",
      "  ],\r\n",
      "  \"image_processor_type\": \"Qwen2VLImageProcessorFast\",\r\n",
      "  \"image_std\": [\r\n",
      "    0.26862954,\r\n",
      "    0.26130258,\r\n",
      "    0.27577711\r\n",
      "  ],\r\n",
      "  \"input_data_format\": null,\r\n",
      "  \"max_pixels\": 12845056,\r\n",
      "  \"merge_size\": 2,\r\n",
      "  \"min_pixels\": 3136,\r\n",
      "  \"pad_size\": null,\r\n",
      "  \"patch_size\": 14,\r\n",
      "  \"processor_class\": \"Qwen2VLProcessor\",\r\n",
      "  \"resample\": 3,\r\n",
      "  \"rescale_factor\": 0.00392156862745098,\r\n",
      "  \"return_tensors\": null,\r\n",
      "  \"size\": {\r\n",
      "    \"longest_edge\": 12845056,\r\n",
      "    \"shortest_edge\": 3136\r\n",
      "  },\r\n",
      "  \"temporal_patch_size\": 2\r\n",
      "}\r\n",
      "\r\n",
      "- tokenizer: Qwen2TokenizerFast(name_or_path='Qwen/Qwen2-VL-7B-Instruct', vocab_size=151643, model_max_length=32768, is_fast=True, padding_side='left', truncation_side='right', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={\r\n",
      "\t151643: AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\r\n",
      "\t151644: AddedToken(\"<|im_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\r\n",
      "\t151645: AddedToken(\"<|im_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\r\n",
      "\t151646: AddedToken(\"<|object_ref_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\r\n",
      "\t151647: AddedToken(\"<|object_ref_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\r\n",
      "\t151648: AddedToken(\"<|box_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\r\n",
      "\t151649: AddedToken(\"<|box_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\r\n",
      "\t151650: AddedToken(\"<|quad_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\r\n",
      "\t151651: AddedToken(\"<|quad_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\r\n",
      "\t151652: AddedToken(\"<|vision_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\r\n",
      "\t151653: AddedToken(\"<|vision_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\r\n",
      "\t151654: AddedToken(\"<|vision_pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\r\n",
      "\t151655: AddedToken(\"<|image_pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\r\n",
      "\t151656: AddedToken(\"<|video_pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\r\n",
      "}\r\n",
      ")\r\n",
      "- video_processor: Qwen2VLVideoProcessor {\r\n",
      "  \"crop_size\": null,\r\n",
      "  \"data_format\": \"channels_first\",\r\n",
      "  \"default_to_square\": true,\r\n",
      "  \"device\": null,\r\n",
      "  \"do_center_crop\": null,\r\n",
      "  \"do_convert_rgb\": true,\r\n",
      "  \"do_normalize\": true,\r\n",
      "  \"do_rescale\": true,\r\n",
      "  \"do_resize\": true,\r\n",
      "  \"do_sample_frames\": false,\r\n",
      "  \"fps\": null,\r\n",
      "  \"image_mean\": [\r\n",
      "    0.48145466,\r\n",
      "    0.4578275,\r\n",
      "    0.40821073\r\n",
      "  ],\r\n",
      "  \"image_std\": [\r\n",
      "    0.26862954,\r\n",
      "    0.26130258,\r\n",
      "    0.27577711\r\n",
      "  ],\r\n",
      "  \"input_data_format\": null,\r\n",
      "  \"max_frames\": 768,\r\n",
      "  \"max_pixels\": 12845056,\r\n",
      "  \"merge_size\": 2,\r\n",
      "  \"min_frames\": 4,\r\n",
      "  \"min_pixels\": 3136,\r\n",
      "  \"num_frames\": null,\r\n",
      "  \"pad_size\": null,\r\n",
      "  \"patch_size\": 14,\r\n",
      "  \"processor_class\": \"Qwen2VLProcessor\",\r\n",
      "  \"resample\": 3,\r\n",
      "  \"rescale_factor\": 0.00392156862745098,\r\n",
      "  \"return_metadata\": false,\r\n",
      "  \"size\": {\r\n",
      "    \"longest_edge\": 12845056,\r\n",
      "    \"shortest_edge\": 3136\r\n",
      "  },\r\n",
      "  \"temporal_patch_size\": 2,\r\n",
      "  \"video_metadata\": null,\r\n",
      "  \"video_processor_type\": \"Qwen2VLVideoProcessor\"\r\n",
      "}\r\n",
      "\r\n",
      "\r\n",
      "{\r\n",
      "  \"processor_class\": \"Qwen2VLProcessor\"\r\n",
      "}\r\n",
      "\r\n",
      "[INFO|2026-01-02 18:35:30] llamafactory.data.loader:143 >> Loading dataset /kaggle/working/data/vqa_train_abs.json...\r\n",
      "Setting num_proc from 4 back to 1 for the train split to disable multiprocessing as it only contains one shard.\r\n",
      "WARNING:datasets.builder:Setting num_proc from 4 back to 1 for the train split to disable multiprocessing as it only contains one shard.\r\n",
      "Generating train split: 7598 examples [00:00, 23911.90 examples/s]\r\n",
      "Converting format of dataset (num_proc=4): 100%|█| 7598/7598 [00:02<00:00, 3743.\r\n",
      "[INFO|2026-01-02 18:35:32] llamafactory.data.loader:143 >> Loading dataset /kaggle/working/data/vqa_eval_abs.json...\r\n",
      "Setting num_proc from 4 back to 1 for the train split to disable multiprocessing as it only contains one shard.\r\n",
      "WARNING:datasets.builder:Setting num_proc from 4 back to 1 for the train split to disable multiprocessing as it only contains one shard.\r\n",
      "Generating train split: 60 examples [00:00, 7654.54 examples/s]\r\n",
      "Converting format of dataset (num_proc=4): 100%|█| 60/60 [00:00<00:00, 305.70 ex\r\n",
      "Running tokenizer on dataset (num_proc=4):   0%| | 0/7598 [00:00<?, ? examples/s/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\r\n",
      "  warnings.warn(\r\n",
      "Running tokenizer on dataset (num_proc=4): 100%|█| 7598/7598 [02:30<00:00, 50.61\r\n",
      "training example:\r\n",
      "input_ids:\r\n",
      "[151644, 8948, 198, 94917, 37915, 128886, 128356, 647, 47522, 128744, 128265, 128717, 128353, 47742, 128683, 128585, 128324, 29974, 13, 1163, 21742, 128814, 129260, 129087, 126258, 64, 128273, 472, 144201, 51271, 220, 126884, 51271, 37915, 128311, 13, 386, 9574, 134358, 128338, 128492, 47742, 128683, 128450, 80577, 98127, 37915, 92430, 24790, 270, 309, 132123, 11, 28776, 128254, 53037, 128311, 129207, 13, 29458, 70248, 128482, 130623, 39339, 128430, 128486, 128745, 131307, 128304, 94994, 128360, 382, 5757, 56, 350, 144166, 34, 425, 144166, 51, 54029, 135137, 34, 510, 16, 13, 6826, 144354, 129477, 128814, 128411, 128607, 128324, 77374, 69611, 89218, 88, 11, 350, 31301, 135382, 51, 50327, 135211, 40, 80355, 131371, 6140, 128469, 128607, 1163, 2185, 11, 130442, 11, 129898, 17669, 128633, 128880, 137425, 133687, 128352, 128354, 624, 17, 13, 136091, 128284, 128311, 134358, 128607, 128324, 129311, 128250, 131575, 1091, 71, 129315, 624, 18, 13, 1163, 21742, 128814, 129398, 135111, 11, 28776, 133795, 134383, 47742, 128926, 129061, 13, 151645, 198, 151644, 872, 198, 151652, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151653, 271, 35, 126599, 86139, 130179, 134358, 128338, 128492, 25, 137515, 128492, 2600, 128391, 128249, 89451, 129826, 128634, 128348, 128353, 128284, 128249, 129141, 272, 94313, 293, 124431, 128411, 140531, 128865, 856, 27924, 135676, 20303, 124646, 13, 356, 94313, 293, 124431, 28776, 46051, 128278, 63478, 136822, 86139, 46051, 129213, 59735, 89451, 129826, 11, 128430, 89451, 129826, 130719, 133863, 13, 425, 963, 129826, 131945, 129970, 270, 359, 134248, 274, 82026, 856, 27924, 130595, 11, 132543, 128865, 856, 35234, 11, 50196, 13535, 53022, 128254, 270, 3441, 128865, 135342, 13, 425, 963, 129826, 128348, 130719, 133863, 11, 46051, 129213, 59735, 89451, 129826, 63478, 129566, 130052, 132457, 128944, 46051, 128278, 272, 94313, 293, 124431, 382, 98041, 24790, 128683, 128450, 69086, 128492, 25, 129182, 28776, 128683, 128450, 382, 72572, 70248, 128482, 128717, 128353, 47742, 128683, 128585, 510, 50, 61031, 128283, 129054, 59735, 125440, 46051, 128433, 130849, 595, 383, 78, 481, 129045, 128573, 47742, 128283, 128479, 481, 2600, 128391, 128277, 128907, 130249, 47742, 129363, 128365, 128745, 128740, 59735, 128683, 128585, 128324, 29974, 13, 220, 133357, 128362, 128531, 59735, 130849, 595, 383, 78, 128283, 128479, 128430, 129659, 128971, 96535, 128424, 136855, 63478, 128250, 128271, 128251, 128304, 11, 128788, 128589, 37915, 69086, 128334, 129065, 458, 128401, 128304, 382, 40225, 72, 130849, 595, 383, 78, 37915, 129659, 128971, 128394, 342, 1103, 28776, 128717, 128353, 129986, 129169, 128269, 128324, 29974, 11, 128415, 128283, 94576, 128327, 71800, 139518, 11, 136822, 132726, 128250, 128790, 130917, 59735, 128271, 128314, 128457, 382, 34, 124692, 129087, 25, 2055, 274, 124415, 130849, 595, 383, 78, 69086, 128338, 128492, 128250, 130849, 595, 383, 78, 129045, 128573, 128269, 128324, 29974, 1939, 39, 3202, 88, 129477, 128814, 128411, 128607, 128324, 129311, 320, 75729, 131371, 6140, 128469, 128607, 1163, 2185, 17669, 137425, 133687, 128354, 568, 129024, 129831, 128319, 11, 129805, 272, 2185, 128376, 128486, 128745, 25798, 128861, 11, 128431, 129598, 128683, 128585, 47742, 293, 87939, 129111, 128717, 128353, 13, 151645, 198, 151644, 77091, 198, 34, 6362, 595, 383, 78, 69086, 128492, 128283, 128479, 128304, 382, 34, 6362, 595, 383, 78, 129045, 128573, 128454, 63478, 128266, 94576, 133105, 128475, 4258, 11, 28776, 128422, 128495, 128666, 130631, 128304, 13, 220, 356, 6362, 595, 383, 78, 69086, 128338, 128492, 28776, 130525, 63478, 128266, 94576, 55784, 128433, 11, 128422, 128495, 130052, 132457, 47742, 458, 128401, 128304, 11, 28776, 128254, 130925, 128740, 128575, 129311, 458, 128401, 128283, 128479, 13, 133357, 128354, 128589, 96535, 131084, 18698, 16719, 128277, 128362, 128531, 47742, 128745, 128740, 59735, 129659, 128971, 128394, 342, 1103, 128250, 128334, 129065, 128283, 128479, 13, 151645, 198]\r\n",
      "inputs:\r\n",
      "<|im_start|>system\r\n",
      "Bạn là trợ lý VQA chuyên về lịch sử và văn hóa Việt Nam. Trả lời câu hỏi dựa trên HÌNH ẢNH là chính. Mô tả hình ảnh và văn bản OCR chỉ là thông tin tham khảo, có thể không chính xác. Kiến thức bổ sung giúp giải thích sâu hơn khi cần.\r\n",
      "\r\n",
      "QUY TẮC BẮT BUỘC:\r\n",
      "1. CHỈ trả lời bằng tiếng Việt thuần túy, TUYỆT ĐỐI KHÔNG dùng tiếng Trung, Hàn, Nhật hay bất kỳ ngôn ngữ nào khác.\r\n",
      "2. Sử dụng chính tả tiếng Việt chuẩn với dấu thanh đúng.\r\n",
      "3. Trả lời rõ ràng, có cấu trúc và dễ hiểu.<|im_end|>\r\n",
      "<|im_start|>user\r\n",
      "<|vision_start|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|vision_end|>\r\n",
      "\r\n",
      "Dựa vào mô tả hình ảnh: Hình ảnh cho thấy một bé gái trẻ đang sử dụng một chiếc cột bắc bằng nhựa màu xanh dương nhạt. Cột bắc có hai đầu được gắn vào hai chân của bé gái, giúp bé gái đứng thẳng. Bé gái mặc áo thun kẻ sọc xanh trắng, quần màu xám, mang giày thể thao màu hồng. Bé gái đang đứng thẳng, hai chân của bé gái được giữ chắc chắn bởi hai đầu cột bắc.\r\n",
      "\r\n",
      "Thông tin văn bản trong ảnh: Không có văn bản.\r\n",
      "\r\n",
      "Kiến thức lịch sử và văn hóa:\r\n",
      "Sự hiện diện của cả hai loại cà kheo - truyền thống và hiện đại - cho thấy sự đa dạng và khả năng thích ứng của văn hóa Việt Nam.  Sự phát triển của cà kheo hiện đại giúp trò chơi này tiếp cận được với nhiều người hơn, đặc biệt là trong điều kiện an toàn hơn.\r\n",
      "\r\n",
      "Đi cà kheo là trò chơi dân gian có lịch sử lâu đời ở Việt Nam, xuất hiện từ thời xa xưa, gắn liền với tuổi thơ của nhiều thế hệ.\r\n",
      "\r\n",
      "Câu hỏi: So sánh cà kheo trong hình ảnh với cà kheo truyền thống ở Việt Nam?\r\n",
      "\r\n",
      "Hãy trả lời bằng tiếng Việt chuẩn (KHÔNG dùng tiếng Trung hay ngôn ngữ khác). Nếu phù hợp, hãy cung cấp giải thích chi tiết, ý nghĩa văn hóa và bối cảnh lịch sử.<|im_end|>\r\n",
      "<|im_start|>assistant\r\n",
      "Cà kheo trong ảnh hiện đại hơn.\r\n",
      "\r\n",
      "Cà kheo truyền thống thường được làm từ gỗ hoặc tre, có thiết kế đơn giản hơn.  Cà kheo trong hình ảnh có vẻ được làm từ kim loại, thiết kế chắc chắn và an toàn hơn, có thể đáp ứng tiêu chuẩn an toàn hiện đại. Sự khác biệt này phản ánh sự phát triển và thích ứng của trò chơi dân gian với điều kiện hiện đại.<|im_end|>\r\n",
      "\r\n",
      "label_ids:\r\n",
      "[-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 34, 6362, 595, 383, 78, 69086, 128492, 128283, 128479, 128304, 382, 34, 6362, 595, 383, 78, 129045, 128573, 128454, 63478, 128266, 94576, 133105, 128475, 4258, 11, 28776, 128422, 128495, 128666, 130631, 128304, 13, 220, 356, 6362, 595, 383, 78, 69086, 128338, 128492, 28776, 130525, 63478, 128266, 94576, 55784, 128433, 11, 128422, 128495, 130052, 132457, 47742, 458, 128401, 128304, 11, 28776, 128254, 130925, 128740, 128575, 129311, 458, 128401, 128283, 128479, 13, 133357, 128354, 128589, 96535, 131084, 18698, 16719, 128277, 128362, 128531, 47742, 128745, 128740, 59735, 129659, 128971, 128394, 342, 1103, 128250, 128334, 129065, 128283, 128479, 13, 151645, 198]\r\n",
      "labels:\r\n",
      "Cà kheo trong ảnh hiện đại hơn.\r\n",
      "\r\n",
      "Cà kheo truyền thống thường được làm từ gỗ hoặc tre, có thiết kế đơn giản hơn.  Cà kheo trong hình ảnh có vẻ được làm từ kim loại, thiết kế chắc chắn và an toàn hơn, có thể đáp ứng tiêu chuẩn an toàn hiện đại. Sự khác biệt này phản ánh sự phát triển và thích ứng của trò chơi dân gian với điều kiện hiện đại.<|im_end|>\r\n",
      "\r\n",
      "Running tokenizer on dataset (num_proc=4): 100%|█| 60/60 [00:02<00:00, 29.98 exa\r\n",
      "eval example:\r\n",
      "input_ids:\r\n",
      "[151644, 8948, 198, 94917, 37915, 128886, 128356, 647, 47522, 128744, 128265, 128717, 128353, 47742, 128683, 128585, 128324, 29974, 13, 1163, 21742, 128814, 129260, 129087, 126258, 64, 128273, 472, 144201, 51271, 220, 126884, 51271, 37915, 128311, 13, 386, 9574, 134358, 128338, 128492, 47742, 128683, 128450, 80577, 98127, 37915, 92430, 24790, 270, 309, 132123, 11, 28776, 128254, 53037, 128311, 129207, 13, 29458, 70248, 128482, 130623, 39339, 128430, 128486, 128745, 131307, 128304, 94994, 128360, 382, 5757, 56, 350, 144166, 34, 425, 144166, 51, 54029, 135137, 34, 510, 16, 13, 6826, 144354, 129477, 128814, 128411, 128607, 128324, 77374, 69611, 89218, 88, 11, 350, 31301, 135382, 51, 50327, 135211, 40, 80355, 131371, 6140, 128469, 128607, 1163, 2185, 11, 130442, 11, 129898, 17669, 128633, 128880, 137425, 133687, 128352, 128354, 624, 17, 13, 136091, 128284, 128311, 134358, 128607, 128324, 129311, 128250, 131575, 1091, 71, 129315, 624, 18, 13, 1163, 21742, 128814, 129398, 135111, 11, 28776, 133795, 134383, 47742, 128926, 129061, 13, 151645, 198, 151644, 872, 198, 151652, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151653, 271, 35, 126599, 86139, 130179, 134358, 128338, 128492, 25, 137515, 128492, 2600, 128391, 128249, 128564, 141305, 143897, 128273, 134782, 11, 128250, 128249, 390, 435, 124483, 63478, 489, 524, 128597, 128411, 128865, 856, 27924, 135676, 47742, 130180, 13, 220, 129016, 128271, 128251, 270, 309, 94995, 11, 129202, 125440, 128582, 131945, 129970, 1319, 3441, 128865, 6592, 47742, 129188, 130909, 128865, 856, 27924, 53638, 129368, 13, 220, 129005, 128251, 128348, 134650, 128249, 129368, 521, 97516, 11, 28776, 128254, 37915, 128251, 521, 4458, 78, 143897, 13, 220, 451, 69243, 37915, 128387, 128301, 11, 28776, 128249, 131302, 128432, 129590, 22708, 382, 98041, 24790, 128683, 128450, 69086, 128492, 25, 129182, 28776, 128683, 128450, 382, 72572, 70248, 128482, 128717, 128353, 47742, 128683, 128585, 510, 40225, 4284, 143897, 435, 124483, 37915, 128249, 129659, 128971, 128394, 342, 1103, 128254, 128283, 259, 20868, 129719, 129675, 128403, 11, 128738, 128818, 47742, 128277, 23165, 88477, 62728, 78, 59735, 128251, 128324, 13, 131031, 136822, 132726, 128250, 128683, 137692, 326, 89639, 128301, 47742, 78228, 131309, 128410, 129045, 128573, 382, 1282, 125593, 128573, 141305, 143897, 435, 124483, 28776, 129738, 134766, 94576, 129986, 129169, 11, 28776, 128254, 128542, 128457, 128263, 128683, 128585, 326, 89639, 128301, 47742, 129913, 7777, 126726, 139900, 272, 125446, 59735, 128251, 128324, 13, 220, 131160, 308, 352, 11, 141305, 143897, 435, 124483, 63478, 126341, 128502, 128260, 128249, 129659, 128971, 128254, 270, 3441, 11, 129566, 342, 126368, 128450, 129222, 128683, 137692, 382, 34, 124692, 129087, 25, 130244, 37915, 128382, 1939, 39, 3202, 88, 129477, 128814, 128411, 128607, 128324, 129311, 320, 75729, 131371, 6140, 128469, 128607, 1163, 2185, 17669, 137425, 133687, 128354, 568, 129024, 129831, 128319, 11, 129805, 272, 2185, 128376, 128486, 128745, 25798, 128861, 11, 128431, 129598, 128683, 128585, 47742, 293, 87939, 129111, 128717, 128353, 13, 151645, 198, 151644, 77091, 198, 44, 94313, 128564, 141305, 143897, 435, 124483, 382, 39, 58506, 128492, 128254, 128283, 128249, 129188, 128348, 270, 309, 94995, 128564, 141305, 143897, 435, 124483, 13, 663, 125593, 435, 124483, 37915, 128249, 128433, 143897, 129121, 11, 128278, 143897, 63478, 141619, 132611, 128338, 128278, 435, 124483, 11, 128454, 63478, 128353, 128284, 69086, 78228, 128564, 141305, 129045, 128573, 13, 151645, 198]\r\n",
      "inputs:\r\n",
      "<|im_start|>system\r\n",
      "Bạn là trợ lý VQA chuyên về lịch sử và văn hóa Việt Nam. Trả lời câu hỏi dựa trên HÌNH ẢNH là chính. Mô tả hình ảnh và văn bản OCR chỉ là thông tin tham khảo, có thể không chính xác. Kiến thức bổ sung giúp giải thích sâu hơn khi cần.\r\n",
      "\r\n",
      "QUY TẮC BẮT BUỘC:\r\n",
      "1. CHỈ trả lời bằng tiếng Việt thuần túy, TUYỆT ĐỐI KHÔNG dùng tiếng Trung, Hàn, Nhật hay bất kỳ ngôn ngữ nào khác.\r\n",
      "2. Sử dụng chính tả tiếng Việt chuẩn với dấu thanh đúng.\r\n",
      "3. Trả lời rõ ràng, có cấu trúc và dễ hiểu.<|im_end|>\r\n",
      "<|im_start|>user\r\n",
      "<|vision_start|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|vision_end|>\r\n",
      "\r\n",
      "Dựa vào mô tả hình ảnh: Hình ảnh cho thấy một cuộc đua thuyền trên sông, với một con rồng được trang trí bằng màu xanh dương và vàng.  Có nhiều người tham gia, tất cả đều mặc áo phao màu cam và đội khăn màu xanh lá cây.  Một người đang cầm một cây chổi, có thể là người chèo thuyền.  Nền là mặt nước, có một vài quả bóng bay.\r\n",
      "\r\n",
      "Thông tin văn bản trong ảnh: Không có văn bản.\r\n",
      "\r\n",
      "Kiến thức lịch sử và văn hóa:\r\n",
      "Đua thuyền rồng là một trò chơi dân gian thể hiện tinh thần đoàn kết, sức mạnh và sự khéo léo của người Việt. Nó gắn liền với văn hoá lúa nước và các lễ hội truyền thống.\r\n",
      "\r\n",
      "Truyền thống đua thuyền rồng có nguồn gốc từ lâu đời, có thể liên hệ đến văn hóa lúa nước và tín ngưỡng thờ cúng của người Việt.  Ngày nay, đua thuyền rồng được tổ chức như một trò chơi thể thao, giữ gìn bản sắc văn hoá.\r\n",
      "\r\n",
      "Câu hỏi: Đây là gì?\r\n",
      "\r\n",
      "Hãy trả lời bằng tiếng Việt chuẩn (KHÔNG dùng tiếng Trung hay ngôn ngữ khác). Nếu phù hợp, hãy cung cấp giải thích chi tiết, ý nghĩa văn hóa và bối cảnh lịch sử.<|im_end|>\r\n",
      "<|im_start|>assistant\r\n",
      "Một cuộc đua thuyền rồng.\r\n",
      "\r\n",
      "Hình ảnh thể hiện một đội đang tham gia cuộc đua thuyền rồng. Thuyền rồng là một loại thuyền dài, đầu thuyền được chạm khắc hình đầu rồng, thường được sử dụng trong các cuộc đua truyền thống.<|im_end|>\r\n",
      "\r\n",
      "label_ids:\r\n",
      "[-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 44, 94313, 128564, 141305, 143897, 435, 124483, 382, 39, 58506, 128492, 128254, 128283, 128249, 129188, 128348, 270, 309, 94995, 128564, 141305, 143897, 435, 124483, 13, 663, 125593, 435, 124483, 37915, 128249, 128433, 143897, 129121, 11, 128278, 143897, 63478, 141619, 132611, 128338, 128278, 435, 124483, 11, 128454, 63478, 128353, 128284, 69086, 78228, 128564, 141305, 129045, 128573, 13, 151645, 198]\r\n",
      "labels:\r\n",
      "Một cuộc đua thuyền rồng.\r\n",
      "\r\n",
      "Hình ảnh thể hiện một đội đang tham gia cuộc đua thuyền rồng. Thuyền rồng là một loại thuyền dài, đầu thuyền được chạm khắc hình đầu rồng, thường được sử dụng trong các cuộc đua truyền thống.<|im_end|>\r\n",
      "\r\n",
      "config.json: 1.20kB [00:00, 10.2MB/s]\r\n",
      "[INFO|configuration_utils.py:765] 2026-01-02 18:38:05,148 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2-VL-7B-Instruct/snapshots/eed13092ef92e448dd6875b2a00151bd3f7db0ac/config.json\r\n",
      "[INFO|configuration_utils.py:839] 2026-01-02 18:38:05,150 >> Model config Qwen2VLConfig {\r\n",
      "  \"architectures\": [\r\n",
      "    \"Qwen2VLForConditionalGeneration\"\r\n",
      "  ],\r\n",
      "  \"attention_dropout\": 0.0,\r\n",
      "  \"bos_token_id\": 151643,\r\n",
      "  \"dtype\": \"bfloat16\",\r\n",
      "  \"eos_token_id\": 151645,\r\n",
      "  \"hidden_act\": \"silu\",\r\n",
      "  \"hidden_size\": 3584,\r\n",
      "  \"image_token_id\": 151655,\r\n",
      "  \"initializer_range\": 0.02,\r\n",
      "  \"intermediate_size\": 18944,\r\n",
      "  \"max_position_embeddings\": 32768,\r\n",
      "  \"max_window_layers\": 28,\r\n",
      "  \"model_type\": \"qwen2_vl\",\r\n",
      "  \"num_attention_heads\": 28,\r\n",
      "  \"num_hidden_layers\": 28,\r\n",
      "  \"num_key_value_heads\": 4,\r\n",
      "  \"rms_norm_eps\": 1e-06,\r\n",
      "  \"rope_scaling\": {\r\n",
      "    \"mrope_section\": [\r\n",
      "      16,\r\n",
      "      24,\r\n",
      "      24\r\n",
      "    ],\r\n",
      "    \"rope_type\": \"default\",\r\n",
      "    \"type\": \"default\"\r\n",
      "  },\r\n",
      "  \"rope_theta\": 1000000.0,\r\n",
      "  \"sliding_window\": 32768,\r\n",
      "  \"text_config\": {\r\n",
      "    \"_name_or_path\": \"Qwen/Qwen2-VL-7B-Instruct\",\r\n",
      "    \"architectures\": [\r\n",
      "      \"Qwen2VLForConditionalGeneration\"\r\n",
      "    ],\r\n",
      "    \"attention_dropout\": 0.0,\r\n",
      "    \"bos_token_id\": 151643,\r\n",
      "    \"dtype\": \"bfloat16\",\r\n",
      "    \"eos_token_id\": 151645,\r\n",
      "    \"hidden_act\": \"silu\",\r\n",
      "    \"hidden_size\": 3584,\r\n",
      "    \"initializer_range\": 0.02,\r\n",
      "    \"intermediate_size\": 18944,\r\n",
      "    \"layer_types\": [\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\"\r\n",
      "    ],\r\n",
      "    \"max_position_embeddings\": 32768,\r\n",
      "    \"max_window_layers\": 28,\r\n",
      "    \"model_type\": \"qwen2_vl_text\",\r\n",
      "    \"num_attention_heads\": 28,\r\n",
      "    \"num_hidden_layers\": 28,\r\n",
      "    \"num_key_value_heads\": 4,\r\n",
      "    \"rms_norm_eps\": 1e-06,\r\n",
      "    \"rope_scaling\": {\r\n",
      "      \"mrope_section\": [\r\n",
      "        16,\r\n",
      "        24,\r\n",
      "        24\r\n",
      "      ],\r\n",
      "      \"rope_type\": \"default\",\r\n",
      "      \"type\": \"default\"\r\n",
      "    },\r\n",
      "    \"rope_theta\": 1000000.0,\r\n",
      "    \"sliding_window\": null,\r\n",
      "    \"use_cache\": true,\r\n",
      "    \"use_sliding_window\": false,\r\n",
      "    \"vision_token_id\": 151654,\r\n",
      "    \"vocab_size\": 152064\r\n",
      "  },\r\n",
      "  \"tie_word_embeddings\": false,\r\n",
      "  \"transformers_version\": \"4.57.1\",\r\n",
      "  \"use_cache\": true,\r\n",
      "  \"use_sliding_window\": false,\r\n",
      "  \"video_token_id\": 151656,\r\n",
      "  \"vision_config\": {\r\n",
      "    \"depth\": 32,\r\n",
      "    \"embed_dim\": 1280,\r\n",
      "    \"hidden_act\": \"quick_gelu\",\r\n",
      "    \"hidden_size\": 3584,\r\n",
      "    \"in_channels\": 3,\r\n",
      "    \"in_chans\": 3,\r\n",
      "    \"initializer_range\": 0.02,\r\n",
      "    \"mlp_ratio\": 4,\r\n",
      "    \"model_type\": \"qwen2_vl\",\r\n",
      "    \"num_heads\": 16,\r\n",
      "    \"patch_size\": 14,\r\n",
      "    \"spatial_merge_size\": 2,\r\n",
      "    \"spatial_patch_size\": 14,\r\n",
      "    \"temporal_patch_size\": 2\r\n",
      "  },\r\n",
      "  \"vision_end_token_id\": 151653,\r\n",
      "  \"vision_start_token_id\": 151652,\r\n",
      "  \"vision_token_id\": 151654,\r\n",
      "  \"vocab_size\": 152064\r\n",
      "}\r\n",
      "\r\n",
      "[INFO|2026-01-02 18:38:05] llamafactory.model.model_utils.kv_cache:143 >> KV cache is disabled during training.\r\n",
      "[WARNING|logging.py:328] 2026-01-02 18:38:07,663 >> `torch_dtype` is deprecated! Use `dtype` instead!\r\n",
      "model.safetensors.index.json: 56.5kB [00:00, 215MB/s]\r\n",
      "[INFO|modeling_utils.py:1172] 2026-01-02 18:38:07,720 >> loading weights file model.safetensors from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2-VL-7B-Instruct/snapshots/eed13092ef92e448dd6875b2a00151bd3f7db0ac/model.safetensors.index.json\r\n",
      "Fetching 5 files:   0%|                                   | 0/5 [00:00<?, ?it/s]\r\n",
      "model-00001-of-00005.safetensors:   0%|             | 0.00/3.90G [00:00<?, ?B/s]\u001b[A\r\n",
      "\r\n",
      "model-00004-of-00005.safetensors:   0%|             | 0.00/3.86G [00:00<?, ?B/s]\u001b[A\u001b[A\r\n",
      "\r\n",
      "\r\n",
      "model-00002-of-00005.safetensors:   0%|             | 0.00/3.86G [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "model-00005-of-00005.safetensors:   0%|             | 0.00/1.09G [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "model-00003-of-00005.safetensors:   0%|             | 0.00/3.86G [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\r\n",
      "model-00001-of-00005.safetensors:   0%| | 11.4k/3.90G [00:00<53:08:50, 20.4kB/s]\u001b[A\r\n",
      "\r\n",
      "\r\n",
      "model-00002-of-00005.safetensors:   0%|    | 131k/3.86G [00:00<4:47:50, 224kB/s]\u001b[A\u001b[A\u001b[A\r\n",
      "model-00001-of-00005.safetensors:   1%|    | 35.0M/3.90G [00:00<00:54, 71.1MB/s]\u001b[A\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "model-00005-of-00005.safetensors:   0%|      | 619k/1.09G [00:00<19:14, 943kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "model-00003-of-00005.safetensors:   0%|    | 124k/3.86G [00:00<5:45:00, 187kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\r\n",
      "\r\n",
      "\r\n",
      "model-00002-of-00005.safetensors:   0%|    | 18.3M/3.86G [00:00<01:51, 34.6MB/s]\u001b[A\u001b[A\u001b[A\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "model-00003-of-00005.safetensors:   0%|    | 11.2M/3.86G [00:00<03:29, 18.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\r\n",
      "\r\n",
      "\r\n",
      "model-00002-of-00005.safetensors:   1%|    | 35.7M/3.86G [00:00<01:05, 58.2MB/s]\u001b[A\u001b[A\u001b[A\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "model-00003-of-00005.safetensors:   1%|    | 29.0M/3.86G [00:00<01:27, 44.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\r\n",
      "\r\n",
      "\r\n",
      "model-00002-of-00005.safetensors:   2%|     | 65.7M/3.86G [00:00<00:36, 104MB/s]\u001b[A\u001b[A\u001b[A\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "model-00005-of-00005.safetensors:   1%|    | 9.00M/1.09G [00:00<01:36, 11.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\r\n",
      "model-00001-of-00005.safetensors:   2%|    | 58.7M/3.90G [00:01<00:55, 69.6MB/s]\u001b[A\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "model-00003-of-00005.safetensors:   1%|    | 40.3M/3.86G [00:01<01:28, 43.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\r\n",
      "\r\n",
      "\r\n",
      "model-00002-of-00005.safetensors:   2%|    | 83.0M/3.86G [00:01<00:45, 82.5MB/s]\u001b[A\u001b[A\u001b[A\r\n",
      "model-00001-of-00005.safetensors:   3%|▏     | 120M/3.90G [00:01<00:32, 117MB/s]\u001b[A\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "model-00005-of-00005.safetensors:   7%|▎   | 76.1M/1.09G [00:01<00:12, 79.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "model-00003-of-00005.safetensors:   1%|    | 47.0M/3.86G [00:01<01:22, 46.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\r\n",
      "model-00001-of-00005.safetensors:   7%|▍     | 254M/3.90G [00:01<00:12, 293MB/s]\u001b[A\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "model-00005-of-00005.safetensors:  21%|█▏    | 226M/1.09G [00:01<00:03, 261MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\r\n",
      "\r\n",
      "\r\n",
      "model-00002-of-00005.safetensors:   3%|    | 98.7M/3.86G [00:01<00:46, 80.9MB/s]\u001b[A\u001b[A\u001b[A\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "model-00003-of-00005.safetensors:   1%|    | 54.5M/3.86G [00:01<01:26, 43.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\r\n",
      "model-00001-of-00005.safetensors:   9%|▌     | 356M/3.90G [00:01<00:08, 410MB/s]\u001b[A\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "model-00005-of-00005.safetensors:  38%|██▎   | 419M/1.09G [00:01<00:01, 517MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "model-00003-of-00005.safetensors:   4%|▏     | 138M/3.86G [00:01<00:19, 193MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\r\n",
      "\r\n",
      "\r\n",
      "model-00002-of-00005.safetensors:   3%|▏    | 111M/3.86G [00:01<00:48, 77.2MB/s]\u001b[A\u001b[A\u001b[A\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "model-00005-of-00005.safetensors:  63%|███▊  | 688M/1.09G [00:01<00:00, 871MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "model-00003-of-00005.safetensors:   6%|▎     | 217M/3.86G [00:01<00:16, 216MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "model-00005-of-00005.safetensors:  88%|█████▎| 956M/1.09G [00:02<00:00, 884MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\r\n",
      "\r\n",
      "model-00004-of-00005.safetensors:   0%|    | 5.61M/3.86G [00:02<24:07, 2.67MB/s]\u001b[A\u001b[A\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "model-00003-of-00005.safetensors:   9%|▌     | 351M/3.86G [00:02<00:08, 393MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\r\n",
      "\r\n",
      "\r\n",
      "model-00002-of-00005.safetensors:   3%|▏    | 121M/3.86G [00:02<01:14, 50.4MB/s]\u001b[A\u001b[A\u001b[A\r\n",
      "model-00001-of-00005.safetensors:  12%|▋     | 467M/3.90G [00:02<00:12, 274MB/s]\u001b[A\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "model-00005-of-00005.safetensors: 100%|█████| 1.09G/1.09G [00:02<00:00, 480MB/s]\r\n",
      "\r\n",
      "model-00001-of-00005.safetensors:  14%|▊     | 534M/3.90G [00:02<00:10, 321MB/s]\u001b[A\r\n",
      "\r\n",
      "model-00004-of-00005.safetensors:   0%|    | 15.6M/3.86G [00:02<07:35, 8.46MB/s]\u001b[A\u001b[A\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "model-00003-of-00005.safetensors:  11%|▋     | 431M/3.86G [00:02<00:08, 407MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\r\n",
      "\r\n",
      "\r\n",
      "model-00002-of-00005.safetensors:   3%|▏    | 132M/3.86G [00:02<01:23, 44.5MB/s]\u001b[A\u001b[A\u001b[A\r\n",
      "model-00001-of-00005.safetensors:  17%|█     | 668M/3.90G [00:02<00:07, 429MB/s]\u001b[A\r\n",
      "\r\n",
      "model-00004-of-00005.safetensors:   1%|    | 21.3M/3.86G [00:02<05:29, 11.6MB/s]\u001b[A\u001b[A\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "model-00003-of-00005.safetensors:  13%|▊     | 495M/3.86G [00:02<00:08, 399MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\r\n",
      "\r\n",
      "\r\n",
      "model-00002-of-00005.safetensors:   6%|▍     | 250M/3.86G [00:02<00:19, 190MB/s]\u001b[A\u001b[A\u001b[A\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "model-00003-of-00005.safetensors:  15%|▉     | 593M/3.86G [00:02<00:06, 513MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\r\n",
      "model-00001-of-00005.safetensors:  19%|█▏    | 737M/3.90G [00:02<00:07, 451MB/s]\u001b[A\r\n",
      "\r\n",
      "model-00004-of-00005.safetensors:   3%|▏    | 105M/3.86G [00:02<00:43, 86.5MB/s]\u001b[A\u001b[A\r\n",
      "model-00001-of-00005.safetensors:  21%|█▏    | 805M/3.90G [00:02<00:07, 432MB/s]\u001b[A\r\n",
      "\r\n",
      "\r\n",
      "model-00002-of-00005.safetensors:   8%|▍     | 292M/3.86G [00:02<00:20, 172MB/s]\u001b[A\u001b[A\u001b[A\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "model-00003-of-00005.safetensors:  17%|█     | 657M/3.86G [00:02<00:08, 368MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\r\n",
      "model-00001-of-00005.safetensors:  22%|█▎    | 872M/3.90G [00:02<00:07, 383MB/s]\u001b[A\r\n",
      "\r\n",
      "\r\n",
      "model-00002-of-00005.safetensors:   9%|▌     | 359M/3.86G [00:02<00:15, 233MB/s]\u001b[A\u001b[A\u001b[A\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "model-00003-of-00005.safetensors:  19%|█▏    | 732M/3.86G [00:03<00:07, 395MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\r\n",
      "\r\n",
      "model-00004-of-00005.safetensors:   5%|▎     | 184M/3.86G [00:03<00:29, 123MB/s]\u001b[A\u001b[A\r\n",
      "\r\n",
      "model-00004-of-00005.safetensors:   8%|▌     | 324M/3.86G [00:03<00:13, 256MB/s]\u001b[A\u001b[A\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "model-00003-of-00005.safetensors:  21%|█▏    | 804M/3.86G [00:03<00:07, 429MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "model-00003-of-00005.safetensors:  22%|█▎    | 857M/3.86G [00:03<00:06, 437MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\r\n",
      "\r\n",
      "\r\n",
      "model-00002-of-00005.safetensors:  10%|▌     | 400M/3.86G [00:03<00:17, 194MB/s]\u001b[A\u001b[A\u001b[A\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "model-00003-of-00005.safetensors:  25%|█▍    | 959M/3.86G [00:03<00:05, 552MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\r\n",
      "\r\n",
      "\r\n",
      "model-00002-of-00005.safetensors:  13%|▊     | 496M/3.86G [00:03<00:11, 293MB/s]\u001b[A\u001b[A\u001b[A\r\n",
      "model-00001-of-00005.safetensors:  24%|█▍    | 940M/3.90G [00:03<00:12, 234MB/s]\u001b[A\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "model-00003-of-00005.safetensors:  27%|█▎   | 1.06G/3.86G [00:03<00:05, 486MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\r\n",
      "model-00001-of-00005.safetensors:  28%|█▍   | 1.08G/3.90G [00:03<00:07, 366MB/s]\u001b[A\r\n",
      "\r\n",
      "model-00004-of-00005.safetensors:  10%|▌     | 383M/3.86G [00:03<00:20, 169MB/s]\u001b[A\u001b[A\r\n",
      "\r\n",
      "model-00004-of-00005.safetensors:  12%|▋     | 455M/3.86G [00:03<00:15, 213MB/s]\u001b[A\u001b[A\r\n",
      "\r\n",
      "\r\n",
      "model-00002-of-00005.safetensors:  16%|▉     | 599M/3.86G [00:03<00:13, 236MB/s]\u001b[A\u001b[A\u001b[A\r\n",
      "\r\n",
      "\r\n",
      "model-00002-of-00005.safetensors:  18%|█     | 689M/3.86G [00:04<00:10, 310MB/s]\u001b[A\u001b[A\u001b[A\r\n",
      "\r\n",
      "model-00004-of-00005.safetensors:  16%|▉     | 600M/3.86G [00:04<00:09, 336MB/s]\u001b[A\u001b[A\r\n",
      "model-00001-of-00005.safetensors:  29%|█▍   | 1.14G/3.90G [00:04<00:12, 227MB/s]\u001b[A\r\n",
      "\r\n",
      "\r\n",
      "model-00002-of-00005.safetensors:  19%|█▏    | 739M/3.86G [00:04<00:12, 255MB/s]\u001b[A\u001b[A\u001b[A\r\n",
      "model-00001-of-00005.safetensors:  31%|█▌   | 1.23G/3.90G [00:04<00:10, 265MB/s]\u001b[A\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "model-00003-of-00005.safetensors:  29%|█▍   | 1.12G/3.86G [00:04<00:14, 196MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "model-00003-of-00005.safetensors:  30%|█▍   | 1.16G/3.86G [00:04<00:12, 216MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\r\n",
      "\r\n",
      "model-00004-of-00005.safetensors:  17%|█     | 664M/3.86G [00:04<00:13, 231MB/s]\u001b[A\u001b[A\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "model-00003-of-00005.safetensors:  32%|█▌   | 1.22G/3.86G [00:04<00:10, 264MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\r\n",
      "model-00001-of-00005.safetensors:  33%|█▋   | 1.30G/3.90G [00:04<00:09, 263MB/s]\u001b[A\r\n",
      "\r\n",
      "model-00004-of-00005.safetensors:  18%|█     | 709M/3.86G [00:04<00:12, 250MB/s]\u001b[A\u001b[A\r\n",
      "model-00001-of-00005.safetensors:  35%|█▋   | 1.35G/3.90G [00:04<00:08, 293MB/s]\u001b[A\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "model-00003-of-00005.safetensors:  33%|█▋   | 1.27G/3.86G [00:04<00:09, 265MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\r\n",
      "\r\n",
      "\r\n",
      "model-00002-of-00005.safetensors:  21%|█▎    | 826M/3.86G [00:04<00:13, 219MB/s]\u001b[A\u001b[A\u001b[A\r\n",
      "\r\n",
      "model-00004-of-00005.safetensors:  20%|█▏    | 754M/3.86G [00:04<00:11, 268MB/s]\u001b[A\u001b[A\r\n",
      "\r\n",
      "\r\n",
      "model-00002-of-00005.safetensors:  25%|█▍    | 953M/3.86G [00:05<00:08, 332MB/s]\u001b[A\u001b[A\u001b[A\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "model-00003-of-00005.safetensors:  34%|█▋   | 1.31G/3.86G [00:05<00:09, 283MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\r\n",
      "model-00001-of-00005.safetensors:  36%|█▊   | 1.40G/3.90G [00:05<00:08, 300MB/s]\u001b[A\r\n",
      "\r\n",
      "model-00004-of-00005.safetensors:  21%|█▏    | 798M/3.86G [00:05<00:11, 275MB/s]\u001b[A\u001b[A\r\n",
      "\r\n",
      "\r\n",
      "model-00002-of-00005.safetensors:  27%|█▎   | 1.04G/3.86G [00:05<00:06, 407MB/s]\u001b[A\u001b[A\u001b[A\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "model-00003-of-00005.safetensors:  35%|█▊   | 1.35G/3.86G [00:05<00:09, 277MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\r\n",
      "model-00001-of-00005.safetensors:  37%|█▊   | 1.44G/3.90G [00:05<00:09, 268MB/s]\u001b[A\r\n",
      "\r\n",
      "model-00004-of-00005.safetensors:  22%|█▎    | 839M/3.86G [00:05<00:11, 260MB/s]\u001b[A\u001b[A\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "model-00003-of-00005.safetensors:  37%|█▊   | 1.41G/3.86G [00:05<00:07, 323MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\r\n",
      "model-00001-of-00005.safetensors:  39%|█▉   | 1.52G/3.90G [00:05<00:06, 356MB/s]\u001b[A\r\n",
      "\r\n",
      "model-00004-of-00005.safetensors:  24%|█▍    | 928M/3.86G [00:05<00:08, 340MB/s]\u001b[A\u001b[A\r\n",
      "\r\n",
      "\r\n",
      "model-00002-of-00005.safetensors:  29%|█▍   | 1.11G/3.86G [00:05<00:07, 349MB/s]\u001b[A\u001b[A\u001b[A\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "model-00003-of-00005.safetensors:  38%|█▉   | 1.46G/3.86G [00:05<00:07, 324MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\r\n",
      "model-00001-of-00005.safetensors:  41%|██   | 1.61G/3.90G [00:05<00:05, 447MB/s]\u001b[A\r\n",
      "model-00001-of-00005.safetensors:  43%|██▏  | 1.69G/3.90G [00:05<00:04, 512MB/s]\u001b[A\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "model-00003-of-00005.safetensors:  39%|█▉   | 1.50G/3.86G [00:05<00:07, 314MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\r\n",
      "\r\n",
      "model-00004-of-00005.safetensors:  25%|█▌    | 973M/3.86G [00:05<00:09, 316MB/s]\u001b[A\u001b[A\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "model-00003-of-00005.safetensors:  40%|█▉   | 1.54G/3.86G [00:05<00:07, 322MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\r\n",
      "\r\n",
      "\r\n",
      "model-00002-of-00005.safetensors:  30%|█▌   | 1.16G/3.86G [00:05<00:09, 288MB/s]\u001b[A\u001b[A\u001b[A\r\n",
      "\r\n",
      "model-00004-of-00005.safetensors:  26%|█▎   | 1.01G/3.86G [00:05<00:10, 281MB/s]\u001b[A\u001b[A\r\n",
      "\r\n",
      "\r\n",
      "model-00002-of-00005.safetensors:  32%|█▌   | 1.25G/3.86G [00:05<00:07, 361MB/s]\u001b[A\u001b[A\u001b[A\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "model-00003-of-00005.safetensors:  41%|██   | 1.57G/3.86G [00:05<00:07, 299MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\r\n",
      "model-00001-of-00005.safetensors:  45%|██▎  | 1.76G/3.90G [00:05<00:05, 382MB/s]\u001b[A\r\n",
      "\r\n",
      "model-00004-of-00005.safetensors:  29%|█▍   | 1.11G/3.86G [00:05<00:06, 407MB/s]\u001b[A\u001b[A\r\n",
      "\r\n",
      "\r\n",
      "model-00002-of-00005.safetensors:  35%|█▋   | 1.35G/3.86G [00:05<00:05, 458MB/s]\u001b[A\u001b[A\u001b[A\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "model-00003-of-00005.safetensors:  41%|██   | 1.60G/3.86G [00:05<00:07, 300MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\r\n",
      "model-00001-of-00005.safetensors:  47%|██▎  | 1.84G/3.90G [00:05<00:04, 462MB/s]\u001b[A\r\n",
      "\r\n",
      "model-00004-of-00005.safetensors:  31%|█▌   | 1.19G/3.86G [00:06<00:05, 459MB/s]\u001b[A\u001b[A\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "model-00003-of-00005.safetensors:  42%|██   | 1.64G/3.86G [00:06<00:09, 228MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\r\n",
      "\r\n",
      "model-00004-of-00005.safetensors:  33%|█▋   | 1.26G/3.86G [00:06<00:06, 425MB/s]\u001b[A\u001b[A\r\n",
      "model-00001-of-00005.safetensors:  49%|██▍  | 1.93G/3.90G [00:06<00:04, 403MB/s]\u001b[A\r\n",
      "\r\n",
      "\r\n",
      "model-00002-of-00005.safetensors:  37%|█▊   | 1.41G/3.86G [00:06<00:06, 351MB/s]\u001b[A\u001b[A\u001b[A\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "model-00003-of-00005.safetensors:  43%|██▏  | 1.66G/3.86G [00:06<00:10, 212MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\r\n",
      "model-00001-of-00005.safetensors:  52%|██▌  | 2.03G/3.90G [00:06<00:03, 498MB/s]\u001b[A\r\n",
      "\r\n",
      "\r\n",
      "model-00002-of-00005.safetensors:  39%|█▉   | 1.51G/3.86G [00:06<00:06, 378MB/s]\u001b[A\u001b[A\u001b[A\r\n",
      "\r\n",
      "model-00004-of-00005.safetensors:  34%|█▋   | 1.31G/3.86G [00:06<00:07, 325MB/s]\u001b[A\u001b[A\r\n",
      "model-00001-of-00005.safetensors:  55%|██▊  | 2.15G/3.90G [00:06<00:03, 575MB/s]\u001b[A\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "model-00003-of-00005.safetensors:  44%|██▏  | 1.69G/3.86G [00:06<00:12, 174MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\r\n",
      "\r\n",
      "\r\n",
      "model-00002-of-00005.safetensors:  41%|██   | 1.58G/3.86G [00:06<00:05, 414MB/s]\u001b[A\u001b[A\u001b[A\r\n",
      "model-00001-of-00005.safetensors:  57%|██▊  | 2.23G/3.90G [00:06<00:02, 561MB/s]\u001b[A\r\n",
      "\r\n",
      "model-00004-of-00005.safetensors:  36%|█▊   | 1.40G/3.86G [00:06<00:07, 345MB/s]\u001b[A\u001b[A\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "model-00003-of-00005.safetensors:  44%|██▏  | 1.71G/3.86G [00:06<00:14, 153MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\r\n",
      "\r\n",
      "model-00004-of-00005.safetensors:  40%|█▉   | 1.54G/3.86G [00:06<00:04, 530MB/s]\u001b[A\u001b[A\r\n",
      "model-00001-of-00005.safetensors:  59%|██▉  | 2.30G/3.90G [00:06<00:03, 512MB/s]\u001b[A\r\n",
      "\r\n",
      "model-00004-of-00005.safetensors:  42%|██   | 1.61G/3.86G [00:06<00:04, 560MB/s]\u001b[A\u001b[A\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "model-00003-of-00005.safetensors:  45%|██▏  | 1.73G/3.86G [00:06<00:14, 149MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\r\n",
      "model-00001-of-00005.safetensors:  62%|███  | 2.41G/3.90G [00:06<00:02, 632MB/s]\u001b[A\r\n",
      "\r\n",
      "\r\n",
      "model-00002-of-00005.safetensors:  44%|██▏  | 1.68G/3.86G [00:07<00:06, 340MB/s]\u001b[A\u001b[A\u001b[A\r\n",
      "\r\n",
      "model-00004-of-00005.safetensors:  44%|██▏  | 1.70G/3.86G [00:07<00:03, 618MB/s]\u001b[A\u001b[A\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "model-00003-of-00005.safetensors:  45%|██▎  | 1.75G/3.86G [00:07<00:14, 147MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\r\n",
      "model-00001-of-00005.safetensors:  65%|███▎ | 2.55G/3.90G [00:07<00:02, 666MB/s]\u001b[A\r\n",
      "\r\n",
      "model-00004-of-00005.safetensors:  46%|██▎  | 1.78G/3.86G [00:07<00:03, 614MB/s]\u001b[A\u001b[A\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "model-00003-of-00005.safetensors:  46%|██▎  | 1.77G/3.86G [00:07<00:13, 155MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\r\n",
      "\r\n",
      "\r\n",
      "model-00002-of-00005.safetensors:  45%|██▏  | 1.73G/3.86G [00:07<00:07, 290MB/s]\u001b[A\u001b[A\u001b[A\r\n",
      "\r\n",
      "model-00004-of-00005.safetensors:  48%|██▍  | 1.87G/3.86G [00:07<00:02, 667MB/s]\u001b[A\u001b[A\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "model-00003-of-00005.safetensors:  47%|██▎  | 1.80G/3.86G [00:07<00:11, 175MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\r\n",
      "\r\n",
      "\r\n",
      "model-00002-of-00005.safetensors:  46%|██▎  | 1.77G/3.86G [00:07<00:06, 303MB/s]\u001b[A\u001b[A\u001b[A\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "model-00003-of-00005.safetensors:  48%|██▍  | 1.84G/3.86G [00:07<00:08, 238MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\r\n",
      "model-00001-of-00005.safetensors:  67%|███▎ | 2.63G/3.90G [00:07<00:02, 510MB/s]\u001b[A\r\n",
      "\r\n",
      "model-00004-of-00005.safetensors:  52%|██▌  | 2.00G/3.86G [00:07<00:02, 665MB/s]\u001b[A\u001b[A\r\n",
      "\r\n",
      "\r\n",
      "model-00002-of-00005.safetensors:  47%|██▎  | 1.81G/3.86G [00:07<00:06, 312MB/s]\u001b[A\u001b[A\u001b[A\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "model-00003-of-00005.safetensors:  48%|██▍  | 1.87G/3.86G [00:07<00:07, 252MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "model-00003-of-00005.safetensors:  49%|██▍  | 1.91G/3.86G [00:07<00:07, 264MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\r\n",
      "\r\n",
      "\r\n",
      "model-00002-of-00005.safetensors:  50%|██▍  | 1.92G/3.86G [00:07<00:04, 397MB/s]\u001b[A\u001b[A\u001b[A\r\n",
      "model-00001-of-00005.safetensors:  69%|███▍ | 2.69G/3.90G [00:07<00:03, 372MB/s]\u001b[A\r\n",
      "\r\n",
      "model-00004-of-00005.safetensors:  54%|██▋  | 2.07G/3.86G [00:07<00:03, 485MB/s]\u001b[A\u001b[A\r\n",
      "\r\n",
      "\r\n",
      "model-00002-of-00005.safetensors:  51%|██▌  | 1.97G/3.86G [00:07<00:04, 406MB/s]\u001b[A\u001b[A\u001b[A\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "model-00003-of-00005.safetensors:  50%|██▌  | 1.94G/3.86G [00:07<00:08, 226MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\r\n",
      "model-00001-of-00005.safetensors:  71%|███▌ | 2.78G/3.90G [00:07<00:02, 452MB/s]\u001b[A\r\n",
      "\r\n",
      "model-00004-of-00005.safetensors:  55%|██▊  | 2.13G/3.86G [00:07<00:03, 449MB/s]\u001b[A\u001b[A\r\n",
      "\r\n",
      "\r\n",
      "model-00002-of-00005.safetensors:  52%|██▌  | 2.01G/3.86G [00:07<00:05, 370MB/s]\u001b[A\u001b[A\u001b[A\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "model-00003-of-00005.safetensors:  51%|██▌  | 1.97G/3.86G [00:07<00:08, 225MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "model-00003-of-00005.safetensors:  52%|██▌  | 2.01G/3.86G [00:08<00:06, 272MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\r\n",
      "\r\n",
      "\r\n",
      "model-00002-of-00005.safetensors:  53%|██▋  | 2.05G/3.86G [00:08<00:05, 348MB/s]\u001b[A\u001b[A\u001b[A\r\n",
      "\r\n",
      "model-00004-of-00005.safetensors:  56%|██▊  | 2.18G/3.86G [00:08<00:04, 409MB/s]\u001b[A\u001b[A\r\n",
      "model-00001-of-00005.safetensors:  73%|███▋ | 2.84G/3.90G [00:08<00:02, 365MB/s]\u001b[A\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "model-00003-of-00005.safetensors:  53%|██▋  | 2.05G/3.86G [00:08<00:06, 266MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\r\n",
      "\r\n",
      "model-00004-of-00005.safetensors:  59%|██▉  | 2.27G/3.86G [00:08<00:03, 475MB/s]\u001b[A\u001b[A\r\n",
      "\r\n",
      "\r\n",
      "model-00002-of-00005.safetensors:  54%|██▋  | 2.09G/3.86G [00:08<00:05, 327MB/s]\u001b[A\u001b[A\u001b[A\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "model-00003-of-00005.safetensors:  54%|██▋  | 2.08G/3.86G [00:08<00:06, 295MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\r\n",
      "\r\n",
      "\r\n",
      "model-00002-of-00005.safetensors:  55%|██▋  | 2.13G/3.86G [00:08<00:05, 318MB/s]\u001b[A\u001b[A\u001b[A\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "model-00003-of-00005.safetensors:  56%|██▊  | 2.17G/3.86G [00:08<00:03, 437MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\r\n",
      "model-00001-of-00005.safetensors:  74%|███▋ | 2.89G/3.90G [00:08<00:03, 302MB/s]\u001b[A\r\n",
      "\r\n",
      "\r\n",
      "model-00002-of-00005.safetensors:  56%|██▊  | 2.16G/3.86G [00:08<00:05, 304MB/s]\u001b[A\u001b[A\u001b[A\r\n",
      "\r\n",
      "model-00004-of-00005.safetensors:  62%|███  | 2.38G/3.86G [00:08<00:03, 400MB/s]\u001b[A\u001b[A\r\n",
      "\r\n",
      "\r\n",
      "model-00002-of-00005.safetensors:  58%|██▉  | 2.25G/3.86G [00:08<00:04, 391MB/s]\u001b[A\u001b[A\u001b[A\r\n",
      "model-00001-of-00005.safetensors:  75%|███▊ | 2.93G/3.90G [00:08<00:03, 250MB/s]\u001b[A\r\n",
      "\r\n",
      "model-00004-of-00005.safetensors:  63%|███▏ | 2.44G/3.86G [00:08<00:03, 370MB/s]\u001b[A\u001b[A\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "model-00003-of-00005.safetensors:  57%|██▊  | 2.22G/3.86G [00:08<00:06, 261MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\r\n",
      "model-00001-of-00005.safetensors:  77%|███▊ | 2.99G/3.90G [00:08<00:02, 306MB/s]\u001b[A\r\n",
      "\r\n",
      "\r\n",
      "model-00002-of-00005.safetensors:  59%|██▉  | 2.29G/3.86G [00:08<00:04, 317MB/s]\u001b[A\u001b[A\u001b[A\r\n",
      "\r\n",
      "model-00004-of-00005.safetensors:  66%|███▎ | 2.54G/3.86G [00:08<00:02, 473MB/s]\u001b[A\u001b[A\r\n",
      "\r\n",
      "\r\n",
      "model-00002-of-00005.safetensors:  60%|███  | 2.32G/3.86G [00:08<00:04, 322MB/s]\u001b[A\u001b[A\u001b[A\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "model-00003-of-00005.safetensors:  58%|██▉  | 2.26G/3.86G [00:08<00:06, 238MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\r\n",
      "\r\n",
      "model-00004-of-00005.safetensors:  69%|███▍ | 2.65G/3.86G [00:08<00:02, 576MB/s]\u001b[A\u001b[A\r\n",
      "model-00001-of-00005.safetensors:  79%|███▉ | 3.09G/3.90G [00:09<00:02, 326MB/s]\u001b[A\r\n",
      "\r\n",
      "\r\n",
      "model-00002-of-00005.safetensors:  61%|███  | 2.36G/3.86G [00:09<00:04, 306MB/s]\u001b[A\u001b[A\u001b[A\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "model-00003-of-00005.safetensors:  59%|██▉  | 2.29G/3.86G [00:09<00:07, 214MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\r\n",
      "\r\n",
      "\r\n",
      "model-00002-of-00005.safetensors:  63%|███▏ | 2.44G/3.86G [00:09<00:03, 415MB/s]\u001b[A\u001b[A\u001b[A\r\n",
      "model-00001-of-00005.safetensors:  81%|████ | 3.15G/3.90G [00:09<00:02, 300MB/s]\u001b[A\r\n",
      "\r\n",
      "model-00004-of-00005.safetensors:  72%|███▌ | 2.77G/3.86G [00:09<00:02, 491MB/s]\u001b[A\u001b[A\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "model-00003-of-00005.safetensors:  60%|███  | 2.32G/3.86G [00:09<00:07, 207MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\r\n",
      "\r\n",
      "\r\n",
      "model-00002-of-00005.safetensors:  64%|███▏ | 2.49G/3.86G [00:09<00:03, 368MB/s]\u001b[A\u001b[A\u001b[A\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "model-00003-of-00005.safetensors:  61%|███  | 2.36G/3.86G [00:09<00:06, 238MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\r\n",
      "\r\n",
      "model-00004-of-00005.safetensors:  75%|███▋ | 2.88G/3.86G [00:09<00:02, 475MB/s]\u001b[A\u001b[A\r\n",
      "\r\n",
      "\r\n",
      "model-00002-of-00005.safetensors:  65%|███▎ | 2.53G/3.86G [00:09<00:04, 284MB/s]\u001b[A\u001b[A\u001b[A\r\n",
      "model-00001-of-00005.safetensors:  82%|████ | 3.19G/3.90G [00:09<00:03, 234MB/s]\u001b[A\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "model-00003-of-00005.safetensors:  62%|███  | 2.39G/3.86G [00:09<00:07, 206MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\r\n",
      "model-00001-of-00005.safetensors:  84%|████▏| 3.27G/3.90G [00:09<00:02, 308MB/s]\u001b[A\r\n",
      "\r\n",
      "\r\n",
      "model-00002-of-00005.safetensors:  67%|███▎ | 2.59G/3.86G [00:09<00:03, 327MB/s]\u001b[A\u001b[A\u001b[A\r\n",
      "\r\n",
      "model-00004-of-00005.safetensors:  76%|███▊ | 2.94G/3.86G [00:09<00:02, 418MB/s]\u001b[A\u001b[A\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "model-00003-of-00005.safetensors:  63%|███▏ | 2.42G/3.86G [00:09<00:07, 189MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\r\n",
      "model-00001-of-00005.safetensors:  86%|████▎| 3.35G/3.90G [00:09<00:01, 356MB/s]\u001b[A\r\n",
      "\r\n",
      "model-00004-of-00005.safetensors:  77%|███▊ | 2.99G/3.86G [00:09<00:02, 358MB/s]\u001b[A\u001b[A\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "model-00003-of-00005.safetensors:  63%|███▏ | 2.44G/3.86G [00:09<00:07, 180MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\r\n",
      "model-00001-of-00005.safetensors:  88%|████▍| 3.43G/3.90G [00:10<00:01, 406MB/s]\u001b[A\r\n",
      "\r\n",
      "\r\n",
      "model-00002-of-00005.safetensors:  70%|███▍ | 2.69G/3.86G [00:10<00:03, 309MB/s]\u001b[A\u001b[A\u001b[A\r\n",
      "model-00001-of-00005.safetensors:  90%|████▍| 3.50G/3.90G [00:10<00:00, 474MB/s]\u001b[A\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "model-00003-of-00005.safetensors:  64%|███▏ | 2.46G/3.86G [00:10<00:08, 162MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "model-00003-of-00005.safetensors:  64%|███▏ | 2.48G/3.86G [00:10<00:08, 163MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\r\n",
      "model-00001-of-00005.safetensors:  92%|████▌| 3.60G/3.90G [00:10<00:00, 538MB/s]\u001b[A\r\n",
      "\r\n",
      "\r\n",
      "model-00002-of-00005.safetensors:  71%|███▌ | 2.73G/3.86G [00:10<00:04, 283MB/s]\u001b[A\u001b[A\u001b[A\r\n",
      "\r\n",
      "model-00004-of-00005.safetensors:  78%|███▉ | 3.03G/3.86G [00:10<00:03, 272MB/s]\u001b[A\u001b[A\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "model-00003-of-00005.safetensors:  65%|███▎ | 2.53G/3.86G [00:10<00:06, 217MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\r\n",
      "model-00001-of-00005.safetensors:  95%|████▋| 3.70G/3.90G [00:10<00:00, 588MB/s]\u001b[A\r\n",
      "\r\n",
      "\r\n",
      "model-00002-of-00005.safetensors:  72%|███▌ | 2.77G/3.86G [00:10<00:03, 287MB/s]\u001b[A\u001b[A\u001b[A\r\n",
      "\r\n",
      "model-00004-of-00005.safetensors:  79%|███▉ | 3.06G/3.86G [00:10<00:03, 253MB/s]\u001b[A\u001b[A\r\n",
      "\r\n",
      "\r\n",
      "model-00002-of-00005.safetensors:  73%|███▋ | 2.80G/3.86G [00:10<00:03, 288MB/s]\u001b[A\u001b[A\u001b[A\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "model-00003-of-00005.safetensors:  67%|███▎ | 2.57G/3.86G [00:10<00:05, 251MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\r\n",
      "\r\n",
      "model-00004-of-00005.safetensors:  81%|████ | 3.15G/3.86G [00:10<00:02, 327MB/s]\u001b[A\u001b[A\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "model-00003-of-00005.safetensors:  68%|███▍ | 2.64G/3.86G [00:10<00:03, 358MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\r\n",
      "model-00001-of-00005.safetensors:  96%|████▊| 3.76G/3.90G [00:10<00:00, 429MB/s]\u001b[A\r\n",
      "\r\n",
      "\r\n",
      "model-00002-of-00005.safetensors:  73%|███▋ | 2.84G/3.86G [00:10<00:03, 260MB/s]\u001b[A\u001b[A\u001b[A\r\n",
      "\r\n",
      "model-00004-of-00005.safetensors:  82%|████ | 3.19G/3.86G [00:10<00:02, 335MB/s]\u001b[A\u001b[A\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "model-00003-of-00005.safetensors:  70%|███▍ | 2.69G/3.86G [00:10<00:03, 356MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\r\n",
      "\r\n",
      "\r\n",
      "model-00002-of-00005.safetensors:  75%|███▋ | 2.89G/3.86G [00:10<00:03, 316MB/s]\u001b[A\u001b[A\u001b[A\r\n",
      "\r\n",
      "model-00004-of-00005.safetensors:  84%|████▏| 3.23G/3.86G [00:10<00:01, 341MB/s]\u001b[A\u001b[A\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "model-00003-of-00005.safetensors:  71%|███▌ | 2.73G/3.86G [00:10<00:03, 331MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\r\n",
      "\r\n",
      "\r\n",
      "model-00002-of-00005.safetensors:  76%|███▊ | 2.93G/3.86G [00:10<00:02, 320MB/s]\u001b[A\u001b[A\u001b[A\r\n",
      "model-00001-of-00005.safetensors:  98%|████▉| 3.82G/3.90G [00:10<00:00, 354MB/s]\u001b[A\r\n",
      "\r\n",
      "model-00004-of-00005.safetensors:  85%|████▏| 3.27G/3.86G [00:10<00:01, 356MB/s]\u001b[A\u001b[A\r\n",
      "\r\n",
      "\r\n",
      "model-00002-of-00005.safetensors:  77%|███▊ | 2.97G/3.86G [00:11<00:03, 299MB/s]\u001b[A\u001b[A\u001b[A\r\n",
      "\r\n",
      "model-00004-of-00005.safetensors:  87%|████▎| 3.38G/3.86G [00:11<00:00, 497MB/s]\u001b[A\u001b[A\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "model-00003-of-00005.safetensors:  71%|███▌ | 2.76G/3.86G [00:11<00:03, 285MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\r\n",
      "\r\n",
      "\r\n",
      "model-00002-of-00005.safetensors:  78%|███▉ | 3.00G/3.86G [00:11<00:02, 305MB/s]\u001b[A\u001b[A\u001b[A\r\n",
      "model-00001-of-00005.safetensors: 100%|█████| 3.90G/3.90G [00:11<00:00, 349MB/s]\r\n",
      "Fetching 5 files:  20%|█████▍                     | 1/5 [00:11<00:45, 11.40s/it]\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "model-00003-of-00005.safetensors:  73%|███▋ | 2.81G/3.86G [00:11<00:03, 307MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\r\n",
      "\r\n",
      "model-00004-of-00005.safetensors:  89%|████▍| 3.43G/3.86G [00:11<00:01, 434MB/s]\u001b[A\u001b[A\r\n",
      "\r\n",
      "\r\n",
      "model-00002-of-00005.safetensors:  78%|███▉ | 3.03G/3.86G [00:11<00:02, 308MB/s]\u001b[A\u001b[A\u001b[A\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "model-00003-of-00005.safetensors:  74%|███▋ | 2.84G/3.86G [00:11<00:03, 300MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\r\n",
      "\r\n",
      "model-00004-of-00005.safetensors:  90%|████▍| 3.48G/3.86G [00:11<00:00, 436MB/s]\u001b[A\u001b[A\r\n",
      "\r\n",
      "\r\n",
      "model-00002-of-00005.safetensors:  80%|███▉ | 3.09G/3.86G [00:11<00:02, 358MB/s]\u001b[A\u001b[A\u001b[A\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "model-00003-of-00005.safetensors:  75%|███▋ | 2.89G/3.86G [00:11<00:02, 338MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\r\n",
      "\r\n",
      "model-00004-of-00005.safetensors:  91%|████▌| 3.52G/3.86G [00:11<00:00, 423MB/s]\u001b[A\u001b[A\r\n",
      "\r\n",
      "\r\n",
      "model-00002-of-00005.safetensors:  81%|████ | 3.13G/3.86G [00:11<00:01, 381MB/s]\u001b[A\u001b[A\u001b[A\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "model-00003-of-00005.safetensors:  76%|███▊ | 2.94G/3.86G [00:11<00:02, 357MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\r\n",
      "\r\n",
      "\r\n",
      "model-00002-of-00005.safetensors:  82%|████ | 3.18G/3.86G [00:11<00:01, 416MB/s]\u001b[A\u001b[A\u001b[A\r\n",
      "\r\n",
      "model-00004-of-00005.safetensors:  92%|████▌| 3.57G/3.86G [00:11<00:00, 393MB/s]\u001b[A\u001b[A\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "model-00003-of-00005.safetensors:  77%|███▊ | 2.98G/3.86G [00:11<00:02, 365MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\r\n",
      "\r\n",
      "\r\n",
      "model-00002-of-00005.safetensors:  84%|████▏| 3.23G/3.86G [00:11<00:01, 411MB/s]\u001b[A\u001b[A\u001b[A\r\n",
      "\r\n",
      "model-00004-of-00005.safetensors:  94%|████▋| 3.62G/3.86G [00:11<00:00, 408MB/s]\u001b[A\u001b[A\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "model-00003-of-00005.safetensors:  80%|███▉ | 3.08G/3.86G [00:11<00:01, 451MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\r\n",
      "\r\n",
      "\r\n",
      "model-00002-of-00005.safetensors:  85%|████▏| 3.27G/3.86G [00:11<00:01, 356MB/s]\u001b[A\u001b[A\u001b[A\r\n",
      "\r\n",
      "model-00004-of-00005.safetensors:  95%|████▋| 3.66G/3.86G [00:11<00:00, 323MB/s]\u001b[A\u001b[A\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "model-00003-of-00005.safetensors:  81%|████ | 3.13G/3.86G [00:11<00:01, 471MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\r\n",
      "\r\n",
      "\r\n",
      "model-00002-of-00005.safetensors:  86%|████▎| 3.32G/3.86G [00:11<00:01, 385MB/s]\u001b[A\u001b[A\u001b[A\r\n",
      "\r\n",
      "\r\n",
      "model-00002-of-00005.safetensors:  87%|████▎| 3.36G/3.86G [00:12<00:01, 371MB/s]\u001b[A\u001b[A\u001b[A\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "model-00003-of-00005.safetensors:  82%|████ | 3.18G/3.86G [00:12<00:01, 400MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\r\n",
      "\r\n",
      "\r\n",
      "model-00002-of-00005.safetensors:  89%|████▍| 3.42G/3.86G [00:12<00:01, 436MB/s]\u001b[A\u001b[A\u001b[A\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "model-00003-of-00005.safetensors:  84%|████▏| 3.23G/3.86G [00:12<00:01, 422MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\r\n",
      "\r\n",
      "model-00004-of-00005.safetensors:  96%|████▊| 3.71G/3.86G [00:12<00:00, 247MB/s]\u001b[A\u001b[A\r\n",
      "\r\n",
      "\r\n",
      "model-00002-of-00005.safetensors:  90%|████▍| 3.47G/3.86G [00:12<00:00, 444MB/s]\u001b[A\u001b[A\u001b[A\r\n",
      "\r\n",
      "model-00004-of-00005.safetensors:  98%|████▉| 3.79G/3.86G [00:12<00:00, 338MB/s]\u001b[A\u001b[A\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "model-00003-of-00005.safetensors:  85%|████▏| 3.28G/3.86G [00:12<00:01, 383MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\r\n",
      "\r\n",
      "\r\n",
      "model-00002-of-00005.safetensors:  91%|████▌| 3.52G/3.86G [00:12<00:00, 438MB/s]\u001b[A\u001b[A\u001b[A\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "model-00003-of-00005.safetensors:  87%|████▎| 3.36G/3.86G [00:12<00:01, 496MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\r\n",
      "\r\n",
      "\r\n",
      "model-00002-of-00005.safetensors:  93%|████▋| 3.58G/3.86G [00:12<00:00, 466MB/s]\u001b[A\u001b[A\u001b[A\r\n",
      "\r\n",
      "model-00004-of-00005.safetensors: 100%|█████| 3.86G/3.86G [00:12<00:00, 308MB/s]\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "model-00003-of-00005.safetensors:  88%|████▍| 3.42G/3.86G [00:12<00:00, 478MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\r\n",
      "\r\n",
      "\r\n",
      "model-00002-of-00005.safetensors:  94%|████▋| 3.63G/3.86G [00:12<00:00, 470MB/s]\u001b[A\u001b[A\u001b[A\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "model-00003-of-00005.safetensors:  90%|████▍| 3.47G/3.86G [00:12<00:00, 503MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\r\n",
      "\r\n",
      "\r\n",
      "model-00002-of-00005.safetensors:  96%|████▊| 3.69G/3.86G [00:12<00:00, 515MB/s]\u001b[A\u001b[A\u001b[A\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "model-00003-of-00005.safetensors:  91%|████▌| 3.54G/3.86G [00:12<00:00, 526MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "model-00003-of-00005.safetensors:  95%|████▋| 3.66G/3.86G [00:12<00:00, 702MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\r\n",
      "\r\n",
      "\r\n",
      "model-00002-of-00005.safetensors:  98%|████▉| 3.80G/3.86G [00:12<00:00, 425MB/s]\u001b[A\u001b[A\u001b[A\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "model-00003-of-00005.safetensors:  97%|████▊| 3.76G/3.86G [00:12<00:00, 725MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "model-00003-of-00005.safetensors: 100%|█████| 3.86G/3.86G [00:13<00:00, 290MB/s]\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "model-00002-of-00005.safetensors: 100%|█████| 3.86G/3.86G [00:13<00:00, 290MB/s]\r\n",
      "Fetching 5 files: 100%|███████████████████████████| 5/5 [00:13<00:00,  2.71s/it]\r\n",
      "[INFO|modeling_utils.py:1243] 2026-01-02 18:38:21,311 >> Will use dtype=torch.bfloat16 as defined in model's config object\r\n",
      "[INFO|modeling_utils.py:2341] 2026-01-02 18:38:21,311 >> Instantiating Qwen2VLForConditionalGeneration model under default dtype torch.bfloat16.\r\n",
      "[INFO|configuration_utils.py:986] 2026-01-02 18:38:21,313 >> Generate config GenerationConfig {\r\n",
      "  \"bos_token_id\": 151643,\r\n",
      "  \"eos_token_id\": 151645\r\n",
      "}\r\n",
      "\r\n",
      "[INFO|modeling_utils.py:2341] 2026-01-02 18:38:21,328 >> Instantiating Qwen2VLTextModel model under default dtype torch.bfloat16.\r\n",
      "Loading checkpoint shards: 100%|██████████████████| 5/5 [00:02<00:00,  1.77it/s]\r\n",
      "generation_config.json: 100%|██████████████████| 244/244 [00:00<00:00, 1.74MB/s]\r\n",
      "[INFO|configuration_utils.py:941] 2026-01-02 18:38:24,240 >> loading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2-VL-7B-Instruct/snapshots/eed13092ef92e448dd6875b2a00151bd3f7db0ac/generation_config.json\r\n",
      "[INFO|configuration_utils.py:986] 2026-01-02 18:38:24,241 >> Generate config GenerationConfig {\r\n",
      "  \"bos_token_id\": 151643,\r\n",
      "  \"do_sample\": true,\r\n",
      "  \"eos_token_id\": [\r\n",
      "    151645,\r\n",
      "    151643\r\n",
      "  ],\r\n",
      "  \"pad_token_id\": 151643,\r\n",
      "  \"temperature\": 0.01,\r\n",
      "  \"top_k\": 1,\r\n",
      "  \"top_p\": 0.001\r\n",
      "}\r\n",
      "\r\n",
      "[INFO|dynamic_module_utils.py:423] 2026-01-02 18:38:24,275 >> Could not locate the custom_generate/generate.py inside Qwen/Qwen2-VL-7B-Instruct.\r\n",
      "[INFO|2026-01-02 18:38:24] llamafactory.model.model_utils.checkpointing:143 >> Gradient checkpointing enabled.\r\n",
      "[INFO|2026-01-02 18:38:24] llamafactory.model.model_utils.attention:143 >> Using torch SDPA for faster training and inference.\r\n",
      "[INFO|2026-01-02 18:38:24] llamafactory.model.adapter:143 >> Upcasting trainable params to float32.\r\n",
      "[INFO|2026-01-02 18:38:24] llamafactory.model.adapter:143 >> Fine-tuning method: LoRA\r\n",
      "[INFO|2026-01-02 18:38:24] llamafactory.model.model_utils.misc:143 >> Found linear modules: v_proj,k_proj,q_proj,down_proj,up_proj,o_proj,gate_proj\r\n",
      "[INFO|2026-01-02 18:38:24] llamafactory.model.model_utils.visual:143 >> Set vision model not trainable: ['visual.patch_embed', 'visual.blocks'].\r\n",
      "[INFO|2026-01-02 18:38:24] llamafactory.model.model_utils.visual:143 >> Set multi model projector not trainable: visual.merger.\r\n",
      "[INFO|2026-01-02 18:38:30] llamafactory.model.loader:143 >> trainable params: 161,480,704 || all params: 8,452,856,320 || trainable%: 1.9104\r\n",
      "[WARNING|trainer.py:906] 2026-01-02 18:38:30,715 >> The model is already on multiple devices. Skipping the move to device specified in `args`.\r\n",
      "[INFO|trainer.py:749] 2026-01-02 18:38:43,737 >> Using auto half precision backend\r\n",
      "[WARNING|trainer.py:982] 2026-01-02 18:38:43,738 >> The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': None, 'pad_token_id': 151643}.\r\n",
      "[INFO|trainer.py:2519] 2026-01-02 18:38:44,272 >> ***** Running training *****\r\n",
      "[INFO|trainer.py:2520] 2026-01-02 18:38:44,272 >>   Num examples = 7,598\r\n",
      "[INFO|trainer.py:2521] 2026-01-02 18:38:44,272 >>   Num Epochs = 3\r\n",
      "[INFO|trainer.py:2522] 2026-01-02 18:38:44,272 >>   Instantaneous batch size per device = 4\r\n",
      "[INFO|trainer.py:2525] 2026-01-02 18:38:44,272 >>   Total train batch size (w. parallel, distributed & accumulation) = 16\r\n",
      "[INFO|trainer.py:2526] 2026-01-02 18:38:44,272 >>   Gradient Accumulation steps = 4\r\n",
      "[INFO|trainer.py:2527] 2026-01-02 18:38:44,272 >>   Total optimization steps = 1,425\r\n",
      "[INFO|trainer.py:2528] 2026-01-02 18:38:44,274 >>   Number of trainable parameters = 161,480,704\r\n",
      "  1%|▎                                       | 9/1425 [00:46<1:58:23,  5.02s/it]/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\r\n",
      "  warnings.warn(\r\n",
      "{'loss': 1.4892, 'grad_norm': 1.4355984926223755, 'learning_rate': 3.1468531468531472e-06, 'epoch': 0.02}\r\n",
      "{'loss': 1.44, 'grad_norm': 1.169238805770874, 'learning_rate': 6.643356643356643e-06, 'epoch': 0.04}\r\n",
      "{'loss': 1.3236, 'grad_norm': 1.07955801486969, 'learning_rate': 1.013986013986014e-05, 'epoch': 0.06}\r\n",
      "{'loss': 1.1946, 'grad_norm': 1.123327612876892, 'learning_rate': 1.3636363636363637e-05, 'epoch': 0.08}\r\n",
      "{'loss': 1.1424, 'grad_norm': 1.1306196451187134, 'learning_rate': 1.7132867132867133e-05, 'epoch': 0.11}\r\n",
      "{'loss': 1.084, 'grad_norm': 1.2973310947418213, 'learning_rate': 2.062937062937063e-05, 'epoch': 0.13}\r\n",
      "{'loss': 1.0631, 'grad_norm': 1.39925217628479, 'learning_rate': 2.4125874125874125e-05, 'epoch': 0.15}\r\n",
      "{'loss': 1.0324, 'grad_norm': 1.4100044965744019, 'learning_rate': 2.762237762237762e-05, 'epoch': 0.17}\r\n",
      "{'loss': 1.0355, 'grad_norm': 1.4309945106506348, 'learning_rate': 3.111888111888112e-05, 'epoch': 0.19}\r\n",
      "{'loss': 0.9493, 'grad_norm': 1.3907557725906372, 'learning_rate': 3.461538461538462e-05, 'epoch': 0.21}\r\n",
      "  7%|██▋                                   | 100/1425 [08:11<1:45:29,  4.78s/it][INFO|trainer.py:4643] 2026-01-02 18:46:55,992 >> \r\n",
      "***** Running Evaluation *****\r\n",
      "[INFO|trainer.py:4645] 2026-01-02 18:46:55,992 >>   Num examples = 60\r\n",
      "[INFO|trainer.py:4648] 2026-01-02 18:46:55,993 >>   Batch size = 1\r\n",
      "\r\n",
      "  0%|                                                    | 0/60 [00:00<?, ?it/s]\u001b[A\r\n",
      "  3%|█▍                                          | 2/60 [00:00<00:05, 10.44it/s]\u001b[A\r\n",
      "  7%|██▉                                         | 4/60 [00:00<00:07,  7.60it/s]\u001b[A\r\n",
      "  8%|███▋                                        | 5/60 [00:00<00:07,  7.22it/s]\u001b[A\r\n",
      " 10%|████▍                                       | 6/60 [00:00<00:07,  6.78it/s]\u001b[A\r\n",
      " 12%|█████▏                                      | 7/60 [00:00<00:07,  6.69it/s]\u001b[A\r\n",
      " 13%|█████▊                                      | 8/60 [00:01<00:07,  6.99it/s]\u001b[A\r\n",
      " 15%|██████▌                                     | 9/60 [00:01<00:08,  6.07it/s]\u001b[A\r\n",
      " 17%|███████▏                                   | 10/60 [00:01<00:08,  6.22it/s]\u001b[A\r\n",
      " 18%|███████▉                                   | 11/60 [00:01<00:07,  6.48it/s]\u001b[A\r\n",
      " 20%|████████▌                                  | 12/60 [00:01<00:07,  6.48it/s]\u001b[A\r\n",
      " 22%|█████████▎                                 | 13/60 [00:01<00:07,  6.34it/s]\u001b[A\r\n",
      " 23%|██████████                                 | 14/60 [00:02<00:13,  3.46it/s]\u001b[A\r\n",
      " 25%|██████████▊                                | 15/60 [00:02<00:11,  4.01it/s]\u001b[A\r\n",
      " 27%|███████████▍                               | 16/60 [00:02<00:09,  4.49it/s]\u001b[A\r\n",
      " 28%|████████████▏                              | 17/60 [00:03<00:08,  4.83it/s]\u001b[A\r\n",
      " 30%|████████████▉                              | 18/60 [00:03<00:07,  5.26it/s]\u001b[A\r\n",
      " 32%|█████████████▌                             | 19/60 [00:03<00:07,  5.72it/s]\u001b[A\r\n",
      " 33%|██████████████▎                            | 20/60 [00:03<00:06,  6.11it/s]\u001b[A\r\n",
      " 35%|███████████████                            | 21/60 [00:03<00:06,  6.45it/s]\u001b[A\r\n",
      " 37%|███████████████▊                           | 22/60 [00:03<00:06,  6.11it/s]\u001b[A\r\n",
      " 38%|████████████████▍                          | 23/60 [00:03<00:06,  5.91it/s]\u001b[A\r\n",
      " 40%|█████████████████▏                         | 24/60 [00:04<00:10,  3.41it/s]\u001b[A\r\n",
      " 42%|█████████████████▉                         | 25/60 [00:04<00:08,  3.89it/s]\u001b[A\r\n",
      " 43%|██████████████████▋                        | 26/60 [00:04<00:07,  4.51it/s]\u001b[A\r\n",
      " 45%|███████████████████▎                       | 27/60 [00:05<00:08,  3.94it/s]\u001b[A\r\n",
      " 47%|████████████████████                       | 28/60 [00:05<00:07,  4.32it/s]\u001b[A\r\n",
      " 48%|████████████████████▊                      | 29/60 [00:05<00:06,  4.90it/s]\u001b[A\r\n",
      " 50%|█████████████████████▌                     | 30/60 [00:05<00:05,  5.47it/s]\u001b[A\r\n",
      " 52%|██████████████████████▏                    | 31/60 [00:05<00:04,  6.15it/s]\u001b[A\r\n",
      " 53%|██████████████████████▉                    | 32/60 [00:05<00:04,  5.97it/s]\u001b[A\r\n",
      " 55%|███████████████████████▋                   | 33/60 [00:06<00:04,  5.72it/s]\u001b[A\r\n",
      " 57%|████████████████████████▎                  | 34/60 [00:06<00:04,  5.96it/s]\u001b[A\r\n",
      " 58%|█████████████████████████                  | 35/60 [00:06<00:04,  5.88it/s]\u001b[A\r\n",
      " 60%|█████████████████████████▊                 | 36/60 [00:06<00:04,  5.98it/s]\u001b[A\r\n",
      " 62%|██████████████████████████▌                | 37/60 [00:06<00:03,  6.54it/s]\u001b[A\r\n",
      " 63%|███████████████████████████▏               | 38/60 [00:06<00:03,  6.43it/s]\u001b[A\r\n",
      " 65%|███████████████████████████▉               | 39/60 [00:07<00:03,  6.50it/s]\u001b[A\r\n",
      " 67%|████████████████████████████▋              | 40/60 [00:07<00:03,  6.29it/s]\u001b[A\r\n",
      " 68%|█████████████████████████████▍             | 41/60 [00:07<00:03,  6.03it/s]\u001b[A\r\n",
      " 70%|██████████████████████████████             | 42/60 [00:07<00:02,  6.10it/s]\u001b[A\r\n",
      " 72%|██████████████████████████████▊            | 43/60 [00:07<00:02,  6.07it/s]\u001b[A\r\n",
      " 73%|███████████████████████████████▌           | 44/60 [00:07<00:02,  6.15it/s]\u001b[A\r\n",
      " 75%|████████████████████████████████▎          | 45/60 [00:08<00:02,  5.75it/s]\u001b[A\r\n",
      " 77%|████████████████████████████████▉          | 46/60 [00:08<00:02,  6.12it/s]\u001b[A\r\n",
      " 78%|█████████████████████████████████▋         | 47/60 [00:08<00:01,  6.55it/s]\u001b[A\r\n",
      " 80%|██████████████████████████████████▍        | 48/60 [00:08<00:01,  6.66it/s]\u001b[A\r\n",
      " 82%|███████████████████████████████████        | 49/60 [00:08<00:01,  6.81it/s]\u001b[A\r\n",
      " 83%|███████████████████████████████████▊       | 50/60 [00:08<00:01,  6.35it/s]\u001b[A\r\n",
      " 85%|████████████████████████████████████▌      | 51/60 [00:08<00:01,  6.34it/s]\u001b[A\r\n",
      " 87%|█████████████████████████████████████▎     | 52/60 [00:09<00:01,  6.13it/s]\u001b[A\r\n",
      " 88%|█████████████████████████████████████▉     | 53/60 [00:09<00:01,  6.36it/s]\u001b[A\r\n",
      " 90%|██████████████████████████████████████▋    | 54/60 [00:09<00:01,  5.94it/s]\u001b[A\r\n",
      " 92%|███████████████████████████████████████▍   | 55/60 [00:09<00:00,  6.03it/s]\u001b[A\r\n",
      " 93%|████████████████████████████████████████▏  | 56/60 [00:09<00:00,  6.30it/s]\u001b[A\r\n",
      " 95%|████████████████████████████████████████▊  | 57/60 [00:09<00:00,  6.40it/s]\u001b[A\r\n",
      " 97%|█████████████████████████████████████████▌ | 58/60 [00:10<00:00,  5.98it/s]\u001b[A\r\n",
      " 98%|██████████████████████████████████████████▎| 59/60 [00:10<00:00,  5.82it/s]\u001b[A\r\n",
      "100%|███████████████████████████████████████████| 60/60 [00:10<00:00,  6.30it/s]\u001b[A\r\n",
      "{'eval_loss': 0.9683747887611389, 'eval_runtime': 10.6823, 'eval_samples_per_second': 5.617, 'eval_steps_per_second': 5.617, 'epoch': 0.21}\r\n",
      "\r\n",
      "  7%|██▋                                   | 100/1425 [08:22<1:45:29,  4.78s/it]\r\n",
      "                                                                                \u001b[A[INFO|trainer.py:4309] 2026-01-02 18:47:06,673 >> Saving model checkpoint to /kaggle/working/models/qwen2vl-7b-vqa-grounded/checkpoint-100\r\n",
      "[INFO|configuration_utils.py:765] 2026-01-02 18:47:06,855 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2-VL-7B-Instruct/snapshots/eed13092ef92e448dd6875b2a00151bd3f7db0ac/config.json\r\n",
      "[INFO|configuration_utils.py:839] 2026-01-02 18:47:06,857 >> Model config Qwen2VLConfig {\r\n",
      "  \"architectures\": [\r\n",
      "    \"Qwen2VLForConditionalGeneration\"\r\n",
      "  ],\r\n",
      "  \"attention_dropout\": 0.0,\r\n",
      "  \"bos_token_id\": 151643,\r\n",
      "  \"dtype\": \"bfloat16\",\r\n",
      "  \"eos_token_id\": 151645,\r\n",
      "  \"hidden_act\": \"silu\",\r\n",
      "  \"hidden_size\": 3584,\r\n",
      "  \"image_token_id\": 151655,\r\n",
      "  \"initializer_range\": 0.02,\r\n",
      "  \"intermediate_size\": 18944,\r\n",
      "  \"max_position_embeddings\": 32768,\r\n",
      "  \"max_window_layers\": 28,\r\n",
      "  \"model_type\": \"qwen2_vl\",\r\n",
      "  \"num_attention_heads\": 28,\r\n",
      "  \"num_hidden_layers\": 28,\r\n",
      "  \"num_key_value_heads\": 4,\r\n",
      "  \"rms_norm_eps\": 1e-06,\r\n",
      "  \"rope_scaling\": {\r\n",
      "    \"mrope_section\": [\r\n",
      "      16,\r\n",
      "      24,\r\n",
      "      24\r\n",
      "    ],\r\n",
      "    \"rope_type\": \"default\",\r\n",
      "    \"type\": \"default\"\r\n",
      "  },\r\n",
      "  \"rope_theta\": 1000000.0,\r\n",
      "  \"sliding_window\": 32768,\r\n",
      "  \"text_config\": {\r\n",
      "    \"architectures\": [\r\n",
      "      \"Qwen2VLForConditionalGeneration\"\r\n",
      "    ],\r\n",
      "    \"attention_dropout\": 0.0,\r\n",
      "    \"bos_token_id\": 151643,\r\n",
      "    \"dtype\": \"bfloat16\",\r\n",
      "    \"eos_token_id\": 151645,\r\n",
      "    \"hidden_act\": \"silu\",\r\n",
      "    \"hidden_size\": 3584,\r\n",
      "    \"initializer_range\": 0.02,\r\n",
      "    \"intermediate_size\": 18944,\r\n",
      "    \"layer_types\": [\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\"\r\n",
      "    ],\r\n",
      "    \"max_position_embeddings\": 32768,\r\n",
      "    \"max_window_layers\": 28,\r\n",
      "    \"model_type\": \"qwen2_vl_text\",\r\n",
      "    \"num_attention_heads\": 28,\r\n",
      "    \"num_hidden_layers\": 28,\r\n",
      "    \"num_key_value_heads\": 4,\r\n",
      "    \"rms_norm_eps\": 1e-06,\r\n",
      "    \"rope_scaling\": {\r\n",
      "      \"mrope_section\": [\r\n",
      "        16,\r\n",
      "        24,\r\n",
      "        24\r\n",
      "      ],\r\n",
      "      \"rope_type\": \"default\",\r\n",
      "      \"type\": \"default\"\r\n",
      "    },\r\n",
      "    \"rope_theta\": 1000000.0,\r\n",
      "    \"sliding_window\": null,\r\n",
      "    \"use_cache\": true,\r\n",
      "    \"use_sliding_window\": false,\r\n",
      "    \"vision_token_id\": 151654,\r\n",
      "    \"vocab_size\": 152064\r\n",
      "  },\r\n",
      "  \"tie_word_embeddings\": false,\r\n",
      "  \"transformers_version\": \"4.57.1\",\r\n",
      "  \"use_cache\": true,\r\n",
      "  \"use_sliding_window\": false,\r\n",
      "  \"video_token_id\": 151656,\r\n",
      "  \"vision_config\": {\r\n",
      "    \"depth\": 32,\r\n",
      "    \"embed_dim\": 1280,\r\n",
      "    \"hidden_act\": \"quick_gelu\",\r\n",
      "    \"hidden_size\": 3584,\r\n",
      "    \"in_channels\": 3,\r\n",
      "    \"in_chans\": 3,\r\n",
      "    \"initializer_range\": 0.02,\r\n",
      "    \"mlp_ratio\": 4,\r\n",
      "    \"model_type\": \"qwen2_vl\",\r\n",
      "    \"num_heads\": 16,\r\n",
      "    \"patch_size\": 14,\r\n",
      "    \"spatial_merge_size\": 2,\r\n",
      "    \"spatial_patch_size\": 14,\r\n",
      "    \"temporal_patch_size\": 2\r\n",
      "  },\r\n",
      "  \"vision_end_token_id\": 151653,\r\n",
      "  \"vision_start_token_id\": 151652,\r\n",
      "  \"vision_token_id\": 151654,\r\n",
      "  \"vocab_size\": 152064\r\n",
      "}\r\n",
      "\r\n",
      "[INFO|tokenization_utils_base.py:2421] 2026-01-02 18:47:07,528 >> chat template saved in /kaggle/working/models/qwen2vl-7b-vqa-grounded/checkpoint-100/chat_template.jinja\r\n",
      "[INFO|tokenization_utils_base.py:2590] 2026-01-02 18:47:07,529 >> tokenizer config file saved in /kaggle/working/models/qwen2vl-7b-vqa-grounded/checkpoint-100/tokenizer_config.json\r\n",
      "[INFO|tokenization_utils_base.py:2599] 2026-01-02 18:47:07,529 >> Special tokens file saved in /kaggle/working/models/qwen2vl-7b-vqa-grounded/checkpoint-100/special_tokens_map.json\r\n",
      "[INFO|image_processing_base.py:253] 2026-01-02 18:47:08,615 >> Image processor saved in /kaggle/working/models/qwen2vl-7b-vqa-grounded/checkpoint-100/preprocessor_config.json\r\n",
      "[INFO|tokenization_utils_base.py:2421] 2026-01-02 18:47:08,615 >> chat template saved in /kaggle/working/models/qwen2vl-7b-vqa-grounded/checkpoint-100/chat_template.jinja\r\n",
      "[INFO|tokenization_utils_base.py:2590] 2026-01-02 18:47:08,615 >> tokenizer config file saved in /kaggle/working/models/qwen2vl-7b-vqa-grounded/checkpoint-100/tokenizer_config.json\r\n",
      "[INFO|tokenization_utils_base.py:2599] 2026-01-02 18:47:08,615 >> Special tokens file saved in /kaggle/working/models/qwen2vl-7b-vqa-grounded/checkpoint-100/special_tokens_map.json\r\n",
      "[INFO|video_processing_utils.py:600] 2026-01-02 18:47:08,737 >> Video processor saved in /kaggle/working/models/qwen2vl-7b-vqa-grounded/checkpoint-100/video_preprocessor_config.json\r\n",
      "[INFO|processing_utils.py:814] 2026-01-02 18:47:08,737 >> chat template saved in /kaggle/working/models/qwen2vl-7b-vqa-grounded/checkpoint-100/chat_template.jinja\r\n",
      "{'loss': 0.9778, 'grad_norm': 1.4862444400787354, 'learning_rate': 3.811188811188811e-05, 'epoch': 0.23}\r\n",
      "  8%|██▉                                   | 112/1425 [09:23<1:47:55,  4.93s/it]/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\r\n",
      "  warnings.warn(\r\n",
      "{'loss': 0.953, 'grad_norm': 1.589522361755371, 'learning_rate': 4.1608391608391614e-05, 'epoch': 0.25}\r\n",
      "{'loss': 0.9555, 'grad_norm': 1.6343159675598145, 'learning_rate': 4.5104895104895105e-05, 'epoch': 0.27}\r\n",
      "{'loss': 0.9648, 'grad_norm': 1.5304319858551025, 'learning_rate': 4.86013986013986e-05, 'epoch': 0.29}\r\n",
      "{'loss': 0.9446, 'grad_norm': 1.4229480028152466, 'learning_rate': 4.9997297732209156e-05, 'epoch': 0.32}\r\n",
      "{'loss': 0.8997, 'grad_norm': 1.4145350456237793, 'learning_rate': 4.998078598898921e-05, 'epoch': 0.34}\r\n",
      "{'loss': 0.911, 'grad_norm': 1.4671138525009155, 'learning_rate': 4.994927366546217e-05, 'epoch': 0.36}\r\n",
      "{'loss': 0.8909, 'grad_norm': 1.421929121017456, 'learning_rate': 4.990277968429684e-05, 'epoch': 0.38}\r\n",
      "{'loss': 0.9163, 'grad_norm': 1.2703254222869873, 'learning_rate': 4.984133196441854e-05, 'epoch': 0.4}\r\n",
      "{'loss': 0.8944, 'grad_norm': 1.3949224948883057, 'learning_rate': 4.976496740424418e-05, 'epoch': 0.42}\r\n",
      " 14%|█████▎                                | 200/1425 [16:28<1:40:38,  4.93s/it][INFO|trainer.py:4643] 2026-01-02 18:55:12,603 >> \r\n",
      "***** Running Evaluation *****\r\n",
      "[INFO|trainer.py:4645] 2026-01-02 18:55:12,603 >>   Num examples = 60\r\n",
      "[INFO|trainer.py:4648] 2026-01-02 18:55:12,603 >>   Batch size = 1\r\n",
      "\r\n",
      "  0%|                                                    | 0/60 [00:00<?, ?it/s]\u001b[A\r\n",
      "  3%|█▍                                          | 2/60 [00:00<00:04, 11.88it/s]\u001b[A\r\n",
      "  7%|██▉                                         | 4/60 [00:00<00:06,  8.78it/s]\u001b[A\r\n",
      "  8%|███▋                                        | 5/60 [00:00<00:06,  8.85it/s]\u001b[A\r\n",
      " 10%|████▍                                       | 6/60 [00:00<00:06,  8.14it/s]\u001b[A\r\n",
      " 12%|█████▏                                      | 7/60 [00:00<00:06,  8.24it/s]\u001b[A\r\n",
      " 13%|█████▊                                      | 8/60 [00:00<00:06,  8.33it/s]\u001b[A\r\n",
      " 15%|██████▌                                     | 9/60 [00:01<00:07,  6.95it/s]\u001b[A\r\n",
      " 17%|███████▏                                   | 10/60 [00:01<00:07,  7.01it/s]\u001b[A\r\n",
      " 18%|███████▉                                   | 11/60 [00:01<00:06,  7.51it/s]\u001b[A\r\n",
      " 20%|████████▌                                  | 12/60 [00:01<00:06,  7.51it/s]\u001b[A\r\n",
      " 22%|█████████▎                                 | 13/60 [00:01<00:06,  7.24it/s]\u001b[A\r\n",
      " 23%|██████████                                 | 14/60 [00:02<00:11,  3.97it/s]\u001b[A\r\n",
      " 25%|██████████▊                                | 15/60 [00:02<00:09,  4.53it/s]\u001b[A\r\n",
      " 27%|███████████▍                               | 16/60 [00:02<00:08,  5.01it/s]\u001b[A\r\n",
      " 28%|████████████▏                              | 17/60 [00:02<00:07,  5.46it/s]\u001b[A\r\n",
      " 30%|████████████▉                              | 18/60 [00:02<00:07,  5.81it/s]\u001b[A\r\n",
      " 32%|█████████████▌                             | 19/60 [00:02<00:06,  6.44it/s]\u001b[A\r\n",
      " 33%|██████████████▎                            | 20/60 [00:02<00:05,  7.05it/s]\u001b[A\r\n",
      " 35%|███████████████                            | 21/60 [00:03<00:05,  7.37it/s]\u001b[A\r\n",
      " 37%|███████████████▊                           | 22/60 [00:03<00:05,  7.20it/s]\u001b[A\r\n",
      " 38%|████████████████▍                          | 23/60 [00:03<00:05,  6.70it/s]\u001b[A\r\n",
      " 40%|█████████████████▏                         | 24/60 [00:03<00:09,  3.73it/s]\u001b[A\r\n",
      " 42%|█████████████████▉                         | 25/60 [00:04<00:08,  4.22it/s]\u001b[A\r\n",
      " 43%|██████████████████▋                        | 26/60 [00:04<00:07,  4.82it/s]\u001b[A\r\n",
      " 45%|███████████████████▎                       | 27/60 [00:04<00:07,  4.27it/s]\u001b[A\r\n",
      " 47%|████████████████████                       | 28/60 [00:04<00:06,  4.62it/s]\u001b[A\r\n",
      " 48%|████████████████████▊                      | 29/60 [00:04<00:05,  5.21it/s]\u001b[A\r\n",
      " 52%|██████████████████████▏                    | 31/60 [00:05<00:04,  6.68it/s]\u001b[A\r\n",
      " 53%|██████████████████████▉                    | 32/60 [00:05<00:04,  6.72it/s]\u001b[A\r\n",
      " 55%|███████████████████████▋                   | 33/60 [00:05<00:04,  6.32it/s]\u001b[A\r\n",
      " 57%|████████████████████████▎                  | 34/60 [00:05<00:04,  6.48it/s]\u001b[A\r\n",
      " 58%|█████████████████████████                  | 35/60 [00:05<00:03,  6.56it/s]\u001b[A\r\n",
      " 60%|█████████████████████████▊                 | 36/60 [00:05<00:03,  6.76it/s]\u001b[A\r\n",
      " 62%|██████████████████████████▌                | 37/60 [00:05<00:03,  7.28it/s]\u001b[A\r\n",
      " 63%|███████████████████████████▏               | 38/60 [00:06<00:02,  7.52it/s]\u001b[A\r\n",
      " 65%|███████████████████████████▉               | 39/60 [00:06<00:02,  7.40it/s]\u001b[A\r\n",
      " 67%|████████████████████████████▋              | 40/60 [00:06<00:02,  6.97it/s]\u001b[A\r\n",
      " 68%|█████████████████████████████▍             | 41/60 [00:06<00:02,  6.49it/s]\u001b[A\r\n",
      " 70%|██████████████████████████████             | 42/60 [00:06<00:02,  6.48it/s]\u001b[A\r\n",
      " 72%|██████████████████████████████▊            | 43/60 [00:06<00:02,  6.38it/s]\u001b[A\r\n",
      " 73%|███████████████████████████████▌           | 44/60 [00:07<00:02,  6.42it/s]\u001b[A\r\n",
      " 75%|████████████████████████████████▎          | 45/60 [00:07<00:02,  5.94it/s]\u001b[A\r\n",
      " 77%|████████████████████████████████▉          | 46/60 [00:07<00:02,  6.33it/s]\u001b[A\r\n",
      " 78%|█████████████████████████████████▋         | 47/60 [00:07<00:01,  6.90it/s]\u001b[A\r\n",
      " 80%|██████████████████████████████████▍        | 48/60 [00:07<00:01,  7.04it/s]\u001b[A\r\n",
      " 82%|███████████████████████████████████        | 49/60 [00:07<00:01,  7.50it/s]\u001b[A\r\n",
      " 83%|███████████████████████████████████▊       | 50/60 [00:07<00:01,  6.96it/s]\u001b[A\r\n",
      " 85%|████████████████████████████████████▌      | 51/60 [00:08<00:01,  6.83it/s]\u001b[A\r\n",
      " 87%|█████████████████████████████████████▎     | 52/60 [00:08<00:01,  6.47it/s]\u001b[A\r\n",
      " 88%|█████████████████████████████████████▉     | 53/60 [00:08<00:01,  6.72it/s]\u001b[A\r\n",
      " 90%|██████████████████████████████████████▋    | 54/60 [00:08<00:00,  6.34it/s]\u001b[A\r\n",
      " 92%|███████████████████████████████████████▍   | 55/60 [00:08<00:00,  6.40it/s]\u001b[A\r\n",
      " 93%|████████████████████████████████████████▏  | 56/60 [00:08<00:00,  6.60it/s]\u001b[A\r\n",
      " 95%|████████████████████████████████████████▊  | 57/60 [00:08<00:00,  6.86it/s]\u001b[A\r\n",
      " 97%|█████████████████████████████████████████▌ | 58/60 [00:09<00:00,  6.45it/s]\u001b[A\r\n",
      " 98%|██████████████████████████████████████████▎| 59/60 [00:09<00:00,  6.21it/s]\u001b[A\r\n",
      "100%|███████████████████████████████████████████| 60/60 [00:09<00:00,  6.62it/s]\u001b[A\r\n",
      "{'eval_loss': 0.8804826140403748, 'eval_runtime': 9.6667, 'eval_samples_per_second': 6.207, 'eval_steps_per_second': 6.207, 'epoch': 0.42}\r\n",
      "\r\n",
      " 14%|█████▎                                | 200/1425 [16:37<1:40:38,  4.93s/it]\r\n",
      "                                                                                \u001b[A[INFO|trainer.py:4309] 2026-01-02 18:55:22,268 >> Saving model checkpoint to /kaggle/working/models/qwen2vl-7b-vqa-grounded/checkpoint-200\r\n",
      "[INFO|configuration_utils.py:765] 2026-01-02 18:55:22,384 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2-VL-7B-Instruct/snapshots/eed13092ef92e448dd6875b2a00151bd3f7db0ac/config.json\r\n",
      "[INFO|configuration_utils.py:839] 2026-01-02 18:55:22,386 >> Model config Qwen2VLConfig {\r\n",
      "  \"architectures\": [\r\n",
      "    \"Qwen2VLForConditionalGeneration\"\r\n",
      "  ],\r\n",
      "  \"attention_dropout\": 0.0,\r\n",
      "  \"bos_token_id\": 151643,\r\n",
      "  \"dtype\": \"bfloat16\",\r\n",
      "  \"eos_token_id\": 151645,\r\n",
      "  \"hidden_act\": \"silu\",\r\n",
      "  \"hidden_size\": 3584,\r\n",
      "  \"image_token_id\": 151655,\r\n",
      "  \"initializer_range\": 0.02,\r\n",
      "  \"intermediate_size\": 18944,\r\n",
      "  \"max_position_embeddings\": 32768,\r\n",
      "  \"max_window_layers\": 28,\r\n",
      "  \"model_type\": \"qwen2_vl\",\r\n",
      "  \"num_attention_heads\": 28,\r\n",
      "  \"num_hidden_layers\": 28,\r\n",
      "  \"num_key_value_heads\": 4,\r\n",
      "  \"rms_norm_eps\": 1e-06,\r\n",
      "  \"rope_scaling\": {\r\n",
      "    \"mrope_section\": [\r\n",
      "      16,\r\n",
      "      24,\r\n",
      "      24\r\n",
      "    ],\r\n",
      "    \"rope_type\": \"default\",\r\n",
      "    \"type\": \"default\"\r\n",
      "  },\r\n",
      "  \"rope_theta\": 1000000.0,\r\n",
      "  \"sliding_window\": 32768,\r\n",
      "  \"text_config\": {\r\n",
      "    \"architectures\": [\r\n",
      "      \"Qwen2VLForConditionalGeneration\"\r\n",
      "    ],\r\n",
      "    \"attention_dropout\": 0.0,\r\n",
      "    \"bos_token_id\": 151643,\r\n",
      "    \"dtype\": \"bfloat16\",\r\n",
      "    \"eos_token_id\": 151645,\r\n",
      "    \"hidden_act\": \"silu\",\r\n",
      "    \"hidden_size\": 3584,\r\n",
      "    \"initializer_range\": 0.02,\r\n",
      "    \"intermediate_size\": 18944,\r\n",
      "    \"layer_types\": [\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\"\r\n",
      "    ],\r\n",
      "    \"max_position_embeddings\": 32768,\r\n",
      "    \"max_window_layers\": 28,\r\n",
      "    \"model_type\": \"qwen2_vl_text\",\r\n",
      "    \"num_attention_heads\": 28,\r\n",
      "    \"num_hidden_layers\": 28,\r\n",
      "    \"num_key_value_heads\": 4,\r\n",
      "    \"rms_norm_eps\": 1e-06,\r\n",
      "    \"rope_scaling\": {\r\n",
      "      \"mrope_section\": [\r\n",
      "        16,\r\n",
      "        24,\r\n",
      "        24\r\n",
      "      ],\r\n",
      "      \"rope_type\": \"default\",\r\n",
      "      \"type\": \"default\"\r\n",
      "    },\r\n",
      "    \"rope_theta\": 1000000.0,\r\n",
      "    \"sliding_window\": null,\r\n",
      "    \"use_cache\": true,\r\n",
      "    \"use_sliding_window\": false,\r\n",
      "    \"vision_token_id\": 151654,\r\n",
      "    \"vocab_size\": 152064\r\n",
      "  },\r\n",
      "  \"tie_word_embeddings\": false,\r\n",
      "  \"transformers_version\": \"4.57.1\",\r\n",
      "  \"use_cache\": true,\r\n",
      "  \"use_sliding_window\": false,\r\n",
      "  \"video_token_id\": 151656,\r\n",
      "  \"vision_config\": {\r\n",
      "    \"depth\": 32,\r\n",
      "    \"embed_dim\": 1280,\r\n",
      "    \"hidden_act\": \"quick_gelu\",\r\n",
      "    \"hidden_size\": 3584,\r\n",
      "    \"in_channels\": 3,\r\n",
      "    \"in_chans\": 3,\r\n",
      "    \"initializer_range\": 0.02,\r\n",
      "    \"mlp_ratio\": 4,\r\n",
      "    \"model_type\": \"qwen2_vl\",\r\n",
      "    \"num_heads\": 16,\r\n",
      "    \"patch_size\": 14,\r\n",
      "    \"spatial_merge_size\": 2,\r\n",
      "    \"spatial_patch_size\": 14,\r\n",
      "    \"temporal_patch_size\": 2\r\n",
      "  },\r\n",
      "  \"vision_end_token_id\": 151653,\r\n",
      "  \"vision_start_token_id\": 151652,\r\n",
      "  \"vision_token_id\": 151654,\r\n",
      "  \"vocab_size\": 152064\r\n",
      "}\r\n",
      "\r\n",
      "[INFO|tokenization_utils_base.py:2421] 2026-01-02 18:55:22,987 >> chat template saved in /kaggle/working/models/qwen2vl-7b-vqa-grounded/checkpoint-200/chat_template.jinja\r\n",
      "[INFO|tokenization_utils_base.py:2590] 2026-01-02 18:55:22,987 >> tokenizer config file saved in /kaggle/working/models/qwen2vl-7b-vqa-grounded/checkpoint-200/tokenizer_config.json\r\n",
      "[INFO|tokenization_utils_base.py:2599] 2026-01-02 18:55:22,987 >> Special tokens file saved in /kaggle/working/models/qwen2vl-7b-vqa-grounded/checkpoint-200/special_tokens_map.json\r\n",
      "[INFO|image_processing_base.py:253] 2026-01-02 18:55:24,068 >> Image processor saved in /kaggle/working/models/qwen2vl-7b-vqa-grounded/checkpoint-200/preprocessor_config.json\r\n",
      "[INFO|tokenization_utils_base.py:2421] 2026-01-02 18:55:24,068 >> chat template saved in /kaggle/working/models/qwen2vl-7b-vqa-grounded/checkpoint-200/chat_template.jinja\r\n",
      "[INFO|tokenization_utils_base.py:2590] 2026-01-02 18:55:24,068 >> tokenizer config file saved in /kaggle/working/models/qwen2vl-7b-vqa-grounded/checkpoint-200/tokenizer_config.json\r\n",
      "[INFO|tokenization_utils_base.py:2599] 2026-01-02 18:55:24,068 >> Special tokens file saved in /kaggle/working/models/qwen2vl-7b-vqa-grounded/checkpoint-200/special_tokens_map.json\r\n",
      "[INFO|video_processing_utils.py:600] 2026-01-02 18:55:24,183 >> Video processor saved in /kaggle/working/models/qwen2vl-7b-vqa-grounded/checkpoint-200/video_preprocessor_config.json\r\n",
      "[INFO|processing_utils.py:814] 2026-01-02 18:55:24,183 >> chat template saved in /kaggle/working/models/qwen2vl-7b-vqa-grounded/checkpoint-200/chat_template.jinja\r\n",
      "{'loss': 0.9039, 'grad_norm': 1.4293789863586426, 'learning_rate': 4.96737318595254e-05, 'epoch': 0.44}\r\n",
      "{'loss': 0.9015, 'grad_norm': 1.2722697257995605, 'learning_rate': 4.956768011581282e-05, 'epoch': 0.46}\r\n",
      " 16%|██████                                | 226/1425 [18:45<1:34:50,  4.75s/it]/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\r\n",
      "  warnings.warn(\r\n",
      "{'loss': 0.8819, 'grad_norm': 1.3922544717788696, 'learning_rate': 4.944687585555817e-05, 'epoch': 0.48}\r\n",
      "{'loss': 0.8862, 'grad_norm': 1.1630374193191528, 'learning_rate': 4.9311391619873983e-05, 'epoch': 0.51}\r\n",
      "{'loss': 0.8584, 'grad_norm': 1.2766191959381104, 'learning_rate': 4.9161308764973745e-05, 'epoch': 0.53}\r\n",
      "{'loss': 0.8481, 'grad_norm': 1.3091199398040771, 'learning_rate': 4.89967174133187e-05, 'epoch': 0.55}\r\n",
      "{'loss': 0.86, 'grad_norm': 1.3006551265716553, 'learning_rate': 4.881771639950077e-05, 'epoch': 0.57}\r\n",
      "{'loss': 0.8822, 'grad_norm': 1.2140966653823853, 'learning_rate': 4.862441321089378e-05, 'epoch': 0.59}\r\n",
      "{'loss': 0.8724, 'grad_norm': 1.348928689956665, 'learning_rate': 4.841692392310904e-05, 'epoch': 0.61}\r\n",
      "{'loss': 0.8237, 'grad_norm': 1.2468767166137695, 'learning_rate': 4.819537313029365e-05, 'epoch': 0.63}\r\n",
      " 21%|████████                              | 300/1425 [24:43<1:32:25,  4.93s/it][INFO|trainer.py:4643] 2026-01-02 19:03:27,859 >> \r\n",
      "***** Running Evaluation *****\r\n",
      "[INFO|trainer.py:4645] 2026-01-02 19:03:27,859 >>   Num examples = 60\r\n",
      "[INFO|trainer.py:4648] 2026-01-02 19:03:27,859 >>   Batch size = 1\r\n",
      "\r\n",
      "  0%|                                                    | 0/60 [00:00<?, ?it/s]\u001b[A\r\n",
      "  3%|█▍                                          | 2/60 [00:00<00:04, 11.71it/s]\u001b[A\r\n",
      "  7%|██▉                                         | 4/60 [00:00<00:06,  8.68it/s]\u001b[A\r\n",
      "  8%|███▋                                        | 5/60 [00:00<00:06,  8.67it/s]\u001b[A\r\n",
      " 10%|████▍                                       | 6/60 [00:00<00:06,  8.01it/s]\u001b[A\r\n",
      " 12%|█████▏                                      | 7/60 [00:00<00:06,  8.06it/s]\u001b[A\r\n",
      " 13%|█████▊                                      | 8/60 [00:00<00:06,  8.10it/s]\u001b[A\r\n",
      " 15%|██████▌                                     | 9/60 [00:01<00:07,  6.70it/s]\u001b[A\r\n",
      " 17%|███████▏                                   | 10/60 [00:01<00:07,  6.81it/s]\u001b[A\r\n",
      " 18%|███████▉                                   | 11/60 [00:01<00:06,  7.32it/s]\u001b[A\r\n",
      " 20%|████████▌                                  | 12/60 [00:01<00:06,  7.37it/s]\u001b[A\r\n",
      " 22%|█████████▎                                 | 13/60 [00:01<00:06,  6.99it/s]\u001b[A\r\n",
      " 23%|██████████                                 | 14/60 [00:02<00:12,  3.62it/s]\u001b[A\r\n",
      " 25%|██████████▊                                | 15/60 [00:02<00:10,  4.20it/s]\u001b[A\r\n",
      " 27%|███████████▍                               | 16/60 [00:02<00:09,  4.70it/s]\u001b[A\r\n",
      " 28%|████████████▏                              | 17/60 [00:02<00:08,  5.16it/s]\u001b[A\r\n",
      " 30%|████████████▉                              | 18/60 [00:02<00:07,  5.54it/s]\u001b[A\r\n",
      " 32%|█████████████▌                             | 19/60 [00:03<00:06,  6.18it/s]\u001b[A\r\n",
      " 33%|██████████████▎                            | 20/60 [00:03<00:05,  6.78it/s]\u001b[A\r\n",
      " 35%|███████████████                            | 21/60 [00:03<00:05,  7.09it/s]\u001b[A\r\n",
      " 37%|███████████████▊                           | 22/60 [00:03<00:05,  6.93it/s]\u001b[A\r\n",
      " 38%|████████████████▍                          | 23/60 [00:03<00:05,  6.47it/s]\u001b[A\r\n",
      " 40%|█████████████████▏                         | 24/60 [00:04<00:09,  3.62it/s]\u001b[A\r\n",
      " 42%|█████████████████▉                         | 25/60 [00:04<00:08,  4.10it/s]\u001b[A\r\n",
      " 43%|██████████████████▋                        | 26/60 [00:04<00:07,  4.71it/s]\u001b[A\r\n",
      " 45%|███████████████████▎                       | 27/60 [00:04<00:08,  4.12it/s]\u001b[A\r\n",
      " 47%|████████████████████                       | 28/60 [00:04<00:07,  4.46it/s]\u001b[A\r\n",
      " 48%|████████████████████▊                      | 29/60 [00:05<00:06,  5.06it/s]\u001b[A\r\n",
      " 52%|██████████████████████▏                    | 31/60 [00:05<00:04,  6.48it/s]\u001b[A\r\n",
      " 53%|██████████████████████▉                    | 32/60 [00:05<00:04,  6.51it/s]\u001b[A\r\n",
      " 55%|███████████████████████▋                   | 33/60 [00:05<00:04,  6.13it/s]\u001b[A\r\n",
      " 57%|████████████████████████▎                  | 34/60 [00:05<00:04,  6.30it/s]\u001b[A\r\n",
      " 58%|█████████████████████████                  | 35/60 [00:05<00:03,  6.34it/s]\u001b[A\r\n",
      " 60%|█████████████████████████▊                 | 36/60 [00:06<00:03,  6.57it/s]\u001b[A\r\n",
      " 62%|██████████████████████████▌                | 37/60 [00:06<00:03,  7.13it/s]\u001b[A\r\n",
      " 63%|███████████████████████████▏               | 38/60 [00:06<00:02,  7.35it/s]\u001b[A\r\n",
      " 65%|███████████████████████████▉               | 39/60 [00:06<00:02,  7.24it/s]\u001b[A\r\n",
      " 67%|████████████████████████████▋              | 40/60 [00:06<00:02,  6.81it/s]\u001b[A\r\n",
      " 68%|█████████████████████████████▍             | 41/60 [00:06<00:03,  6.30it/s]\u001b[A\r\n",
      " 70%|██████████████████████████████             | 42/60 [00:06<00:02,  6.31it/s]\u001b[A\r\n",
      " 72%|██████████████████████████████▊            | 43/60 [00:07<00:02,  6.21it/s]\u001b[A\r\n",
      " 73%|███████████████████████████████▌           | 44/60 [00:07<00:02,  6.26it/s]\u001b[A\r\n",
      " 75%|████████████████████████████████▎          | 45/60 [00:07<00:02,  5.80it/s]\u001b[A\r\n",
      " 77%|████████████████████████████████▉          | 46/60 [00:07<00:02,  6.21it/s]\u001b[A\r\n",
      " 78%|█████████████████████████████████▋         | 47/60 [00:07<00:01,  6.75it/s]\u001b[A\r\n",
      " 80%|██████████████████████████████████▍        | 48/60 [00:07<00:01,  6.91it/s]\u001b[A\r\n",
      " 82%|███████████████████████████████████        | 49/60 [00:07<00:01,  7.32it/s]\u001b[A\r\n",
      " 83%|███████████████████████████████████▊       | 50/60 [00:08<00:01,  6.81it/s]\u001b[A\r\n",
      " 85%|████████████████████████████████████▌      | 51/60 [00:08<00:01,  6.68it/s]\u001b[A\r\n",
      " 87%|█████████████████████████████████████▎     | 52/60 [00:08<00:01,  6.34it/s]\u001b[A\r\n",
      " 88%|█████████████████████████████████████▉     | 53/60 [00:08<00:01,  6.59it/s]\u001b[A\r\n",
      " 90%|██████████████████████████████████████▋    | 54/60 [00:08<00:00,  6.20it/s]\u001b[A\r\n",
      " 92%|███████████████████████████████████████▍   | 55/60 [00:08<00:00,  6.28it/s]\u001b[A\r\n",
      " 93%|████████████████████████████████████████▏  | 56/60 [00:09<00:00,  6.48it/s]\u001b[A\r\n",
      " 95%|████████████████████████████████████████▊  | 57/60 [00:09<00:00,  6.71it/s]\u001b[A\r\n",
      " 97%|█████████████████████████████████████████▌ | 58/60 [00:09<00:00,  6.33it/s]\u001b[A\r\n",
      " 98%|██████████████████████████████████████████▎| 59/60 [00:09<00:00,  6.06it/s]\u001b[A\r\n",
      "\r\n",
      "\u001b[A{'eval_loss': 0.8320228457450867, 'eval_runtime': 9.9761, 'eval_samples_per_second': 6.014, 'eval_steps_per_second': 6.014, 'epoch': 0.63}\r\n",
      " 21%|████████                              | 300/1425 [24:53<1:32:25,  4.93s/it]\r\n",
      "100%|███████████████████████████████████████████| 60/60 [00:09<00:00,  6.50it/s]\u001b[A\r\n",
      "                                                                                \u001b[A[INFO|trainer.py:4309] 2026-01-02 19:03:37,833 >> Saving model checkpoint to /kaggle/working/models/qwen2vl-7b-vqa-grounded/checkpoint-300\r\n",
      "[INFO|configuration_utils.py:765] 2026-01-02 19:03:37,967 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2-VL-7B-Instruct/snapshots/eed13092ef92e448dd6875b2a00151bd3f7db0ac/config.json\r\n",
      "[INFO|configuration_utils.py:839] 2026-01-02 19:03:37,969 >> Model config Qwen2VLConfig {\r\n",
      "  \"architectures\": [\r\n",
      "    \"Qwen2VLForConditionalGeneration\"\r\n",
      "  ],\r\n",
      "  \"attention_dropout\": 0.0,\r\n",
      "  \"bos_token_id\": 151643,\r\n",
      "  \"dtype\": \"bfloat16\",\r\n",
      "  \"eos_token_id\": 151645,\r\n",
      "  \"hidden_act\": \"silu\",\r\n",
      "  \"hidden_size\": 3584,\r\n",
      "  \"image_token_id\": 151655,\r\n",
      "  \"initializer_range\": 0.02,\r\n",
      "  \"intermediate_size\": 18944,\r\n",
      "  \"max_position_embeddings\": 32768,\r\n",
      "  \"max_window_layers\": 28,\r\n",
      "  \"model_type\": \"qwen2_vl\",\r\n",
      "  \"num_attention_heads\": 28,\r\n",
      "  \"num_hidden_layers\": 28,\r\n",
      "  \"num_key_value_heads\": 4,\r\n",
      "  \"rms_norm_eps\": 1e-06,\r\n",
      "  \"rope_scaling\": {\r\n",
      "    \"mrope_section\": [\r\n",
      "      16,\r\n",
      "      24,\r\n",
      "      24\r\n",
      "    ],\r\n",
      "    \"rope_type\": \"default\",\r\n",
      "    \"type\": \"default\"\r\n",
      "  },\r\n",
      "  \"rope_theta\": 1000000.0,\r\n",
      "  \"sliding_window\": 32768,\r\n",
      "  \"text_config\": {\r\n",
      "    \"architectures\": [\r\n",
      "      \"Qwen2VLForConditionalGeneration\"\r\n",
      "    ],\r\n",
      "    \"attention_dropout\": 0.0,\r\n",
      "    \"bos_token_id\": 151643,\r\n",
      "    \"dtype\": \"bfloat16\",\r\n",
      "    \"eos_token_id\": 151645,\r\n",
      "    \"hidden_act\": \"silu\",\r\n",
      "    \"hidden_size\": 3584,\r\n",
      "    \"initializer_range\": 0.02,\r\n",
      "    \"intermediate_size\": 18944,\r\n",
      "    \"layer_types\": [\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\"\r\n",
      "    ],\r\n",
      "    \"max_position_embeddings\": 32768,\r\n",
      "    \"max_window_layers\": 28,\r\n",
      "    \"model_type\": \"qwen2_vl_text\",\r\n",
      "    \"num_attention_heads\": 28,\r\n",
      "    \"num_hidden_layers\": 28,\r\n",
      "    \"num_key_value_heads\": 4,\r\n",
      "    \"rms_norm_eps\": 1e-06,\r\n",
      "    \"rope_scaling\": {\r\n",
      "      \"mrope_section\": [\r\n",
      "        16,\r\n",
      "        24,\r\n",
      "        24\r\n",
      "      ],\r\n",
      "      \"rope_type\": \"default\",\r\n",
      "      \"type\": \"default\"\r\n",
      "    },\r\n",
      "    \"rope_theta\": 1000000.0,\r\n",
      "    \"sliding_window\": null,\r\n",
      "    \"use_cache\": true,\r\n",
      "    \"use_sliding_window\": false,\r\n",
      "    \"vision_token_id\": 151654,\r\n",
      "    \"vocab_size\": 152064\r\n",
      "  },\r\n",
      "  \"tie_word_embeddings\": false,\r\n",
      "  \"transformers_version\": \"4.57.1\",\r\n",
      "  \"use_cache\": true,\r\n",
      "  \"use_sliding_window\": false,\r\n",
      "  \"video_token_id\": 151656,\r\n",
      "  \"vision_config\": {\r\n",
      "    \"depth\": 32,\r\n",
      "    \"embed_dim\": 1280,\r\n",
      "    \"hidden_act\": \"quick_gelu\",\r\n",
      "    \"hidden_size\": 3584,\r\n",
      "    \"in_channels\": 3,\r\n",
      "    \"in_chans\": 3,\r\n",
      "    \"initializer_range\": 0.02,\r\n",
      "    \"mlp_ratio\": 4,\r\n",
      "    \"model_type\": \"qwen2_vl\",\r\n",
      "    \"num_heads\": 16,\r\n",
      "    \"patch_size\": 14,\r\n",
      "    \"spatial_merge_size\": 2,\r\n",
      "    \"spatial_patch_size\": 14,\r\n",
      "    \"temporal_patch_size\": 2\r\n",
      "  },\r\n",
      "  \"vision_end_token_id\": 151653,\r\n",
      "  \"vision_start_token_id\": 151652,\r\n",
      "  \"vision_token_id\": 151654,\r\n",
      "  \"vocab_size\": 152064\r\n",
      "}\r\n",
      "\r\n",
      "[INFO|tokenization_utils_base.py:2421] 2026-01-02 19:03:38,569 >> chat template saved in /kaggle/working/models/qwen2vl-7b-vqa-grounded/checkpoint-300/chat_template.jinja\r\n",
      "[INFO|tokenization_utils_base.py:2590] 2026-01-02 19:03:38,570 >> tokenizer config file saved in /kaggle/working/models/qwen2vl-7b-vqa-grounded/checkpoint-300/tokenizer_config.json\r\n",
      "[INFO|tokenization_utils_base.py:2599] 2026-01-02 19:03:38,570 >> Special tokens file saved in /kaggle/working/models/qwen2vl-7b-vqa-grounded/checkpoint-300/special_tokens_map.json\r\n",
      "[INFO|image_processing_base.py:253] 2026-01-02 19:03:39,675 >> Image processor saved in /kaggle/working/models/qwen2vl-7b-vqa-grounded/checkpoint-300/preprocessor_config.json\r\n",
      "[INFO|tokenization_utils_base.py:2421] 2026-01-02 19:03:39,675 >> chat template saved in /kaggle/working/models/qwen2vl-7b-vqa-grounded/checkpoint-300/chat_template.jinja\r\n",
      "[INFO|tokenization_utils_base.py:2590] 2026-01-02 19:03:39,676 >> tokenizer config file saved in /kaggle/working/models/qwen2vl-7b-vqa-grounded/checkpoint-300/tokenizer_config.json\r\n",
      "[INFO|tokenization_utils_base.py:2599] 2026-01-02 19:03:39,676 >> Special tokens file saved in /kaggle/working/models/qwen2vl-7b-vqa-grounded/checkpoint-300/special_tokens_map.json\r\n",
      "[INFO|video_processing_utils.py:600] 2026-01-02 19:03:39,804 >> Video processor saved in /kaggle/working/models/qwen2vl-7b-vqa-grounded/checkpoint-300/video_preprocessor_config.json\r\n",
      "[INFO|processing_utils.py:814] 2026-01-02 19:03:39,804 >> chat template saved in /kaggle/working/models/qwen2vl-7b-vqa-grounded/checkpoint-300/chat_template.jinja\r\n",
      "{'loss': 0.8775, 'grad_norm': 1.227664828300476, 'learning_rate': 4.795989387031365e-05, 'epoch': 0.65}\r\n",
      " 22%|████████▎                             | 311/1425 [25:49<1:33:20,  5.03s/it]/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\r\n",
      "  warnings.warn(\r\n",
      "{'loss': 0.8427, 'grad_norm': 1.2621451616287231, 'learning_rate': 4.7710627544866775e-05, 'epoch': 0.67}\r\n",
      "{'loss': 0.8639, 'grad_norm': 1.1639028787612915, 'learning_rate': 4.744772383457295e-05, 'epoch': 0.69}\r\n",
      "{'loss': 0.8319, 'grad_norm': 1.229990005493164, 'learning_rate': 4.717134060909332e-05, 'epoch': 0.72}\r\n",
      "{'loss': 0.8094, 'grad_norm': 1.162661075592041, 'learning_rate': 4.688164383233193e-05, 'epoch': 0.74}\r\n",
      "{'loss': 0.8273, 'grad_norm': 1.213724136352539, 'learning_rate': 4.657880746277701e-05, 'epoch': 0.76}\r\n",
      "{'loss': 0.8502, 'grad_norm': 1.1288622617721558, 'learning_rate': 4.626301334904144e-05, 'epoch': 0.78}\r\n",
      "{'loss': 0.8326, 'grad_norm': 1.2328845262527466, 'learning_rate': 4.5934451120665533e-05, 'epoch': 0.8}\r\n",
      "{'loss': 0.8229, 'grad_norm': 1.1418118476867676, 'learning_rate': 4.559331807424736e-05, 'epoch': 0.82}\r\n",
      "{'loss': 0.8171, 'grad_norm': 1.1608606576919556, 'learning_rate': 4.5239819054969144e-05, 'epoch': 0.84}\r\n",
      " 28%|██████████▋                           | 400/1425 [33:04<1:22:34,  4.83s/it][INFO|trainer.py:4643] 2026-01-02 19:11:48,305 >> \r\n",
      "***** Running Evaluation *****\r\n",
      "[INFO|trainer.py:4645] 2026-01-02 19:11:48,305 >>   Num examples = 60\r\n",
      "[INFO|trainer.py:4648] 2026-01-02 19:11:48,305 >>   Batch size = 1\r\n",
      "\r\n",
      "  0%|                                                    | 0/60 [00:00<?, ?it/s]\u001b[A\r\n",
      "  3%|█▍                                          | 2/60 [00:00<00:04, 11.72it/s]\u001b[A\r\n",
      "  7%|██▉                                         | 4/60 [00:00<00:06,  8.70it/s]\u001b[A\r\n",
      "  8%|███▋                                        | 5/60 [00:00<00:06,  8.74it/s]\u001b[A\r\n",
      " 10%|████▍                                       | 6/60 [00:00<00:06,  8.06it/s]\u001b[A\r\n",
      " 12%|█████▏                                      | 7/60 [00:00<00:06,  8.03it/s]\u001b[A\r\n",
      " 13%|█████▊                                      | 8/60 [00:00<00:06,  8.14it/s]\u001b[A\r\n",
      " 15%|██████▌                                     | 9/60 [00:01<00:07,  6.77it/s]\u001b[A\r\n",
      " 17%|███████▏                                   | 10/60 [00:01<00:07,  6.86it/s]\u001b[A\r\n",
      " 18%|███████▉                                   | 11/60 [00:01<00:06,  7.37it/s]\u001b[A\r\n",
      " 20%|████████▌                                  | 12/60 [00:01<00:06,  7.40it/s]\u001b[A\r\n",
      " 22%|█████████▎                                 | 13/60 [00:01<00:06,  7.09it/s]\u001b[A\r\n",
      " 23%|██████████                                 | 14/60 [00:02<00:12,  3.70it/s]\u001b[A\r\n",
      " 25%|██████████▊                                | 15/60 [00:02<00:10,  4.27it/s]\u001b[A\r\n",
      " 27%|███████████▍                               | 16/60 [00:02<00:09,  4.77it/s]\u001b[A\r\n",
      " 28%|████████████▏                              | 17/60 [00:02<00:08,  5.21it/s]\u001b[A\r\n",
      " 30%|████████████▉                              | 18/60 [00:02<00:07,  5.58it/s]\u001b[A\r\n",
      " 32%|█████████████▌                             | 19/60 [00:02<00:06,  6.21it/s]\u001b[A\r\n",
      " 33%|██████████████▎                            | 20/60 [00:03<00:05,  6.83it/s]\u001b[A\r\n",
      " 35%|███████████████                            | 21/60 [00:03<00:05,  7.12it/s]\u001b[A\r\n",
      " 37%|███████████████▊                           | 22/60 [00:03<00:05,  6.97it/s]\u001b[A\r\n",
      " 38%|████████████████▍                          | 23/60 [00:03<00:05,  6.47it/s]\u001b[A\r\n",
      " 40%|█████████████████▏                         | 24/60 [00:04<00:10,  3.53it/s]\u001b[A\r\n",
      " 42%|█████████████████▉                         | 25/60 [00:04<00:08,  4.03it/s]\u001b[A\r\n",
      " 43%|██████████████████▋                        | 26/60 [00:04<00:07,  4.64it/s]\u001b[A\r\n",
      " 45%|███████████████████▎                       | 27/60 [00:04<00:08,  4.07it/s]\u001b[A\r\n",
      " 47%|████████████████████                       | 28/60 [00:04<00:07,  4.40it/s]\u001b[A\r\n",
      " 48%|████████████████████▊                      | 29/60 [00:05<00:06,  5.01it/s]\u001b[A\r\n",
      " 50%|█████████████████████▌                     | 30/60 [00:05<00:05,  5.88it/s]\u001b[A\r\n",
      " 52%|██████████████████████▏                    | 31/60 [00:05<00:04,  6.60it/s]\u001b[A\r\n",
      " 53%|██████████████████████▉                    | 32/60 [00:05<00:04,  6.64it/s]\u001b[A\r\n",
      " 55%|███████████████████████▋                   | 33/60 [00:05<00:04,  6.16it/s]\u001b[A\r\n",
      " 57%|████████████████████████▎                  | 34/60 [00:05<00:04,  6.36it/s]\u001b[A\r\n",
      " 58%|█████████████████████████                  | 35/60 [00:05<00:03,  6.41it/s]\u001b[A\r\n",
      " 60%|█████████████████████████▊                 | 36/60 [00:06<00:03,  6.63it/s]\u001b[A\r\n",
      " 62%|██████████████████████████▌                | 37/60 [00:06<00:03,  7.18it/s]\u001b[A\r\n",
      " 63%|███████████████████████████▏               | 38/60 [00:06<00:02,  7.40it/s]\u001b[A\r\n",
      " 65%|███████████████████████████▉               | 39/60 [00:06<00:02,  7.28it/s]\u001b[A\r\n",
      " 67%|████████████████████████████▋              | 40/60 [00:06<00:02,  6.84it/s]\u001b[A\r\n",
      " 68%|█████████████████████████████▍             | 41/60 [00:06<00:03,  6.29it/s]\u001b[A\r\n",
      " 70%|██████████████████████████████             | 42/60 [00:06<00:02,  6.30it/s]\u001b[A\r\n",
      " 72%|██████████████████████████████▊            | 43/60 [00:07<00:02,  6.19it/s]\u001b[A\r\n",
      " 73%|███████████████████████████████▌           | 44/60 [00:07<00:02,  6.25it/s]\u001b[A\r\n",
      " 75%|████████████████████████████████▎          | 45/60 [00:07<00:02,  5.78it/s]\u001b[A\r\n",
      " 77%|████████████████████████████████▉          | 46/60 [00:07<00:02,  6.19it/s]\u001b[A\r\n",
      " 78%|█████████████████████████████████▋         | 47/60 [00:07<00:01,  6.71it/s]\u001b[A\r\n",
      " 80%|██████████████████████████████████▍        | 48/60 [00:07<00:01,  6.88it/s]\u001b[A\r\n",
      " 82%|███████████████████████████████████        | 49/60 [00:07<00:01,  7.32it/s]\u001b[A\r\n",
      " 83%|███████████████████████████████████▊       | 50/60 [00:08<00:01,  6.75it/s]\u001b[A\r\n",
      " 85%|████████████████████████████████████▌      | 51/60 [00:08<00:01,  6.50it/s]\u001b[A\r\n",
      " 87%|█████████████████████████████████████▎     | 52/60 [00:08<00:01,  6.22it/s]\u001b[A\r\n",
      " 88%|█████████████████████████████████████▉     | 53/60 [00:08<00:01,  6.50it/s]\u001b[A\r\n",
      " 90%|██████████████████████████████████████▋    | 54/60 [00:08<00:00,  6.12it/s]\u001b[A\r\n",
      " 92%|███████████████████████████████████████▍   | 55/60 [00:08<00:00,  6.20it/s]\u001b[A\r\n",
      " 93%|████████████████████████████████████████▏  | 56/60 [00:09<00:00,  6.41it/s]\u001b[A\r\n",
      " 95%|████████████████████████████████████████▊  | 57/60 [00:09<00:00,  6.67it/s]\u001b[A\r\n",
      " 97%|█████████████████████████████████████████▌ | 58/60 [00:09<00:00,  6.26it/s]\u001b[A\r\n",
      " 98%|██████████████████████████████████████████▎| 59/60 [00:09<00:00,  6.00it/s]\u001b[A\r\n",
      "\r\n",
      "\u001b[A{'eval_loss': 0.7972633242607117, 'eval_runtime': 9.9974, 'eval_samples_per_second': 6.002, 'eval_steps_per_second': 6.002, 'epoch': 0.84}\r\n",
      " 28%|██████████▋                           | 400/1425 [33:14<1:22:34,  4.83s/it]\r\n",
      "100%|███████████████████████████████████████████| 60/60 [00:09<00:00,  6.45it/s]\u001b[A\r\n",
      "                                                                                \u001b[A[INFO|trainer.py:4309] 2026-01-02 19:11:58,301 >> Saving model checkpoint to /kaggle/working/models/qwen2vl-7b-vqa-grounded/checkpoint-400\r\n",
      "[INFO|configuration_utils.py:765] 2026-01-02 19:11:58,451 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2-VL-7B-Instruct/snapshots/eed13092ef92e448dd6875b2a00151bd3f7db0ac/config.json\r\n",
      "[INFO|configuration_utils.py:839] 2026-01-02 19:11:58,453 >> Model config Qwen2VLConfig {\r\n",
      "  \"architectures\": [\r\n",
      "    \"Qwen2VLForConditionalGeneration\"\r\n",
      "  ],\r\n",
      "  \"attention_dropout\": 0.0,\r\n",
      "  \"bos_token_id\": 151643,\r\n",
      "  \"dtype\": \"bfloat16\",\r\n",
      "  \"eos_token_id\": 151645,\r\n",
      "  \"hidden_act\": \"silu\",\r\n",
      "  \"hidden_size\": 3584,\r\n",
      "  \"image_token_id\": 151655,\r\n",
      "  \"initializer_range\": 0.02,\r\n",
      "  \"intermediate_size\": 18944,\r\n",
      "  \"max_position_embeddings\": 32768,\r\n",
      "  \"max_window_layers\": 28,\r\n",
      "  \"model_type\": \"qwen2_vl\",\r\n",
      "  \"num_attention_heads\": 28,\r\n",
      "  \"num_hidden_layers\": 28,\r\n",
      "  \"num_key_value_heads\": 4,\r\n",
      "  \"rms_norm_eps\": 1e-06,\r\n",
      "  \"rope_scaling\": {\r\n",
      "    \"mrope_section\": [\r\n",
      "      16,\r\n",
      "      24,\r\n",
      "      24\r\n",
      "    ],\r\n",
      "    \"rope_type\": \"default\",\r\n",
      "    \"type\": \"default\"\r\n",
      "  },\r\n",
      "  \"rope_theta\": 1000000.0,\r\n",
      "  \"sliding_window\": 32768,\r\n",
      "  \"text_config\": {\r\n",
      "    \"architectures\": [\r\n",
      "      \"Qwen2VLForConditionalGeneration\"\r\n",
      "    ],\r\n",
      "    \"attention_dropout\": 0.0,\r\n",
      "    \"bos_token_id\": 151643,\r\n",
      "    \"dtype\": \"bfloat16\",\r\n",
      "    \"eos_token_id\": 151645,\r\n",
      "    \"hidden_act\": \"silu\",\r\n",
      "    \"hidden_size\": 3584,\r\n",
      "    \"initializer_range\": 0.02,\r\n",
      "    \"intermediate_size\": 18944,\r\n",
      "    \"layer_types\": [\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\"\r\n",
      "    ],\r\n",
      "    \"max_position_embeddings\": 32768,\r\n",
      "    \"max_window_layers\": 28,\r\n",
      "    \"model_type\": \"qwen2_vl_text\",\r\n",
      "    \"num_attention_heads\": 28,\r\n",
      "    \"num_hidden_layers\": 28,\r\n",
      "    \"num_key_value_heads\": 4,\r\n",
      "    \"rms_norm_eps\": 1e-06,\r\n",
      "    \"rope_scaling\": {\r\n",
      "      \"mrope_section\": [\r\n",
      "        16,\r\n",
      "        24,\r\n",
      "        24\r\n",
      "      ],\r\n",
      "      \"rope_type\": \"default\",\r\n",
      "      \"type\": \"default\"\r\n",
      "    },\r\n",
      "    \"rope_theta\": 1000000.0,\r\n",
      "    \"sliding_window\": null,\r\n",
      "    \"use_cache\": true,\r\n",
      "    \"use_sliding_window\": false,\r\n",
      "    \"vision_token_id\": 151654,\r\n",
      "    \"vocab_size\": 152064\r\n",
      "  },\r\n",
      "  \"tie_word_embeddings\": false,\r\n",
      "  \"transformers_version\": \"4.57.1\",\r\n",
      "  \"use_cache\": true,\r\n",
      "  \"use_sliding_window\": false,\r\n",
      "  \"video_token_id\": 151656,\r\n",
      "  \"vision_config\": {\r\n",
      "    \"depth\": 32,\r\n",
      "    \"embed_dim\": 1280,\r\n",
      "    \"hidden_act\": \"quick_gelu\",\r\n",
      "    \"hidden_size\": 3584,\r\n",
      "    \"in_channels\": 3,\r\n",
      "    \"in_chans\": 3,\r\n",
      "    \"initializer_range\": 0.02,\r\n",
      "    \"mlp_ratio\": 4,\r\n",
      "    \"model_type\": \"qwen2_vl\",\r\n",
      "    \"num_heads\": 16,\r\n",
      "    \"patch_size\": 14,\r\n",
      "    \"spatial_merge_size\": 2,\r\n",
      "    \"spatial_patch_size\": 14,\r\n",
      "    \"temporal_patch_size\": 2\r\n",
      "  },\r\n",
      "  \"vision_end_token_id\": 151653,\r\n",
      "  \"vision_start_token_id\": 151652,\r\n",
      "  \"vision_token_id\": 151654,\r\n",
      "  \"vocab_size\": 152064\r\n",
      "}\r\n",
      "\r\n",
      "[INFO|tokenization_utils_base.py:2421] 2026-01-02 19:11:59,069 >> chat template saved in /kaggle/working/models/qwen2vl-7b-vqa-grounded/checkpoint-400/chat_template.jinja\r\n",
      "[INFO|tokenization_utils_base.py:2590] 2026-01-02 19:11:59,069 >> tokenizer config file saved in /kaggle/working/models/qwen2vl-7b-vqa-grounded/checkpoint-400/tokenizer_config.json\r\n",
      "[INFO|tokenization_utils_base.py:2599] 2026-01-02 19:11:59,069 >> Special tokens file saved in /kaggle/working/models/qwen2vl-7b-vqa-grounded/checkpoint-400/special_tokens_map.json\r\n",
      "[INFO|trainer.py:4418] 2026-01-02 19:12:00,204 >> Deleting older checkpoint [/kaggle/working/models/qwen2vl-7b-vqa-grounded/checkpoint-100] due to args.save_total_limit\r\n",
      "[INFO|image_processing_base.py:253] 2026-01-02 19:12:00,363 >> Image processor saved in /kaggle/working/models/qwen2vl-7b-vqa-grounded/checkpoint-400/preprocessor_config.json\r\n",
      "[INFO|tokenization_utils_base.py:2421] 2026-01-02 19:12:00,363 >> chat template saved in /kaggle/working/models/qwen2vl-7b-vqa-grounded/checkpoint-400/chat_template.jinja\r\n",
      "[INFO|tokenization_utils_base.py:2590] 2026-01-02 19:12:00,364 >> tokenizer config file saved in /kaggle/working/models/qwen2vl-7b-vqa-grounded/checkpoint-400/tokenizer_config.json\r\n",
      "[INFO|tokenization_utils_base.py:2599] 2026-01-02 19:12:00,364 >> Special tokens file saved in /kaggle/working/models/qwen2vl-7b-vqa-grounded/checkpoint-400/special_tokens_map.json\r\n",
      "[INFO|video_processing_utils.py:600] 2026-01-02 19:12:00,494 >> Video processor saved in /kaggle/working/models/qwen2vl-7b-vqa-grounded/checkpoint-400/video_preprocessor_config.json\r\n",
      "[INFO|processing_utils.py:814] 2026-01-02 19:12:00,494 >> chat template saved in /kaggle/working/models/qwen2vl-7b-vqa-grounded/checkpoint-400/chat_template.jinja\r\n",
      " 28%|██████████▊                           | 406/1425 [33:45<1:33:08,  5.48s/it]/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\r\n",
      "  warnings.warn(\r\n",
      "{'loss': 0.8056, 'grad_norm': 1.1477415561676025, 'learning_rate': 4.4874166333590894e-05, 'epoch': 0.86}\r\n",
      "{'loss': 0.8166, 'grad_norm': 1.1256557703018188, 'learning_rate': 4.4496579478985e-05, 'epoch': 0.88}\r\n",
      "{'loss': 0.8076, 'grad_norm': 1.180084466934204, 'learning_rate': 4.4107285226288554e-05, 'epoch': 0.91}\r\n",
      "{'loss': 0.8068, 'grad_norm': 1.2285600900650024, 'learning_rate': 4.3706517340752294e-05, 'epoch': 0.93}\r\n",
      "{'loss': 0.8604, 'grad_norm': 1.2141788005828857, 'learning_rate': 4.32945164773682e-05, 'epoch': 0.95}\r\n",
      "{'loss': 0.822, 'grad_norm': 1.1344550848007202, 'learning_rate': 4.2871530036359784e-05, 'epoch': 0.97}\r\n",
      "{'loss': 0.7737, 'grad_norm': 1.2314081192016602, 'learning_rate': 4.243781201462212e-05, 'epoch': 0.99}\r\n",
      "{'loss': 0.721, 'grad_norm': 1.12871515750885, 'learning_rate': 4.199362285320053e-05, 'epoch': 1.01}\r\n",
      "{'loss': 0.6946, 'grad_norm': 1.297450065612793, 'learning_rate': 4.1539229280899696e-05, 'epoch': 1.03}\r\n",
      "{'loss': 0.6946, 'grad_norm': 1.2756857872009277, 'learning_rate': 4.107490415411714e-05, 'epoch': 1.05}\r\n",
      " 35%|█████████████▎                        | 500/1425 [41:25<1:14:51,  4.86s/it][INFO|trainer.py:4643] 2026-01-02 19:20:09,625 >> \r\n",
      "***** Running Evaluation *****\r\n",
      "[INFO|trainer.py:4645] 2026-01-02 19:20:09,625 >>   Num examples = 60\r\n",
      "[INFO|trainer.py:4648] 2026-01-02 19:20:09,625 >>   Batch size = 1\r\n",
      "\r\n",
      "  0%|                                                    | 0/60 [00:00<?, ?it/s]\u001b[A\r\n",
      "  3%|█▍                                          | 2/60 [00:00<00:04, 11.78it/s]\u001b[A\r\n",
      "  7%|██▉                                         | 4/60 [00:00<00:06,  8.73it/s]\u001b[A\r\n",
      "  8%|███▋                                        | 5/60 [00:00<00:06,  8.75it/s]\u001b[A\r\n",
      " 10%|████▍                                       | 6/60 [00:00<00:06,  8.02it/s]\u001b[A\r\n",
      " 12%|█████▏                                      | 7/60 [00:00<00:06,  8.10it/s]\u001b[A\r\n",
      " 13%|█████▊                                      | 8/60 [00:00<00:06,  8.20it/s]\u001b[A\r\n",
      " 15%|██████▌                                     | 9/60 [00:01<00:07,  6.82it/s]\u001b[A\r\n",
      " 17%|███████▏                                   | 10/60 [00:01<00:07,  6.88it/s]\u001b[A\r\n",
      " 18%|███████▉                                   | 11/60 [00:01<00:06,  7.39it/s]\u001b[A\r\n",
      " 20%|████████▌                                  | 12/60 [00:01<00:06,  7.41it/s]\u001b[A\r\n",
      " 22%|█████████▎                                 | 13/60 [00:01<00:06,  7.12it/s]\u001b[A\r\n",
      " 23%|██████████                                 | 14/60 [00:02<00:12,  3.73it/s]\u001b[A\r\n",
      " 25%|██████████▊                                | 15/60 [00:02<00:10,  4.30it/s]\u001b[A\r\n",
      " 27%|███████████▍                               | 16/60 [00:02<00:09,  4.80it/s]\u001b[A\r\n",
      " 28%|████████████▏                              | 17/60 [00:02<00:08,  5.25it/s]\u001b[A\r\n",
      " 30%|████████████▉                              | 18/60 [00:02<00:07,  5.62it/s]\u001b[A\r\n",
      " 32%|█████████████▌                             | 19/60 [00:02<00:06,  6.24it/s]\u001b[A\r\n",
      " 33%|██████████████▎                            | 20/60 [00:03<00:05,  6.87it/s]\u001b[A\r\n",
      " 35%|███████████████                            | 21/60 [00:03<00:05,  7.18it/s]\u001b[A\r\n",
      " 37%|███████████████▊                           | 22/60 [00:03<00:05,  6.98it/s]\u001b[A\r\n",
      " 38%|████████████████▍                          | 23/60 [00:03<00:05,  6.53it/s]\u001b[A\r\n",
      " 40%|█████████████████▏                         | 24/60 [00:04<00:09,  3.67it/s]\u001b[A\r\n",
      " 42%|█████████████████▉                         | 25/60 [00:04<00:08,  4.17it/s]\u001b[A\r\n",
      " 43%|██████████████████▋                        | 26/60 [00:04<00:07,  4.77it/s]\u001b[A\r\n",
      " 45%|███████████████████▎                       | 27/60 [00:04<00:07,  4.20it/s]\u001b[A\r\n",
      " 47%|████████████████████                       | 28/60 [00:04<00:07,  4.54it/s]\u001b[A\r\n",
      " 48%|████████████████████▊                      | 29/60 [00:05<00:06,  5.14it/s]\u001b[A\r\n",
      " 52%|██████████████████████▏                    | 31/60 [00:05<00:04,  6.57it/s]\u001b[A\r\n",
      " 53%|██████████████████████▉                    | 32/60 [00:05<00:04,  6.60it/s]\u001b[A\r\n",
      " 55%|███████████████████████▋                   | 33/60 [00:05<00:04,  6.21it/s]\u001b[A\r\n",
      " 57%|████████████████████████▎                  | 34/60 [00:05<00:04,  6.38it/s]\u001b[A\r\n",
      " 58%|█████████████████████████                  | 35/60 [00:05<00:03,  6.43it/s]\u001b[A\r\n",
      " 60%|█████████████████████████▊                 | 36/60 [00:05<00:03,  6.64it/s]\u001b[A\r\n",
      " 62%|██████████████████████████▌                | 37/60 [00:06<00:03,  7.17it/s]\u001b[A\r\n",
      " 63%|███████████████████████████▏               | 38/60 [00:06<00:02,  7.41it/s]\u001b[A\r\n",
      " 65%|███████████████████████████▉               | 39/60 [00:06<00:02,  7.30it/s]\u001b[A\r\n",
      " 67%|████████████████████████████▋              | 40/60 [00:06<00:02,  6.87it/s]\u001b[A\r\n",
      " 68%|█████████████████████████████▍             | 41/60 [00:06<00:02,  6.38it/s]\u001b[A\r\n",
      " 70%|██████████████████████████████             | 42/60 [00:06<00:02,  6.38it/s]\u001b[A\r\n",
      " 72%|██████████████████████████████▊            | 43/60 [00:07<00:02,  6.28it/s]\u001b[A\r\n",
      " 73%|███████████████████████████████▌           | 44/60 [00:07<00:02,  6.30it/s]\u001b[A\r\n",
      " 75%|████████████████████████████████▎          | 45/60 [00:07<00:02,  5.84it/s]\u001b[A\r\n",
      " 77%|████████████████████████████████▉          | 46/60 [00:07<00:02,  6.23it/s]\u001b[A\r\n",
      " 78%|█████████████████████████████████▋         | 47/60 [00:07<00:01,  6.66it/s]\u001b[A\r\n",
      " 80%|██████████████████████████████████▍        | 48/60 [00:07<00:01,  6.84it/s]\u001b[A\r\n",
      " 82%|███████████████████████████████████        | 49/60 [00:07<00:01,  7.31it/s]\u001b[A\r\n",
      " 83%|███████████████████████████████████▊       | 50/60 [00:08<00:01,  6.80it/s]\u001b[A\r\n",
      " 85%|████████████████████████████████████▌      | 51/60 [00:08<00:01,  6.70it/s]\u001b[A\r\n",
      " 87%|█████████████████████████████████████▎     | 52/60 [00:08<00:01,  6.38it/s]\u001b[A\r\n",
      " 88%|█████████████████████████████████████▉     | 53/60 [00:08<00:01,  6.64it/s]\u001b[A\r\n",
      " 90%|██████████████████████████████████████▋    | 54/60 [00:08<00:00,  6.20it/s]\u001b[A\r\n",
      " 92%|███████████████████████████████████████▍   | 55/60 [00:08<00:00,  6.29it/s]\u001b[A\r\n",
      " 93%|████████████████████████████████████████▏  | 56/60 [00:09<00:00,  6.48it/s]\u001b[A\r\n",
      " 95%|████████████████████████████████████████▊  | 57/60 [00:09<00:00,  6.73it/s]\u001b[A\r\n",
      " 97%|█████████████████████████████████████████▌ | 58/60 [00:09<00:00,  6.34it/s]\u001b[A\r\n",
      " 98%|██████████████████████████████████████████▎| 59/60 [00:09<00:00,  6.13it/s]\u001b[A\r\n",
      "100%|███████████████████████████████████████████| 60/60 [00:09<00:00,  6.56it/s]\u001b[A\r\n",
      "{'eval_loss': 0.7845768332481384, 'eval_runtime': 9.8761, 'eval_samples_per_second': 6.075, 'eval_steps_per_second': 6.075, 'epoch': 1.05}\r\n",
      "\r\n",
      " 35%|█████████████▎                        | 500/1425 [41:35<1:14:51,  4.86s/it]\r\n",
      "                                                                                \u001b[A[INFO|trainer.py:4309] 2026-01-02 19:20:19,499 >> Saving model checkpoint to /kaggle/working/models/qwen2vl-7b-vqa-grounded/checkpoint-500\r\n",
      "[INFO|configuration_utils.py:765] 2026-01-02 19:20:19,617 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2-VL-7B-Instruct/snapshots/eed13092ef92e448dd6875b2a00151bd3f7db0ac/config.json\r\n",
      "[INFO|configuration_utils.py:839] 2026-01-02 19:20:19,619 >> Model config Qwen2VLConfig {\r\n",
      "  \"architectures\": [\r\n",
      "    \"Qwen2VLForConditionalGeneration\"\r\n",
      "  ],\r\n",
      "  \"attention_dropout\": 0.0,\r\n",
      "  \"bos_token_id\": 151643,\r\n",
      "  \"dtype\": \"bfloat16\",\r\n",
      "  \"eos_token_id\": 151645,\r\n",
      "  \"hidden_act\": \"silu\",\r\n",
      "  \"hidden_size\": 3584,\r\n",
      "  \"image_token_id\": 151655,\r\n",
      "  \"initializer_range\": 0.02,\r\n",
      "  \"intermediate_size\": 18944,\r\n",
      "  \"max_position_embeddings\": 32768,\r\n",
      "  \"max_window_layers\": 28,\r\n",
      "  \"model_type\": \"qwen2_vl\",\r\n",
      "  \"num_attention_heads\": 28,\r\n",
      "  \"num_hidden_layers\": 28,\r\n",
      "  \"num_key_value_heads\": 4,\r\n",
      "  \"rms_norm_eps\": 1e-06,\r\n",
      "  \"rope_scaling\": {\r\n",
      "    \"mrope_section\": [\r\n",
      "      16,\r\n",
      "      24,\r\n",
      "      24\r\n",
      "    ],\r\n",
      "    \"rope_type\": \"default\",\r\n",
      "    \"type\": \"default\"\r\n",
      "  },\r\n",
      "  \"rope_theta\": 1000000.0,\r\n",
      "  \"sliding_window\": 32768,\r\n",
      "  \"text_config\": {\r\n",
      "    \"architectures\": [\r\n",
      "      \"Qwen2VLForConditionalGeneration\"\r\n",
      "    ],\r\n",
      "    \"attention_dropout\": 0.0,\r\n",
      "    \"bos_token_id\": 151643,\r\n",
      "    \"dtype\": \"bfloat16\",\r\n",
      "    \"eos_token_id\": 151645,\r\n",
      "    \"hidden_act\": \"silu\",\r\n",
      "    \"hidden_size\": 3584,\r\n",
      "    \"initializer_range\": 0.02,\r\n",
      "    \"intermediate_size\": 18944,\r\n",
      "    \"layer_types\": [\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\"\r\n",
      "    ],\r\n",
      "    \"max_position_embeddings\": 32768,\r\n",
      "    \"max_window_layers\": 28,\r\n",
      "    \"model_type\": \"qwen2_vl_text\",\r\n",
      "    \"num_attention_heads\": 28,\r\n",
      "    \"num_hidden_layers\": 28,\r\n",
      "    \"num_key_value_heads\": 4,\r\n",
      "    \"rms_norm_eps\": 1e-06,\r\n",
      "    \"rope_scaling\": {\r\n",
      "      \"mrope_section\": [\r\n",
      "        16,\r\n",
      "        24,\r\n",
      "        24\r\n",
      "      ],\r\n",
      "      \"rope_type\": \"default\",\r\n",
      "      \"type\": \"default\"\r\n",
      "    },\r\n",
      "    \"rope_theta\": 1000000.0,\r\n",
      "    \"sliding_window\": null,\r\n",
      "    \"use_cache\": true,\r\n",
      "    \"use_sliding_window\": false,\r\n",
      "    \"vision_token_id\": 151654,\r\n",
      "    \"vocab_size\": 152064\r\n",
      "  },\r\n",
      "  \"tie_word_embeddings\": false,\r\n",
      "  \"transformers_version\": \"4.57.1\",\r\n",
      "  \"use_cache\": true,\r\n",
      "  \"use_sliding_window\": false,\r\n",
      "  \"video_token_id\": 151656,\r\n",
      "  \"vision_config\": {\r\n",
      "    \"depth\": 32,\r\n",
      "    \"embed_dim\": 1280,\r\n",
      "    \"hidden_act\": \"quick_gelu\",\r\n",
      "    \"hidden_size\": 3584,\r\n",
      "    \"in_channels\": 3,\r\n",
      "    \"in_chans\": 3,\r\n",
      "    \"initializer_range\": 0.02,\r\n",
      "    \"mlp_ratio\": 4,\r\n",
      "    \"model_type\": \"qwen2_vl\",\r\n",
      "    \"num_heads\": 16,\r\n",
      "    \"patch_size\": 14,\r\n",
      "    \"spatial_merge_size\": 2,\r\n",
      "    \"spatial_patch_size\": 14,\r\n",
      "    \"temporal_patch_size\": 2\r\n",
      "  },\r\n",
      "  \"vision_end_token_id\": 151653,\r\n",
      "  \"vision_start_token_id\": 151652,\r\n",
      "  \"vision_token_id\": 151654,\r\n",
      "  \"vocab_size\": 152064\r\n",
      "}\r\n",
      "\r\n",
      "[INFO|tokenization_utils_base.py:2421] 2026-01-02 19:20:20,242 >> chat template saved in /kaggle/working/models/qwen2vl-7b-vqa-grounded/checkpoint-500/chat_template.jinja\r\n",
      "[INFO|tokenization_utils_base.py:2590] 2026-01-02 19:20:20,242 >> tokenizer config file saved in /kaggle/working/models/qwen2vl-7b-vqa-grounded/checkpoint-500/tokenizer_config.json\r\n",
      "[INFO|tokenization_utils_base.py:2599] 2026-01-02 19:20:20,242 >> Special tokens file saved in /kaggle/working/models/qwen2vl-7b-vqa-grounded/checkpoint-500/special_tokens_map.json\r\n",
      "[INFO|trainer.py:4418] 2026-01-02 19:20:21,340 >> Deleting older checkpoint [/kaggle/working/models/qwen2vl-7b-vqa-grounded/checkpoint-200] due to args.save_total_limit\r\n",
      "[INFO|image_processing_base.py:253] 2026-01-02 19:20:21,494 >> Image processor saved in /kaggle/working/models/qwen2vl-7b-vqa-grounded/checkpoint-500/preprocessor_config.json\r\n",
      "[INFO|tokenization_utils_base.py:2421] 2026-01-02 19:20:21,494 >> chat template saved in /kaggle/working/models/qwen2vl-7b-vqa-grounded/checkpoint-500/chat_template.jinja\r\n",
      "[INFO|tokenization_utils_base.py:2590] 2026-01-02 19:20:21,495 >> tokenizer config file saved in /kaggle/working/models/qwen2vl-7b-vqa-grounded/checkpoint-500/tokenizer_config.json\r\n",
      "[INFO|tokenization_utils_base.py:2599] 2026-01-02 19:20:21,495 >> Special tokens file saved in /kaggle/working/models/qwen2vl-7b-vqa-grounded/checkpoint-500/special_tokens_map.json\r\n",
      "[INFO|video_processing_utils.py:600] 2026-01-02 19:20:21,628 >> Video processor saved in /kaggle/working/models/qwen2vl-7b-vqa-grounded/checkpoint-500/video_preprocessor_config.json\r\n",
      "[INFO|processing_utils.py:814] 2026-01-02 19:20:21,628 >> chat template saved in /kaggle/working/models/qwen2vl-7b-vqa-grounded/checkpoint-500/chat_template.jinja\r\n",
      " 35%|█████████████▎                        | 501/1425 [41:42<2:09:39,  8.42s/it]/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\r\n",
      "  warnings.warn(\r\n",
      "{'loss': 0.7, 'grad_norm': 1.235469102859497, 'learning_rate': 4.060092629299714e-05, 'epoch': 1.07}\r\n",
      "{'loss': 0.6539, 'grad_norm': 1.3131070137023926, 'learning_rate': 4.01175803140034e-05, 'epoch': 1.09}\r\n",
      "{'loss': 0.6701, 'grad_norm': 1.3629041910171509, 'learning_rate': 3.962515645901133e-05, 'epoch': 1.12}\r\n",
      "{'loss': 0.6841, 'grad_norm': 1.305135726928711, 'learning_rate': 3.9123950421022134e-05, 'epoch': 1.14}\r\n",
      "{'loss': 0.6988, 'grad_norm': 1.3535245656967163, 'learning_rate': 3.861426316660375e-05, 'epoch': 1.16}\r\n",
      "{'loss': 0.6862, 'grad_norm': 1.3547743558883667, 'learning_rate': 3.809640075516498e-05, 'epoch': 1.18}\r\n",
      "{'loss': 0.6404, 'grad_norm': 1.2896714210510254, 'learning_rate': 3.757067415517153e-05, 'epoch': 1.2}\r\n",
      "{'loss': 0.6748, 'grad_norm': 1.373661994934082, 'learning_rate': 3.703739905741414e-05, 'epoch': 1.22}\r\n",
      "{'loss': 0.6742, 'grad_norm': 1.3261466026306152, 'learning_rate': 3.649689568544117e-05, 'epoch': 1.24}\r\n",
      "{'loss': 0.675, 'grad_norm': 1.384568214416504, 'learning_rate': 3.5949488603269183e-05, 'epoch': 1.26}\r\n",
      " 42%|████████████████                      | 600/1425 [49:44<1:06:40,  4.85s/it][INFO|trainer.py:4643] 2026-01-02 19:28:28,996 >> \r\n",
      "***** Running Evaluation *****\r\n",
      "[INFO|trainer.py:4645] 2026-01-02 19:28:28,996 >>   Num examples = 60\r\n",
      "[INFO|trainer.py:4648] 2026-01-02 19:28:28,996 >>   Batch size = 1\r\n",
      "\r\n",
      "  0%|                                                    | 0/60 [00:00<?, ?it/s]\u001b[A\r\n",
      "  3%|█▍                                          | 2/60 [00:00<00:04, 11.83it/s]\u001b[A\r\n",
      "  7%|██▉                                         | 4/60 [00:00<00:06,  8.70it/s]\u001b[A\r\n",
      "  8%|███▋                                        | 5/60 [00:00<00:06,  8.68it/s]\u001b[A\r\n",
      " 10%|████▍                                       | 6/60 [00:00<00:06,  8.00it/s]\u001b[A\r\n",
      " 12%|█████▏                                      | 7/60 [00:00<00:06,  8.09it/s]\u001b[A\r\n",
      " 13%|█████▊                                      | 8/60 [00:00<00:06,  8.17it/s]\u001b[A\r\n",
      " 15%|██████▌                                     | 9/60 [00:01<00:07,  6.79it/s]\u001b[A\r\n",
      " 17%|███████▏                                   | 10/60 [00:01<00:07,  6.88it/s]\u001b[A\r\n",
      " 18%|███████▉                                   | 11/60 [00:01<00:06,  7.39it/s]\u001b[A\r\n",
      " 20%|████████▌                                  | 12/60 [00:01<00:06,  7.41it/s]\u001b[A\r\n",
      " 22%|█████████▎                                 | 13/60 [00:01<00:06,  7.06it/s]\u001b[A\r\n",
      " 23%|██████████                                 | 14/60 [00:02<00:12,  3.76it/s]\u001b[A\r\n",
      " 25%|██████████▊                                | 15/60 [00:02<00:10,  4.33it/s]\u001b[A\r\n",
      " 27%|███████████▍                               | 16/60 [00:02<00:09,  4.81it/s]\u001b[A\r\n",
      " 28%|████████████▏                              | 17/60 [00:02<00:08,  5.26it/s]\u001b[A\r\n",
      " 30%|████████████▉                              | 18/60 [00:02<00:07,  5.63it/s]\u001b[A\r\n",
      " 32%|█████████████▌                             | 19/60 [00:02<00:06,  6.27it/s]\u001b[A\r\n",
      " 33%|██████████████▎                            | 20/60 [00:03<00:05,  6.87it/s]\u001b[A\r\n",
      " 35%|███████████████                            | 21/60 [00:03<00:05,  7.18it/s]\u001b[A\r\n",
      " 37%|███████████████▊                           | 22/60 [00:03<00:05,  7.01it/s]\u001b[A\r\n",
      " 38%|████████████████▍                          | 23/60 [00:03<00:05,  6.53it/s]\u001b[A\r\n",
      " 40%|█████████████████▏                         | 24/60 [00:04<00:10,  3.59it/s]\u001b[A\r\n",
      " 42%|█████████████████▉                         | 25/60 [00:04<00:08,  4.09it/s]\u001b[A\r\n",
      " 43%|██████████████████▋                        | 26/60 [00:04<00:07,  4.70it/s]\u001b[A\r\n",
      " 45%|███████████████████▎                       | 27/60 [00:04<00:07,  4.13it/s]\u001b[A\r\n",
      " 47%|████████████████████                       | 28/60 [00:04<00:07,  4.49it/s]\u001b[A\r\n",
      " 48%|████████████████████▊                      | 29/60 [00:05<00:06,  5.09it/s]\u001b[A\r\n",
      " 52%|██████████████████████▏                    | 31/60 [00:05<00:04,  6.54it/s]\u001b[A\r\n",
      " 53%|██████████████████████▉                    | 32/60 [00:05<00:04,  6.62it/s]\u001b[A\r\n",
      " 55%|███████████████████████▋                   | 33/60 [00:05<00:04,  6.21it/s]\u001b[A\r\n",
      " 57%|████████████████████████▎                  | 34/60 [00:05<00:04,  6.38it/s]\u001b[A\r\n",
      " 58%|█████████████████████████                  | 35/60 [00:05<00:03,  6.45it/s]\u001b[A\r\n",
      " 60%|█████████████████████████▊                 | 36/60 [00:06<00:03,  6.65it/s]\u001b[A\r\n",
      " 62%|██████████████████████████▌                | 37/60 [00:06<00:03,  7.20it/s]\u001b[A\r\n",
      " 63%|███████████████████████████▏               | 38/60 [00:06<00:02,  7.42it/s]\u001b[A\r\n",
      " 65%|███████████████████████████▉               | 39/60 [00:06<00:02,  7.29it/s]\u001b[A\r\n",
      " 67%|████████████████████████████▋              | 40/60 [00:06<00:02,  6.83it/s]\u001b[A\r\n",
      " 68%|█████████████████████████████▍             | 41/60 [00:06<00:03,  6.28it/s]\u001b[A\r\n",
      " 70%|██████████████████████████████             | 42/60 [00:06<00:02,  6.33it/s]\u001b[A\r\n",
      " 72%|██████████████████████████████▊            | 43/60 [00:07<00:02,  6.20it/s]\u001b[A\r\n",
      " 73%|███████████████████████████████▌           | 44/60 [00:07<00:02,  6.25it/s]\u001b[A\r\n",
      " 75%|████████████████████████████████▎          | 45/60 [00:07<00:02,  5.76it/s]\u001b[A\r\n",
      " 77%|████████████████████████████████▉          | 46/60 [00:07<00:02,  6.17it/s]\u001b[A\r\n",
      " 78%|█████████████████████████████████▋         | 47/60 [00:07<00:01,  6.69it/s]\u001b[A\r\n",
      " 80%|██████████████████████████████████▍        | 48/60 [00:07<00:01,  6.86it/s]\u001b[A\r\n",
      " 82%|███████████████████████████████████        | 49/60 [00:07<00:01,  7.32it/s]\u001b[A\r\n",
      " 83%|███████████████████████████████████▊       | 50/60 [00:08<00:01,  6.82it/s]\u001b[A\r\n",
      " 85%|████████████████████████████████████▌      | 51/60 [00:08<00:01,  6.72it/s]\u001b[A\r\n",
      " 87%|█████████████████████████████████████▎     | 52/60 [00:08<00:01,  6.38it/s]\u001b[A\r\n",
      " 88%|█████████████████████████████████████▉     | 53/60 [00:08<00:01,  6.62it/s]\u001b[A\r\n",
      " 90%|██████████████████████████████████████▋    | 54/60 [00:08<00:00,  6.20it/s]\u001b[A\r\n",
      " 92%|███████████████████████████████████████▍   | 55/60 [00:08<00:00,  6.28it/s]\u001b[A\r\n",
      " 93%|████████████████████████████████████████▏  | 56/60 [00:09<00:00,  6.48it/s]\u001b[A\r\n",
      " 95%|████████████████████████████████████████▊  | 57/60 [00:09<00:00,  6.75it/s]\u001b[A\r\n",
      " 97%|█████████████████████████████████████████▌ | 58/60 [00:09<00:00,  6.33it/s]\u001b[A\r\n",
      " 98%|██████████████████████████████████████████▎| 59/60 [00:09<00:00,  6.09it/s]\u001b[A\r\n",
      "100%|███████████████████████████████████████████| 60/60 [00:09<00:00,  6.53it/s]\u001b[A\r\n",
      "{'eval_loss': 0.7581847310066223, 'eval_runtime': 9.9025, 'eval_samples_per_second': 6.059, 'eval_steps_per_second': 6.059, 'epoch': 1.26}\r\n",
      "\r\n",
      " 42%|████████████████                      | 600/1425 [49:54<1:06:40,  4.85s/it]\r\n",
      "                                                                                \u001b[A[INFO|trainer.py:4309] 2026-01-02 19:28:38,897 >> Saving model checkpoint to /kaggle/working/models/qwen2vl-7b-vqa-grounded/checkpoint-600\r\n",
      "[INFO|configuration_utils.py:765] 2026-01-02 19:28:39,055 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2-VL-7B-Instruct/snapshots/eed13092ef92e448dd6875b2a00151bd3f7db0ac/config.json\r\n",
      "[INFO|configuration_utils.py:839] 2026-01-02 19:28:39,057 >> Model config Qwen2VLConfig {\r\n",
      "  \"architectures\": [\r\n",
      "    \"Qwen2VLForConditionalGeneration\"\r\n",
      "  ],\r\n",
      "  \"attention_dropout\": 0.0,\r\n",
      "  \"bos_token_id\": 151643,\r\n",
      "  \"dtype\": \"bfloat16\",\r\n",
      "  \"eos_token_id\": 151645,\r\n",
      "  \"hidden_act\": \"silu\",\r\n",
      "  \"hidden_size\": 3584,\r\n",
      "  \"image_token_id\": 151655,\r\n",
      "  \"initializer_range\": 0.02,\r\n",
      "  \"intermediate_size\": 18944,\r\n",
      "  \"max_position_embeddings\": 32768,\r\n",
      "  \"max_window_layers\": 28,\r\n",
      "  \"model_type\": \"qwen2_vl\",\r\n",
      "  \"num_attention_heads\": 28,\r\n",
      "  \"num_hidden_layers\": 28,\r\n",
      "  \"num_key_value_heads\": 4,\r\n",
      "  \"rms_norm_eps\": 1e-06,\r\n",
      "  \"rope_scaling\": {\r\n",
      "    \"mrope_section\": [\r\n",
      "      16,\r\n",
      "      24,\r\n",
      "      24\r\n",
      "    ],\r\n",
      "    \"rope_type\": \"default\",\r\n",
      "    \"type\": \"default\"\r\n",
      "  },\r\n",
      "  \"rope_theta\": 1000000.0,\r\n",
      "  \"sliding_window\": 32768,\r\n",
      "  \"text_config\": {\r\n",
      "    \"architectures\": [\r\n",
      "      \"Qwen2VLForConditionalGeneration\"\r\n",
      "    ],\r\n",
      "    \"attention_dropout\": 0.0,\r\n",
      "    \"bos_token_id\": 151643,\r\n",
      "    \"dtype\": \"bfloat16\",\r\n",
      "    \"eos_token_id\": 151645,\r\n",
      "    \"hidden_act\": \"silu\",\r\n",
      "    \"hidden_size\": 3584,\r\n",
      "    \"initializer_range\": 0.02,\r\n",
      "    \"intermediate_size\": 18944,\r\n",
      "    \"layer_types\": [\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\"\r\n",
      "    ],\r\n",
      "    \"max_position_embeddings\": 32768,\r\n",
      "    \"max_window_layers\": 28,\r\n",
      "    \"model_type\": \"qwen2_vl_text\",\r\n",
      "    \"num_attention_heads\": 28,\r\n",
      "    \"num_hidden_layers\": 28,\r\n",
      "    \"num_key_value_heads\": 4,\r\n",
      "    \"rms_norm_eps\": 1e-06,\r\n",
      "    \"rope_scaling\": {\r\n",
      "      \"mrope_section\": [\r\n",
      "        16,\r\n",
      "        24,\r\n",
      "        24\r\n",
      "      ],\r\n",
      "      \"rope_type\": \"default\",\r\n",
      "      \"type\": \"default\"\r\n",
      "    },\r\n",
      "    \"rope_theta\": 1000000.0,\r\n",
      "    \"sliding_window\": null,\r\n",
      "    \"use_cache\": true,\r\n",
      "    \"use_sliding_window\": false,\r\n",
      "    \"vision_token_id\": 151654,\r\n",
      "    \"vocab_size\": 152064\r\n",
      "  },\r\n",
      "  \"tie_word_embeddings\": false,\r\n",
      "  \"transformers_version\": \"4.57.1\",\r\n",
      "  \"use_cache\": true,\r\n",
      "  \"use_sliding_window\": false,\r\n",
      "  \"video_token_id\": 151656,\r\n",
      "  \"vision_config\": {\r\n",
      "    \"depth\": 32,\r\n",
      "    \"embed_dim\": 1280,\r\n",
      "    \"hidden_act\": \"quick_gelu\",\r\n",
      "    \"hidden_size\": 3584,\r\n",
      "    \"in_channels\": 3,\r\n",
      "    \"in_chans\": 3,\r\n",
      "    \"initializer_range\": 0.02,\r\n",
      "    \"mlp_ratio\": 4,\r\n",
      "    \"model_type\": \"qwen2_vl\",\r\n",
      "    \"num_heads\": 16,\r\n",
      "    \"patch_size\": 14,\r\n",
      "    \"spatial_merge_size\": 2,\r\n",
      "    \"spatial_patch_size\": 14,\r\n",
      "    \"temporal_patch_size\": 2\r\n",
      "  },\r\n",
      "  \"vision_end_token_id\": 151653,\r\n",
      "  \"vision_start_token_id\": 151652,\r\n",
      "  \"vision_token_id\": 151654,\r\n",
      "  \"vocab_size\": 152064\r\n",
      "}\r\n",
      "\r\n",
      "[INFO|tokenization_utils_base.py:2421] 2026-01-02 19:28:39,670 >> chat template saved in /kaggle/working/models/qwen2vl-7b-vqa-grounded/checkpoint-600/chat_template.jinja\r\n",
      "[INFO|tokenization_utils_base.py:2590] 2026-01-02 19:28:39,670 >> tokenizer config file saved in /kaggle/working/models/qwen2vl-7b-vqa-grounded/checkpoint-600/tokenizer_config.json\r\n",
      "[INFO|tokenization_utils_base.py:2599] 2026-01-02 19:28:39,670 >> Special tokens file saved in /kaggle/working/models/qwen2vl-7b-vqa-grounded/checkpoint-600/special_tokens_map.json\r\n",
      "[INFO|trainer.py:4418] 2026-01-02 19:28:40,783 >> Deleting older checkpoint [/kaggle/working/models/qwen2vl-7b-vqa-grounded/checkpoint-300] due to args.save_total_limit\r\n",
      "[INFO|image_processing_base.py:253] 2026-01-02 19:28:40,942 >> Image processor saved in /kaggle/working/models/qwen2vl-7b-vqa-grounded/checkpoint-600/preprocessor_config.json\r\n",
      "[INFO|tokenization_utils_base.py:2421] 2026-01-02 19:28:40,942 >> chat template saved in /kaggle/working/models/qwen2vl-7b-vqa-grounded/checkpoint-600/chat_template.jinja\r\n",
      "[INFO|tokenization_utils_base.py:2590] 2026-01-02 19:28:40,942 >> tokenizer config file saved in /kaggle/working/models/qwen2vl-7b-vqa-grounded/checkpoint-600/tokenizer_config.json\r\n",
      "[INFO|tokenization_utils_base.py:2599] 2026-01-02 19:28:40,942 >> Special tokens file saved in /kaggle/working/models/qwen2vl-7b-vqa-grounded/checkpoint-600/special_tokens_map.json\r\n",
      "[INFO|video_processing_utils.py:600] 2026-01-02 19:28:41,066 >> Video processor saved in /kaggle/working/models/qwen2vl-7b-vqa-grounded/checkpoint-600/video_preprocessor_config.json\r\n",
      "[INFO|processing_utils.py:814] 2026-01-02 19:28:41,066 >> chat template saved in /kaggle/working/models/qwen2vl-7b-vqa-grounded/checkpoint-600/chat_template.jinja\r\n",
      " 42%|████████████████▏                     | 605/1425 [50:20<1:17:46,  5.69s/it]/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\r\n",
      "  warnings.warn(\r\n",
      "{'loss': 0.6535, 'grad_norm': 1.3055713176727295, 'learning_rate': 3.539550652048723e-05, 'epoch': 1.28}\r\n",
      "{'loss': 0.6911, 'grad_norm': 1.3457432985305786, 'learning_rate': 3.483528209487178e-05, 'epoch': 1.31}\r\n",
      "{'loss': 0.6798, 'grad_norm': 1.3784734010696411, 'learning_rate': 3.426915173263079e-05, 'epoch': 1.33}\r\n",
      "{'loss': 0.6665, 'grad_norm': 1.3615195751190186, 'learning_rate': 3.369745538639694e-05, 'epoch': 1.35}\r\n",
      "{'loss': 0.6978, 'grad_norm': 1.4139468669891357, 'learning_rate': 3.3120536351091234e-05, 'epoch': 1.37}\r\n",
      "{'loss': 0.67, 'grad_norm': 1.2907021045684814, 'learning_rate': 3.2538741057779674e-05, 'epoch': 1.39}\r\n",
      "{'loss': 0.6837, 'grad_norm': 1.3320553302764893, 'learning_rate': 3.1952418865646705e-05, 'epoch': 1.41}\r\n",
      "{'loss': 0.6765, 'grad_norm': 1.295037865638733, 'learning_rate': 3.1361921852210324e-05, 'epoch': 1.43}\r\n",
      "{'loss': 0.6805, 'grad_norm': 1.2872731685638428, 'learning_rate': 3.076760460190495e-05, 'epoch': 1.45}\r\n",
      "{'loss': 0.6594, 'grad_norm': 1.3554264307022095, 'learning_rate': 3.016982399315888e-05, 'epoch': 1.47}\r\n",
      " 49%|██████████████████▋                   | 700/1425 [58:07<1:00:07,  4.98s/it][INFO|trainer.py:4643] 2026-01-02 19:36:51,689 >> \r\n",
      "***** Running Evaluation *****\r\n",
      "[INFO|trainer.py:4645] 2026-01-02 19:36:51,689 >>   Num examples = 60\r\n",
      "[INFO|trainer.py:4648] 2026-01-02 19:36:51,689 >>   Batch size = 1\r\n",
      "\r\n",
      "  0%|                                                    | 0/60 [00:00<?, ?it/s]\u001b[A\r\n",
      "  3%|█▍                                          | 2/60 [00:00<00:04, 11.86it/s]\u001b[A\r\n",
      "  7%|██▉                                         | 4/60 [00:00<00:06,  8.70it/s]\u001b[A\r\n",
      "  8%|███▋                                        | 5/60 [00:00<00:06,  8.71it/s]\u001b[A\r\n",
      " 10%|████▍                                       | 6/60 [00:00<00:06,  8.06it/s]\u001b[A\r\n",
      " 12%|█████▏                                      | 7/60 [00:00<00:06,  8.13it/s]\u001b[A\r\n",
      " 13%|█████▊                                      | 8/60 [00:00<00:06,  8.22it/s]\u001b[A\r\n",
      " 15%|██████▌                                     | 9/60 [00:01<00:07,  6.81it/s]\u001b[A\r\n",
      " 17%|███████▏                                   | 10/60 [00:01<00:07,  6.90it/s]\u001b[A\r\n",
      " 18%|███████▉                                   | 11/60 [00:01<00:06,  7.40it/s]\u001b[A\r\n",
      " 20%|████████▌                                  | 12/60 [00:01<00:06,  7.41it/s]\u001b[A\r\n",
      " 22%|█████████▎                                 | 13/60 [00:01<00:06,  7.08it/s]\u001b[A\r\n",
      " 23%|██████████                                 | 14/60 [00:02<00:12,  3.69it/s]\u001b[A\r\n",
      " 25%|██████████▊                                | 15/60 [00:02<00:10,  4.25it/s]\u001b[A\r\n",
      " 27%|███████████▍                               | 16/60 [00:02<00:09,  4.74it/s]\u001b[A\r\n",
      " 28%|████████████▏                              | 17/60 [00:02<00:08,  5.20it/s]\u001b[A\r\n",
      " 30%|████████████▉                              | 18/60 [00:02<00:07,  5.56it/s]\u001b[A\r\n",
      " 32%|█████████████▌                             | 19/60 [00:02<00:06,  6.20it/s]\u001b[A\r\n",
      " 33%|██████████████▎                            | 20/60 [00:03<00:05,  6.81it/s]\u001b[A\r\n",
      " 35%|███████████████                            | 21/60 [00:03<00:05,  7.10it/s]\u001b[A\r\n",
      " 37%|███████████████▊                           | 22/60 [00:03<00:05,  6.90it/s]\u001b[A\r\n",
      " 38%|████████████████▍                          | 23/60 [00:03<00:05,  6.41it/s]\u001b[A\r\n",
      " 40%|█████████████████▏                         | 24/60 [00:04<00:10,  3.45it/s]\u001b[A\r\n",
      " 42%|█████████████████▉                         | 25/60 [00:04<00:08,  3.94it/s]\u001b[A\r\n",
      " 43%|██████████████████▋                        | 26/60 [00:04<00:07,  4.56it/s]\u001b[A\r\n",
      " 45%|███████████████████▎                       | 27/60 [00:04<00:08,  3.98it/s]\u001b[A\r\n",
      " 47%|████████████████████                       | 28/60 [00:04<00:07,  4.33it/s]\u001b[A\r\n",
      " 48%|████████████████████▊                      | 29/60 [00:05<00:06,  4.94it/s]\u001b[A\r\n",
      " 50%|█████████████████████▌                     | 30/60 [00:05<00:05,  5.81it/s]\u001b[A\r\n",
      " 52%|██████████████████████▏                    | 31/60 [00:05<00:04,  6.55it/s]\u001b[A\r\n",
      " 53%|██████████████████████▉                    | 32/60 [00:05<00:04,  6.55it/s]\u001b[A\r\n",
      " 55%|███████████████████████▋                   | 33/60 [00:05<00:04,  6.07it/s]\u001b[A\r\n",
      " 57%|████████████████████████▎                  | 34/60 [00:05<00:04,  6.30it/s]\u001b[A\r\n",
      " 58%|█████████████████████████                  | 35/60 [00:05<00:03,  6.37it/s]\u001b[A\r\n",
      " 60%|█████████████████████████▊                 | 36/60 [00:06<00:03,  6.59it/s]\u001b[A\r\n",
      " 62%|██████████████████████████▌                | 37/60 [00:06<00:03,  7.14it/s]\u001b[A\r\n",
      " 63%|███████████████████████████▏               | 38/60 [00:06<00:02,  7.36it/s]\u001b[A\r\n",
      " 65%|███████████████████████████▉               | 39/60 [00:06<00:02,  7.21it/s]\u001b[A\r\n",
      " 67%|████████████████████████████▋              | 40/60 [00:06<00:02,  6.77it/s]\u001b[A\r\n",
      " 68%|█████████████████████████████▍             | 41/60 [00:06<00:03,  6.26it/s]\u001b[A\r\n",
      " 70%|██████████████████████████████             | 42/60 [00:07<00:02,  6.27it/s]\u001b[A\r\n",
      " 72%|██████████████████████████████▊            | 43/60 [00:07<00:02,  6.13it/s]\u001b[A\r\n",
      " 73%|███████████████████████████████▌           | 44/60 [00:07<00:02,  6.18it/s]\u001b[A\r\n",
      " 75%|████████████████████████████████▎          | 45/60 [00:07<00:02,  5.71it/s]\u001b[A\r\n",
      " 77%|████████████████████████████████▉          | 46/60 [00:07<00:02,  6.13it/s]\u001b[A\r\n",
      " 78%|█████████████████████████████████▋         | 47/60 [00:07<00:01,  6.67it/s]\u001b[A\r\n",
      " 80%|██████████████████████████████████▍        | 48/60 [00:07<00:01,  6.84it/s]\u001b[A\r\n",
      " 82%|███████████████████████████████████        | 49/60 [00:08<00:01,  7.25it/s]\u001b[A\r\n",
      " 83%|███████████████████████████████████▊       | 50/60 [00:08<00:01,  6.73it/s]\u001b[A\r\n",
      " 85%|████████████████████████████████████▌      | 51/60 [00:08<00:01,  6.62it/s]\u001b[A\r\n",
      " 87%|█████████████████████████████████████▎     | 52/60 [00:08<00:01,  6.28it/s]\u001b[A\r\n",
      " 88%|█████████████████████████████████████▉     | 53/60 [00:08<00:01,  6.55it/s]\u001b[A\r\n",
      " 90%|██████████████████████████████████████▋    | 54/60 [00:08<00:00,  6.13it/s]\u001b[A\r\n",
      " 92%|███████████████████████████████████████▍   | 55/60 [00:09<00:00,  6.21it/s]\u001b[A\r\n",
      " 93%|████████████████████████████████████████▏  | 56/60 [00:09<00:00,  6.43it/s]\u001b[A\r\n",
      " 95%|████████████████████████████████████████▊  | 57/60 [00:09<00:00,  6.69it/s]\u001b[A\r\n",
      " 97%|█████████████████████████████████████████▌ | 58/60 [00:09<00:00,  6.27it/s]\u001b[A\r\n",
      " 98%|██████████████████████████████████████████▎| 59/60 [00:09<00:00,  6.05it/s]\u001b[A\r\n",
      "\r\n",
      "\u001b[A{'eval_loss': 0.7495173215866089, 'eval_runtime': 10.042, 'eval_samples_per_second': 5.975, 'eval_steps_per_second': 5.975, 'epoch': 1.47}\r\n",
      " 49%|██████████████████▋                   | 700/1425 [58:17<1:00:07,  4.98s/it]\r\n",
      "100%|███████████████████████████████████████████| 60/60 [00:09<00:00,  6.48it/s]\u001b[A\r\n",
      "                                                                                \u001b[A[INFO|trainer.py:4309] 2026-01-02 19:37:01,729 >> Saving model checkpoint to /kaggle/working/models/qwen2vl-7b-vqa-grounded/checkpoint-700\r\n",
      "[INFO|configuration_utils.py:765] 2026-01-02 19:37:01,873 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2-VL-7B-Instruct/snapshots/eed13092ef92e448dd6875b2a00151bd3f7db0ac/config.json\r\n",
      "[INFO|configuration_utils.py:839] 2026-01-02 19:37:01,875 >> Model config Qwen2VLConfig {\r\n",
      "  \"architectures\": [\r\n",
      "    \"Qwen2VLForConditionalGeneration\"\r\n",
      "  ],\r\n",
      "  \"attention_dropout\": 0.0,\r\n",
      "  \"bos_token_id\": 151643,\r\n",
      "  \"dtype\": \"bfloat16\",\r\n",
      "  \"eos_token_id\": 151645,\r\n",
      "  \"hidden_act\": \"silu\",\r\n",
      "  \"hidden_size\": 3584,\r\n",
      "  \"image_token_id\": 151655,\r\n",
      "  \"initializer_range\": 0.02,\r\n",
      "  \"intermediate_size\": 18944,\r\n",
      "  \"max_position_embeddings\": 32768,\r\n",
      "  \"max_window_layers\": 28,\r\n",
      "  \"model_type\": \"qwen2_vl\",\r\n",
      "  \"num_attention_heads\": 28,\r\n",
      "  \"num_hidden_layers\": 28,\r\n",
      "  \"num_key_value_heads\": 4,\r\n",
      "  \"rms_norm_eps\": 1e-06,\r\n",
      "  \"rope_scaling\": {\r\n",
      "    \"mrope_section\": [\r\n",
      "      16,\r\n",
      "      24,\r\n",
      "      24\r\n",
      "    ],\r\n",
      "    \"rope_type\": \"default\",\r\n",
      "    \"type\": \"default\"\r\n",
      "  },\r\n",
      "  \"rope_theta\": 1000000.0,\r\n",
      "  \"sliding_window\": 32768,\r\n",
      "  \"text_config\": {\r\n",
      "    \"architectures\": [\r\n",
      "      \"Qwen2VLForConditionalGeneration\"\r\n",
      "    ],\r\n",
      "    \"attention_dropout\": 0.0,\r\n",
      "    \"bos_token_id\": 151643,\r\n",
      "    \"dtype\": \"bfloat16\",\r\n",
      "    \"eos_token_id\": 151645,\r\n",
      "    \"hidden_act\": \"silu\",\r\n",
      "    \"hidden_size\": 3584,\r\n",
      "    \"initializer_range\": 0.02,\r\n",
      "    \"intermediate_size\": 18944,\r\n",
      "    \"layer_types\": [\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\"\r\n",
      "    ],\r\n",
      "    \"max_position_embeddings\": 32768,\r\n",
      "    \"max_window_layers\": 28,\r\n",
      "    \"model_type\": \"qwen2_vl_text\",\r\n",
      "    \"num_attention_heads\": 28,\r\n",
      "    \"num_hidden_layers\": 28,\r\n",
      "    \"num_key_value_heads\": 4,\r\n",
      "    \"rms_norm_eps\": 1e-06,\r\n",
      "    \"rope_scaling\": {\r\n",
      "      \"mrope_section\": [\r\n",
      "        16,\r\n",
      "        24,\r\n",
      "        24\r\n",
      "      ],\r\n",
      "      \"rope_type\": \"default\",\r\n",
      "      \"type\": \"default\"\r\n",
      "    },\r\n",
      "    \"rope_theta\": 1000000.0,\r\n",
      "    \"sliding_window\": null,\r\n",
      "    \"use_cache\": true,\r\n",
      "    \"use_sliding_window\": false,\r\n",
      "    \"vision_token_id\": 151654,\r\n",
      "    \"vocab_size\": 152064\r\n",
      "  },\r\n",
      "  \"tie_word_embeddings\": false,\r\n",
      "  \"transformers_version\": \"4.57.1\",\r\n",
      "  \"use_cache\": true,\r\n",
      "  \"use_sliding_window\": false,\r\n",
      "  \"video_token_id\": 151656,\r\n",
      "  \"vision_config\": {\r\n",
      "    \"depth\": 32,\r\n",
      "    \"embed_dim\": 1280,\r\n",
      "    \"hidden_act\": \"quick_gelu\",\r\n",
      "    \"hidden_size\": 3584,\r\n",
      "    \"in_channels\": 3,\r\n",
      "    \"in_chans\": 3,\r\n",
      "    \"initializer_range\": 0.02,\r\n",
      "    \"mlp_ratio\": 4,\r\n",
      "    \"model_type\": \"qwen2_vl\",\r\n",
      "    \"num_heads\": 16,\r\n",
      "    \"patch_size\": 14,\r\n",
      "    \"spatial_merge_size\": 2,\r\n",
      "    \"spatial_patch_size\": 14,\r\n",
      "    \"temporal_patch_size\": 2\r\n",
      "  },\r\n",
      "  \"vision_end_token_id\": 151653,\r\n",
      "  \"vision_start_token_id\": 151652,\r\n",
      "  \"vision_token_id\": 151654,\r\n",
      "  \"vocab_size\": 152064\r\n",
      "}\r\n",
      "\r\n",
      "[INFO|tokenization_utils_base.py:2421] 2026-01-02 19:37:02,511 >> chat template saved in /kaggle/working/models/qwen2vl-7b-vqa-grounded/checkpoint-700/chat_template.jinja\r\n",
      "[INFO|tokenization_utils_base.py:2590] 2026-01-02 19:37:02,511 >> tokenizer config file saved in /kaggle/working/models/qwen2vl-7b-vqa-grounded/checkpoint-700/tokenizer_config.json\r\n",
      "[INFO|tokenization_utils_base.py:2599] 2026-01-02 19:37:02,511 >> Special tokens file saved in /kaggle/working/models/qwen2vl-7b-vqa-grounded/checkpoint-700/special_tokens_map.json\r\n",
      "[INFO|trainer.py:4418] 2026-01-02 19:37:03,655 >> Deleting older checkpoint [/kaggle/working/models/qwen2vl-7b-vqa-grounded/checkpoint-400] due to args.save_total_limit\r\n",
      "[INFO|image_processing_base.py:253] 2026-01-02 19:37:03,818 >> Image processor saved in /kaggle/working/models/qwen2vl-7b-vqa-grounded/checkpoint-700/preprocessor_config.json\r\n",
      "[INFO|tokenization_utils_base.py:2421] 2026-01-02 19:37:03,819 >> chat template saved in /kaggle/working/models/qwen2vl-7b-vqa-grounded/checkpoint-700/chat_template.jinja\r\n",
      "[INFO|tokenization_utils_base.py:2590] 2026-01-02 19:37:03,819 >> tokenizer config file saved in /kaggle/working/models/qwen2vl-7b-vqa-grounded/checkpoint-700/tokenizer_config.json\r\n",
      "[INFO|tokenization_utils_base.py:2599] 2026-01-02 19:37:03,819 >> Special tokens file saved in /kaggle/working/models/qwen2vl-7b-vqa-grounded/checkpoint-700/special_tokens_map.json\r\n",
      "[INFO|video_processing_utils.py:600] 2026-01-02 19:37:03,947 >> Video processor saved in /kaggle/working/models/qwen2vl-7b-vqa-grounded/checkpoint-700/video_preprocessor_config.json\r\n",
      "[INFO|processing_utils.py:814] 2026-01-02 19:37:03,947 >> chat template saved in /kaggle/working/models/qwen2vl-7b-vqa-grounded/checkpoint-700/chat_template.jinja\r\n",
      "{'loss': 0.6422, 'grad_norm': 1.4189801216125488, 'learning_rate': 2.9568938984094206e-05, 'epoch': 1.49}\r\n",
      " 50%|████████████████████▏                   | 717/1425 [59:42<57:16,  4.85s/it]/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\r\n",
      "  warnings.warn(\r\n",
      "{'loss': 0.6665, 'grad_norm': 1.2893352508544922, 'learning_rate': 2.8965310396978013e-05, 'epoch': 1.52}\r\n",
      "{'loss': 0.6412, 'grad_norm': 1.3601624965667725, 'learning_rate': 2.8359300701554074e-05, 'epoch': 1.54}\r\n",
      "{'loss': 0.6766, 'grad_norm': 1.441275954246521, 'learning_rate': 2.7751273797385323e-05, 'epoch': 1.56}\r\n",
      "{'loss': 0.6592, 'grad_norm': 1.334489107131958, 'learning_rate': 2.7141594795337715e-05, 'epoch': 1.58}\r\n",
      "{'loss': 0.6612, 'grad_norm': 1.3201805353164673, 'learning_rate': 2.6530629798336758e-05, 'epoch': 1.6}\r\n",
      "{'loss': 0.6306, 'grad_norm': 1.2013248205184937, 'learning_rate': 2.5918745681528255e-05, 'epoch': 1.62}\r\n",
      "{'loss': 0.6599, 'grad_norm': 1.3843141794204712, 'learning_rate': 2.5306309871975438e-05, 'epoch': 1.64}\r\n",
      "{'loss': 0.6567, 'grad_norm': 1.4258264303207397, 'learning_rate': 2.4693690128024568e-05, 'epoch': 1.66}\r\n",
      "{'loss': 0.6643, 'grad_norm': 1.490308165550232, 'learning_rate': 2.408125431847175e-05, 'epoch': 1.68}\r\n",
      " 56%|█████████████████████▎                | 800/1425 [1:06:28<49:33,  4.76s/it][INFO|trainer.py:4643] 2026-01-02 19:45:12,322 >> \r\n",
      "***** Running Evaluation *****\r\n",
      "[INFO|trainer.py:4645] 2026-01-02 19:45:12,322 >>   Num examples = 60\r\n",
      "[INFO|trainer.py:4648] 2026-01-02 19:45:12,322 >>   Batch size = 1\r\n",
      "\r\n",
      "  0%|                                                    | 0/60 [00:00<?, ?it/s]\u001b[A\r\n",
      "  3%|█▍                                          | 2/60 [00:00<00:05, 11.54it/s]\u001b[A\r\n",
      "  7%|██▉                                         | 4/60 [00:00<00:06,  8.60it/s]\u001b[A\r\n",
      "  8%|███▋                                        | 5/60 [00:00<00:06,  8.58it/s]\u001b[A\r\n",
      " 10%|████▍                                       | 6/60 [00:00<00:06,  7.95it/s]\u001b[A\r\n",
      " 12%|█████▏                                      | 7/60 [00:00<00:06,  8.02it/s]\u001b[A\r\n",
      " 13%|█████▊                                      | 8/60 [00:00<00:06,  7.97it/s]\u001b[A\r\n",
      " 15%|██████▌                                     | 9/60 [00:01<00:07,  6.62it/s]\u001b[A\r\n",
      " 17%|███████▏                                   | 10/60 [00:01<00:07,  6.73it/s]\u001b[A\r\n",
      " 18%|███████▉                                   | 11/60 [00:01<00:06,  7.23it/s]\u001b[A\r\n",
      " 20%|████████▌                                  | 12/60 [00:01<00:06,  7.29it/s]\u001b[A\r\n",
      " 22%|█████████▎                                 | 13/60 [00:01<00:06,  6.99it/s]\u001b[A\r\n",
      " 23%|██████████                                 | 14/60 [00:02<00:12,  3.69it/s]\u001b[A\r\n",
      " 25%|██████████▊                                | 15/60 [00:02<00:10,  4.26it/s]\u001b[A\r\n",
      " 27%|███████████▍                               | 16/60 [00:02<00:09,  4.76it/s]\u001b[A\r\n",
      " 28%|████████████▏                              | 17/60 [00:02<00:08,  5.20it/s]\u001b[A\r\n",
      " 30%|████████████▉                              | 18/60 [00:02<00:07,  5.55it/s]\u001b[A\r\n",
      " 32%|█████████████▌                             | 19/60 [00:03<00:06,  6.18it/s]\u001b[A\r\n",
      " 33%|██████████████▎                            | 20/60 [00:03<00:05,  6.79it/s]\u001b[A\r\n",
      " 35%|███████████████                            | 21/60 [00:03<00:05,  7.10it/s]\u001b[A\r\n",
      " 37%|███████████████▊                           | 22/60 [00:03<00:05,  6.95it/s]\u001b[A\r\n",
      " 38%|████████████████▍                          | 23/60 [00:03<00:05,  6.45it/s]\u001b[A\r\n",
      " 40%|█████████████████▏                         | 24/60 [00:04<00:10,  3.55it/s]\u001b[A\r\n",
      " 42%|█████████████████▉                         | 25/60 [00:04<00:08,  4.05it/s]\u001b[A\r\n",
      " 43%|██████████████████▋                        | 26/60 [00:04<00:07,  4.65it/s]\u001b[A\r\n",
      " 45%|███████████████████▎                       | 27/60 [00:04<00:08,  4.08it/s]\u001b[A\r\n",
      " 47%|████████████████████                       | 28/60 [00:04<00:07,  4.42it/s]\u001b[A\r\n",
      " 48%|████████████████████▊                      | 29/60 [00:05<00:06,  5.03it/s]\u001b[A\r\n",
      " 50%|█████████████████████▌                     | 30/60 [00:05<00:05,  5.91it/s]\u001b[A\r\n",
      " 52%|██████████████████████▏                    | 31/60 [00:05<00:04,  6.64it/s]\u001b[A\r\n",
      " 53%|██████████████████████▉                    | 32/60 [00:05<00:04,  6.64it/s]\u001b[A\r\n",
      " 55%|███████████████████████▋                   | 33/60 [00:05<00:04,  6.17it/s]\u001b[A\r\n",
      " 57%|████████████████████████▎                  | 34/60 [00:05<00:04,  6.38it/s]\u001b[A\r\n",
      " 58%|█████████████████████████                  | 35/60 [00:05<00:03,  6.43it/s]\u001b[A\r\n",
      " 60%|█████████████████████████▊                 | 36/60 [00:06<00:03,  6.65it/s]\u001b[A\r\n",
      " 62%|██████████████████████████▌                | 37/60 [00:06<00:03,  7.20it/s]\u001b[A\r\n",
      " 63%|███████████████████████████▏               | 38/60 [00:06<00:02,  7.41it/s]\u001b[A\r\n",
      " 65%|███████████████████████████▉               | 39/60 [00:06<00:02,  7.21it/s]\u001b[A\r\n",
      " 67%|████████████████████████████▋              | 40/60 [00:06<00:02,  6.75it/s]\u001b[A\r\n",
      " 68%|█████████████████████████████▍             | 41/60 [00:06<00:03,  6.26it/s]\u001b[A\r\n",
      " 70%|██████████████████████████████             | 42/60 [00:06<00:02,  6.29it/s]\u001b[A\r\n",
      " 72%|██████████████████████████████▊            | 43/60 [00:07<00:02,  6.18it/s]\u001b[A\r\n",
      " 73%|███████████████████████████████▌           | 44/60 [00:07<00:02,  6.24it/s]\u001b[A\r\n",
      " 75%|████████████████████████████████▎          | 45/60 [00:07<00:02,  5.77it/s]\u001b[A\r\n",
      " 77%|████████████████████████████████▉          | 46/60 [00:07<00:02,  6.19it/s]\u001b[A\r\n",
      " 78%|█████████████████████████████████▋         | 47/60 [00:07<00:01,  6.76it/s]\u001b[A\r\n",
      " 80%|██████████████████████████████████▍        | 48/60 [00:07<00:01,  6.92it/s]\u001b[A\r\n",
      " 82%|███████████████████████████████████        | 49/60 [00:08<00:01,  7.38it/s]\u001b[A\r\n",
      " 83%|███████████████████████████████████▊       | 50/60 [00:08<00:01,  6.85it/s]\u001b[A\r\n",
      " 85%|████████████████████████████████████▌      | 51/60 [00:08<00:01,  6.74it/s]\u001b[A\r\n",
      " 87%|█████████████████████████████████████▎     | 52/60 [00:08<00:01,  6.39it/s]\u001b[A\r\n",
      " 88%|█████████████████████████████████████▉     | 53/60 [00:08<00:01,  6.65it/s]\u001b[A\r\n",
      " 90%|██████████████████████████████████████▋    | 54/60 [00:08<00:00,  6.26it/s]\u001b[A\r\n",
      " 92%|███████████████████████████████████████▍   | 55/60 [00:08<00:00,  6.33it/s]\u001b[A\r\n",
      " 93%|████████████████████████████████████████▏  | 56/60 [00:09<00:00,  6.52it/s]\u001b[A\r\n",
      " 95%|████████████████████████████████████████▊  | 57/60 [00:09<00:00,  6.77it/s]\u001b[A\r\n",
      " 97%|█████████████████████████████████████████▌ | 58/60 [00:09<00:00,  6.36it/s]\u001b[A\r\n",
      " 98%|██████████████████████████████████████████▎| 59/60 [00:09<00:00,  6.12it/s]\u001b[A\r\n",
      "\r\n",
      "\u001b[A{'eval_loss': 0.7343127727508545, 'eval_runtime': 9.98, 'eval_samples_per_second': 6.012, 'eval_steps_per_second': 6.012, 'epoch': 1.68}\r\n",
      " 56%|█████████████████████▎                | 800/1425 [1:06:38<49:33,  4.76s/it]\r\n",
      "100%|███████████████████████████████████████████| 60/60 [00:09<00:00,  6.54it/s]\u001b[A\r\n",
      "                                                                                \u001b[A[INFO|trainer.py:4309] 2026-01-02 19:45:22,300 >> Saving model checkpoint to /kaggle/working/models/qwen2vl-7b-vqa-grounded/checkpoint-800\r\n",
      "[INFO|configuration_utils.py:765] 2026-01-02 19:45:22,432 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2-VL-7B-Instruct/snapshots/eed13092ef92e448dd6875b2a00151bd3f7db0ac/config.json\r\n",
      "[INFO|configuration_utils.py:839] 2026-01-02 19:45:22,434 >> Model config Qwen2VLConfig {\r\n",
      "  \"architectures\": [\r\n",
      "    \"Qwen2VLForConditionalGeneration\"\r\n",
      "  ],\r\n",
      "  \"attention_dropout\": 0.0,\r\n",
      "  \"bos_token_id\": 151643,\r\n",
      "  \"dtype\": \"bfloat16\",\r\n",
      "  \"eos_token_id\": 151645,\r\n",
      "  \"hidden_act\": \"silu\",\r\n",
      "  \"hidden_size\": 3584,\r\n",
      "  \"image_token_id\": 151655,\r\n",
      "  \"initializer_range\": 0.02,\r\n",
      "  \"intermediate_size\": 18944,\r\n",
      "  \"max_position_embeddings\": 32768,\r\n",
      "  \"max_window_layers\": 28,\r\n",
      "  \"model_type\": \"qwen2_vl\",\r\n",
      "  \"num_attention_heads\": 28,\r\n",
      "  \"num_hidden_layers\": 28,\r\n",
      "  \"num_key_value_heads\": 4,\r\n",
      "  \"rms_norm_eps\": 1e-06,\r\n",
      "  \"rope_scaling\": {\r\n",
      "    \"mrope_section\": [\r\n",
      "      16,\r\n",
      "      24,\r\n",
      "      24\r\n",
      "    ],\r\n",
      "    \"rope_type\": \"default\",\r\n",
      "    \"type\": \"default\"\r\n",
      "  },\r\n",
      "  \"rope_theta\": 1000000.0,\r\n",
      "  \"sliding_window\": 32768,\r\n",
      "  \"text_config\": {\r\n",
      "    \"architectures\": [\r\n",
      "      \"Qwen2VLForConditionalGeneration\"\r\n",
      "    ],\r\n",
      "    \"attention_dropout\": 0.0,\r\n",
      "    \"bos_token_id\": 151643,\r\n",
      "    \"dtype\": \"bfloat16\",\r\n",
      "    \"eos_token_id\": 151645,\r\n",
      "    \"hidden_act\": \"silu\",\r\n",
      "    \"hidden_size\": 3584,\r\n",
      "    \"initializer_range\": 0.02,\r\n",
      "    \"intermediate_size\": 18944,\r\n",
      "    \"layer_types\": [\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\"\r\n",
      "    ],\r\n",
      "    \"max_position_embeddings\": 32768,\r\n",
      "    \"max_window_layers\": 28,\r\n",
      "    \"model_type\": \"qwen2_vl_text\",\r\n",
      "    \"num_attention_heads\": 28,\r\n",
      "    \"num_hidden_layers\": 28,\r\n",
      "    \"num_key_value_heads\": 4,\r\n",
      "    \"rms_norm_eps\": 1e-06,\r\n",
      "    \"rope_scaling\": {\r\n",
      "      \"mrope_section\": [\r\n",
      "        16,\r\n",
      "        24,\r\n",
      "        24\r\n",
      "      ],\r\n",
      "      \"rope_type\": \"default\",\r\n",
      "      \"type\": \"default\"\r\n",
      "    },\r\n",
      "    \"rope_theta\": 1000000.0,\r\n",
      "    \"sliding_window\": null,\r\n",
      "    \"use_cache\": true,\r\n",
      "    \"use_sliding_window\": false,\r\n",
      "    \"vision_token_id\": 151654,\r\n",
      "    \"vocab_size\": 152064\r\n",
      "  },\r\n",
      "  \"tie_word_embeddings\": false,\r\n",
      "  \"transformers_version\": \"4.57.1\",\r\n",
      "  \"use_cache\": true,\r\n",
      "  \"use_sliding_window\": false,\r\n",
      "  \"video_token_id\": 151656,\r\n",
      "  \"vision_config\": {\r\n",
      "    \"depth\": 32,\r\n",
      "    \"embed_dim\": 1280,\r\n",
      "    \"hidden_act\": \"quick_gelu\",\r\n",
      "    \"hidden_size\": 3584,\r\n",
      "    \"in_channels\": 3,\r\n",
      "    \"in_chans\": 3,\r\n",
      "    \"initializer_range\": 0.02,\r\n",
      "    \"mlp_ratio\": 4,\r\n",
      "    \"model_type\": \"qwen2_vl\",\r\n",
      "    \"num_heads\": 16,\r\n",
      "    \"patch_size\": 14,\r\n",
      "    \"spatial_merge_size\": 2,\r\n",
      "    \"spatial_patch_size\": 14,\r\n",
      "    \"temporal_patch_size\": 2\r\n",
      "  },\r\n",
      "  \"vision_end_token_id\": 151653,\r\n",
      "  \"vision_start_token_id\": 151652,\r\n",
      "  \"vision_token_id\": 151654,\r\n",
      "  \"vocab_size\": 152064\r\n",
      "}\r\n",
      "\r\n",
      "[INFO|tokenization_utils_base.py:2421] 2026-01-02 19:45:23,046 >> chat template saved in /kaggle/working/models/qwen2vl-7b-vqa-grounded/checkpoint-800/chat_template.jinja\r\n",
      "[INFO|tokenization_utils_base.py:2590] 2026-01-02 19:45:23,046 >> tokenizer config file saved in /kaggle/working/models/qwen2vl-7b-vqa-grounded/checkpoint-800/tokenizer_config.json\r\n",
      "[INFO|tokenization_utils_base.py:2599] 2026-01-02 19:45:23,046 >> Special tokens file saved in /kaggle/working/models/qwen2vl-7b-vqa-grounded/checkpoint-800/special_tokens_map.json\r\n",
      "[INFO|trainer.py:4418] 2026-01-02 19:45:24,148 >> Deleting older checkpoint [/kaggle/working/models/qwen2vl-7b-vqa-grounded/checkpoint-500] due to args.save_total_limit\r\n",
      "[INFO|image_processing_base.py:253] 2026-01-02 19:45:24,305 >> Image processor saved in /kaggle/working/models/qwen2vl-7b-vqa-grounded/checkpoint-800/preprocessor_config.json\r\n",
      "[INFO|tokenization_utils_base.py:2421] 2026-01-02 19:45:24,305 >> chat template saved in /kaggle/working/models/qwen2vl-7b-vqa-grounded/checkpoint-800/chat_template.jinja\r\n",
      "[INFO|tokenization_utils_base.py:2590] 2026-01-02 19:45:24,306 >> tokenizer config file saved in /kaggle/working/models/qwen2vl-7b-vqa-grounded/checkpoint-800/tokenizer_config.json\r\n",
      "[INFO|tokenization_utils_base.py:2599] 2026-01-02 19:45:24,306 >> Special tokens file saved in /kaggle/working/models/qwen2vl-7b-vqa-grounded/checkpoint-800/special_tokens_map.json\r\n",
      "[INFO|video_processing_utils.py:600] 2026-01-02 19:45:24,430 >> Video processor saved in /kaggle/working/models/qwen2vl-7b-vqa-grounded/checkpoint-800/video_preprocessor_config.json\r\n",
      "[INFO|processing_utils.py:814] 2026-01-02 19:45:24,430 >> chat template saved in /kaggle/working/models/qwen2vl-7b-vqa-grounded/checkpoint-800/chat_template.jinja\r\n",
      "{'loss': 0.623, 'grad_norm': 1.3406466245651245, 'learning_rate': 2.3469370201663245e-05, 'epoch': 1.71}\r\n",
      " 57%|█████████████████████▋                | 813/1425 [1:07:44<50:07,  4.91s/it]/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\r\n",
      "  warnings.warn(\r\n",
      "{'loss': 0.6712, 'grad_norm': 1.4060238599777222, 'learning_rate': 2.2858405204662288e-05, 'epoch': 1.73}\r\n",
      "{'loss': 0.6425, 'grad_norm': 1.3110657930374146, 'learning_rate': 2.2248726202614683e-05, 'epoch': 1.75}\r\n",
      "{'loss': 0.6375, 'grad_norm': 1.3339799642562866, 'learning_rate': 2.1640699298445925e-05, 'epoch': 1.77}\r\n",
      "{'loss': 0.6615, 'grad_norm': 1.336397647857666, 'learning_rate': 2.1034689603021993e-05, 'epoch': 1.79}\r\n",
      "{'loss': 0.6675, 'grad_norm': 1.4242106676101685, 'learning_rate': 2.0431061015905796e-05, 'epoch': 1.81}\r\n",
      "{'loss': 0.6286, 'grad_norm': 1.327092170715332, 'learning_rate': 1.983017600684113e-05, 'epoch': 1.83}\r\n",
      "{'loss': 0.6438, 'grad_norm': 1.3007304668426514, 'learning_rate': 1.9232395398095052e-05, 'epoch': 1.85}\r\n",
      "{'loss': 0.6384, 'grad_norm': 1.3078385591506958, 'learning_rate': 1.863807814778968e-05, 'epoch': 1.87}\r\n",
      "{'loss': 0.6341, 'grad_norm': 1.396060585975647, 'learning_rate': 1.8047581134353298e-05, 'epoch': 1.89}\r\n",
      " 63%|████████████████████████              | 900/1425 [1:14:48<42:23,  4.84s/it][INFO|trainer.py:4643] 2026-01-02 19:53:32,411 >> \r\n",
      "***** Running Evaluation *****\r\n",
      "[INFO|trainer.py:4645] 2026-01-02 19:53:32,411 >>   Num examples = 60\r\n",
      "[INFO|trainer.py:4648] 2026-01-02 19:53:32,411 >>   Batch size = 1\r\n",
      "\r\n",
      "  0%|                                                    | 0/60 [00:00<?, ?it/s]\u001b[A\r\n",
      "  3%|█▍                                          | 2/60 [00:00<00:04, 11.85it/s]\u001b[A\r\n",
      "  7%|██▉                                         | 4/60 [00:00<00:06,  8.72it/s]\u001b[A\r\n",
      "  8%|███▋                                        | 5/60 [00:00<00:06,  8.72it/s]\u001b[A\r\n",
      " 10%|████▍                                       | 6/60 [00:00<00:06,  8.03it/s]\u001b[A\r\n",
      " 12%|█████▏                                      | 7/60 [00:00<00:06,  8.08it/s]\u001b[A\r\n",
      " 13%|█████▊                                      | 8/60 [00:00<00:06,  8.17it/s]\u001b[A\r\n",
      " 15%|██████▌                                     | 9/60 [00:01<00:07,  6.76it/s]\u001b[A\r\n",
      " 17%|███████▏                                   | 10/60 [00:01<00:07,  6.84it/s]\u001b[A\r\n",
      " 18%|███████▉                                   | 11/60 [00:01<00:06,  7.33it/s]\u001b[A\r\n",
      " 20%|████████▌                                  | 12/60 [00:01<00:06,  7.35it/s]\u001b[A\r\n",
      " 22%|█████████▎                                 | 13/60 [00:01<00:06,  7.03it/s]\u001b[A\r\n",
      " 23%|██████████                                 | 14/60 [00:02<00:12,  3.73it/s]\u001b[A\r\n",
      " 25%|██████████▊                                | 15/60 [00:02<00:10,  4.29it/s]\u001b[A\r\n",
      " 27%|███████████▍                               | 16/60 [00:02<00:09,  4.78it/s]\u001b[A\r\n",
      " 28%|████████████▏                              | 17/60 [00:02<00:08,  5.22it/s]\u001b[A\r\n",
      " 30%|████████████▉                              | 18/60 [00:02<00:07,  5.56it/s]\u001b[A\r\n",
      " 32%|█████████████▌                             | 19/60 [00:02<00:06,  6.21it/s]\u001b[A\r\n",
      " 33%|██████████████▎                            | 20/60 [00:03<00:05,  6.81it/s]\u001b[A\r\n",
      " 35%|███████████████                            | 21/60 [00:03<00:05,  7.12it/s]\u001b[A\r\n",
      " 37%|███████████████▊                           | 22/60 [00:03<00:05,  6.94it/s]\u001b[A\r\n",
      " 38%|████████████████▍                          | 23/60 [00:03<00:05,  6.49it/s]\u001b[A\r\n",
      " 40%|█████████████████▏                         | 24/60 [00:04<00:10,  3.54it/s]\u001b[A\r\n",
      " 42%|█████████████████▉                         | 25/60 [00:04<00:08,  4.04it/s]\u001b[A\r\n",
      " 43%|██████████████████▋                        | 26/60 [00:04<00:07,  4.64it/s]\u001b[A\r\n",
      " 45%|███████████████████▎                       | 27/60 [00:04<00:08,  4.06it/s]\u001b[A\r\n",
      " 47%|████████████████████                       | 28/60 [00:04<00:07,  4.40it/s]\u001b[A\r\n",
      " 48%|████████████████████▊                      | 29/60 [00:05<00:06,  5.01it/s]\u001b[A\r\n",
      " 50%|█████████████████████▌                     | 30/60 [00:05<00:05,  5.89it/s]\u001b[A\r\n",
      " 52%|██████████████████████▏                    | 31/60 [00:05<00:04,  6.62it/s]\u001b[A\r\n",
      " 53%|██████████████████████▉                    | 32/60 [00:05<00:04,  6.66it/s]\u001b[A\r\n",
      " 55%|███████████████████████▋                   | 33/60 [00:05<00:04,  6.19it/s]\u001b[A\r\n",
      " 57%|████████████████████████▎                  | 34/60 [00:05<00:04,  6.39it/s]\u001b[A\r\n",
      " 58%|█████████████████████████                  | 35/60 [00:05<00:03,  6.45it/s]\u001b[A\r\n",
      " 60%|█████████████████████████▊                 | 36/60 [00:06<00:03,  6.66it/s]\u001b[A\r\n",
      " 62%|██████████████████████████▌                | 37/60 [00:06<00:03,  7.21it/s]\u001b[A\r\n",
      " 63%|███████████████████████████▏               | 38/60 [00:06<00:02,  7.42it/s]\u001b[A\r\n",
      " 65%|███████████████████████████▉               | 39/60 [00:06<00:02,  7.27it/s]\u001b[A\r\n",
      " 67%|████████████████████████████▋              | 40/60 [00:06<00:02,  6.81it/s]\u001b[A\r\n",
      " 68%|█████████████████████████████▍             | 41/60 [00:06<00:03,  6.31it/s]\u001b[A\r\n",
      " 70%|██████████████████████████████             | 42/60 [00:06<00:02,  6.32it/s]\u001b[A\r\n",
      " 72%|██████████████████████████████▊            | 43/60 [00:07<00:02,  6.20it/s]\u001b[A\r\n",
      " 73%|███████████████████████████████▌           | 44/60 [00:07<00:02,  6.25it/s]\u001b[A\r\n",
      " 75%|████████████████████████████████▎          | 45/60 [00:07<00:02,  5.79it/s]\u001b[A\r\n",
      " 77%|████████████████████████████████▉          | 46/60 [00:07<00:02,  6.18it/s]\u001b[A\r\n",
      " 78%|█████████████████████████████████▋         | 47/60 [00:07<00:01,  6.70it/s]\u001b[A\r\n",
      " 80%|██████████████████████████████████▍        | 48/60 [00:07<00:01,  6.86it/s]\u001b[A\r\n",
      " 82%|███████████████████████████████████        | 49/60 [00:07<00:01,  7.30it/s]\u001b[A\r\n",
      " 83%|███████████████████████████████████▊       | 50/60 [00:08<00:01,  6.76it/s]\u001b[A\r\n",
      " 85%|████████████████████████████████████▌      | 51/60 [00:08<00:01,  6.66it/s]\u001b[A\r\n",
      " 87%|█████████████████████████████████████▎     | 52/60 [00:08<00:01,  6.31it/s]\u001b[A\r\n",
      " 88%|█████████████████████████████████████▉     | 53/60 [00:08<00:01,  6.57it/s]\u001b[A\r\n",
      " 90%|██████████████████████████████████████▋    | 54/60 [00:08<00:00,  6.17it/s]\u001b[A\r\n",
      " 92%|███████████████████████████████████████▍   | 55/60 [00:08<00:00,  6.25it/s]\u001b[A\r\n",
      " 93%|████████████████████████████████████████▏  | 56/60 [00:09<00:00,  6.45it/s]\u001b[A\r\n",
      " 95%|████████████████████████████████████████▊  | 57/60 [00:09<00:00,  6.69it/s]\u001b[A\r\n",
      " 97%|█████████████████████████████████████████▌ | 58/60 [00:09<00:00,  6.28it/s]\u001b[A\r\n",
      " 98%|██████████████████████████████████████████▎| 59/60 [00:09<00:00,  6.04it/s]\u001b[A\r\n",
      "100%|███████████████████████████████████████████| 60/60 [00:09<00:00,  6.47it/s]\u001b[A\r\n",
      "{'eval_loss': 0.7160892486572266, 'eval_runtime': 9.9749, 'eval_samples_per_second': 6.015, 'eval_steps_per_second': 6.015, 'epoch': 1.89}\r\n",
      "\r\n",
      " 63%|████████████████████████              | 900/1425 [1:14:58<42:23,  4.84s/it]\r\n",
      "                                                                                \u001b[A[INFO|trainer.py:4309] 2026-01-02 19:53:42,384 >> Saving model checkpoint to /kaggle/working/models/qwen2vl-7b-vqa-grounded/checkpoint-900\r\n",
      "[INFO|configuration_utils.py:765] 2026-01-02 19:53:42,509 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2-VL-7B-Instruct/snapshots/eed13092ef92e448dd6875b2a00151bd3f7db0ac/config.json\r\n",
      "[INFO|configuration_utils.py:839] 2026-01-02 19:53:42,511 >> Model config Qwen2VLConfig {\r\n",
      "  \"architectures\": [\r\n",
      "    \"Qwen2VLForConditionalGeneration\"\r\n",
      "  ],\r\n",
      "  \"attention_dropout\": 0.0,\r\n",
      "  \"bos_token_id\": 151643,\r\n",
      "  \"dtype\": \"bfloat16\",\r\n",
      "  \"eos_token_id\": 151645,\r\n",
      "  \"hidden_act\": \"silu\",\r\n",
      "  \"hidden_size\": 3584,\r\n",
      "  \"image_token_id\": 151655,\r\n",
      "  \"initializer_range\": 0.02,\r\n",
      "  \"intermediate_size\": 18944,\r\n",
      "  \"max_position_embeddings\": 32768,\r\n",
      "  \"max_window_layers\": 28,\r\n",
      "  \"model_type\": \"qwen2_vl\",\r\n",
      "  \"num_attention_heads\": 28,\r\n",
      "  \"num_hidden_layers\": 28,\r\n",
      "  \"num_key_value_heads\": 4,\r\n",
      "  \"rms_norm_eps\": 1e-06,\r\n",
      "  \"rope_scaling\": {\r\n",
      "    \"mrope_section\": [\r\n",
      "      16,\r\n",
      "      24,\r\n",
      "      24\r\n",
      "    ],\r\n",
      "    \"rope_type\": \"default\",\r\n",
      "    \"type\": \"default\"\r\n",
      "  },\r\n",
      "  \"rope_theta\": 1000000.0,\r\n",
      "  \"sliding_window\": 32768,\r\n",
      "  \"text_config\": {\r\n",
      "    \"architectures\": [\r\n",
      "      \"Qwen2VLForConditionalGeneration\"\r\n",
      "    ],\r\n",
      "    \"attention_dropout\": 0.0,\r\n",
      "    \"bos_token_id\": 151643,\r\n",
      "    \"dtype\": \"bfloat16\",\r\n",
      "    \"eos_token_id\": 151645,\r\n",
      "    \"hidden_act\": \"silu\",\r\n",
      "    \"hidden_size\": 3584,\r\n",
      "    \"initializer_range\": 0.02,\r\n",
      "    \"intermediate_size\": 18944,\r\n",
      "    \"layer_types\": [\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\"\r\n",
      "    ],\r\n",
      "    \"max_position_embeddings\": 32768,\r\n",
      "    \"max_window_layers\": 28,\r\n",
      "    \"model_type\": \"qwen2_vl_text\",\r\n",
      "    \"num_attention_heads\": 28,\r\n",
      "    \"num_hidden_layers\": 28,\r\n",
      "    \"num_key_value_heads\": 4,\r\n",
      "    \"rms_norm_eps\": 1e-06,\r\n",
      "    \"rope_scaling\": {\r\n",
      "      \"mrope_section\": [\r\n",
      "        16,\r\n",
      "        24,\r\n",
      "        24\r\n",
      "      ],\r\n",
      "      \"rope_type\": \"default\",\r\n",
      "      \"type\": \"default\"\r\n",
      "    },\r\n",
      "    \"rope_theta\": 1000000.0,\r\n",
      "    \"sliding_window\": null,\r\n",
      "    \"use_cache\": true,\r\n",
      "    \"use_sliding_window\": false,\r\n",
      "    \"vision_token_id\": 151654,\r\n",
      "    \"vocab_size\": 152064\r\n",
      "  },\r\n",
      "  \"tie_word_embeddings\": false,\r\n",
      "  \"transformers_version\": \"4.57.1\",\r\n",
      "  \"use_cache\": true,\r\n",
      "  \"use_sliding_window\": false,\r\n",
      "  \"video_token_id\": 151656,\r\n",
      "  \"vision_config\": {\r\n",
      "    \"depth\": 32,\r\n",
      "    \"embed_dim\": 1280,\r\n",
      "    \"hidden_act\": \"quick_gelu\",\r\n",
      "    \"hidden_size\": 3584,\r\n",
      "    \"in_channels\": 3,\r\n",
      "    \"in_chans\": 3,\r\n",
      "    \"initializer_range\": 0.02,\r\n",
      "    \"mlp_ratio\": 4,\r\n",
      "    \"model_type\": \"qwen2_vl\",\r\n",
      "    \"num_heads\": 16,\r\n",
      "    \"patch_size\": 14,\r\n",
      "    \"spatial_merge_size\": 2,\r\n",
      "    \"spatial_patch_size\": 14,\r\n",
      "    \"temporal_patch_size\": 2\r\n",
      "  },\r\n",
      "  \"vision_end_token_id\": 151653,\r\n",
      "  \"vision_start_token_id\": 151652,\r\n",
      "  \"vision_token_id\": 151654,\r\n",
      "  \"vocab_size\": 152064\r\n",
      "}\r\n",
      "\r\n",
      "[INFO|tokenization_utils_base.py:2421] 2026-01-02 19:53:43,135 >> chat template saved in /kaggle/working/models/qwen2vl-7b-vqa-grounded/checkpoint-900/chat_template.jinja\r\n",
      "[INFO|tokenization_utils_base.py:2590] 2026-01-02 19:53:43,136 >> tokenizer config file saved in /kaggle/working/models/qwen2vl-7b-vqa-grounded/checkpoint-900/tokenizer_config.json\r\n",
      "[INFO|tokenization_utils_base.py:2599] 2026-01-02 19:53:43,136 >> Special tokens file saved in /kaggle/working/models/qwen2vl-7b-vqa-grounded/checkpoint-900/special_tokens_map.json\r\n",
      "[INFO|trainer.py:4418] 2026-01-02 19:53:44,265 >> Deleting older checkpoint [/kaggle/working/models/qwen2vl-7b-vqa-grounded/checkpoint-600] due to args.save_total_limit\r\n",
      "[INFO|image_processing_base.py:253] 2026-01-02 19:53:44,424 >> Image processor saved in /kaggle/working/models/qwen2vl-7b-vqa-grounded/checkpoint-900/preprocessor_config.json\r\n",
      "[INFO|tokenization_utils_base.py:2421] 2026-01-02 19:53:44,424 >> chat template saved in /kaggle/working/models/qwen2vl-7b-vqa-grounded/checkpoint-900/chat_template.jinja\r\n",
      "[INFO|tokenization_utils_base.py:2590] 2026-01-02 19:53:44,425 >> tokenizer config file saved in /kaggle/working/models/qwen2vl-7b-vqa-grounded/checkpoint-900/tokenizer_config.json\r\n",
      "[INFO|tokenization_utils_base.py:2599] 2026-01-02 19:53:44,425 >> Special tokens file saved in /kaggle/working/models/qwen2vl-7b-vqa-grounded/checkpoint-900/special_tokens_map.json\r\n",
      "[INFO|video_processing_utils.py:600] 2026-01-02 19:53:44,547 >> Video processor saved in /kaggle/working/models/qwen2vl-7b-vqa-grounded/checkpoint-900/video_preprocessor_config.json\r\n",
      "[INFO|processing_utils.py:814] 2026-01-02 19:53:44,547 >> chat template saved in /kaggle/working/models/qwen2vl-7b-vqa-grounded/checkpoint-900/chat_template.jinja\r\n",
      "/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\r\n",
      "  warnings.warn(\r\n",
      "{'loss': 0.6474, 'grad_norm': 1.2882754802703857, 'learning_rate': 1.746125894222032e-05, 'epoch': 1.92}\r\n",
      "{'loss': 0.6537, 'grad_norm': 1.2998812198638916, 'learning_rate': 1.687946364890877e-05, 'epoch': 1.94}\r\n",
      "{'loss': 0.6298, 'grad_norm': 1.401197910308838, 'learning_rate': 1.630254461360306e-05, 'epoch': 1.96}\r\n",
      "{'loss': 0.6126, 'grad_norm': 1.3569424152374268, 'learning_rate': 1.5730848267369212e-05, 'epoch': 1.98}\r\n",
      "{'loss': 0.6487, 'grad_norm': 1.5037747621536255, 'learning_rate': 1.5164717905128225e-05, 'epoch': 2.0}\r\n",
      "{'loss': 0.5315, 'grad_norm': 1.2297354936599731, 'learning_rate': 1.4604493479512781e-05, 'epoch': 2.02}\r\n",
      "{'loss': 0.4996, 'grad_norm': 1.4007173776626587, 'learning_rate': 1.4050511396730826e-05, 'epoch': 2.04}\r\n",
      "{'loss': 0.5107, 'grad_norm': 1.4439525604248047, 'learning_rate': 1.350310431455884e-05, 'epoch': 2.06}\r\n",
      "{'loss': 0.5119, 'grad_norm': 1.5044760704040527, 'learning_rate': 1.2962600942585867e-05, 'epoch': 2.08}\r\n",
      "{'loss': 0.5115, 'grad_norm': 1.4500163793563843, 'learning_rate': 1.2429325844828476e-05, 'epoch': 2.11}\r\n",
      " 70%|█████████████████████████▉           | 1000/1425 [1:23:05<35:07,  4.96s/it][INFO|trainer.py:4643] 2026-01-02 20:01:49,890 >> \r\n",
      "***** Running Evaluation *****\r\n",
      "[INFO|trainer.py:4645] 2026-01-02 20:01:49,890 >>   Num examples = 60\r\n",
      "[INFO|trainer.py:4648] 2026-01-02 20:01:49,890 >>   Batch size = 1\r\n",
      "\r\n",
      "  0%|                                                    | 0/60 [00:00<?, ?it/s]\u001b[A\r\n",
      "  3%|█▍                                          | 2/60 [00:00<00:04, 11.84it/s]\u001b[A\r\n",
      "  7%|██▉                                         | 4/60 [00:00<00:06,  8.71it/s]\u001b[A\r\n",
      "  8%|███▋                                        | 5/60 [00:00<00:06,  8.75it/s]\u001b[A\r\n",
      " 10%|████▍                                       | 6/60 [00:00<00:06,  8.00it/s]\u001b[A\r\n",
      " 12%|█████▏                                      | 7/60 [00:00<00:06,  8.08it/s]\u001b[A\r\n",
      " 13%|█████▊                                      | 8/60 [00:00<00:06,  8.19it/s]\u001b[A\r\n",
      " 15%|██████▌                                     | 9/60 [00:01<00:07,  6.76it/s]\u001b[A\r\n",
      " 17%|███████▏                                   | 10/60 [00:01<00:07,  6.86it/s]\u001b[A\r\n",
      " 18%|███████▉                                   | 11/60 [00:01<00:06,  7.36it/s]\u001b[A\r\n",
      " 20%|████████▌                                  | 12/60 [00:01<00:06,  7.39it/s]\u001b[A\r\n",
      " 22%|█████████▎                                 | 13/60 [00:01<00:06,  7.04it/s]\u001b[A\r\n",
      " 23%|██████████                                 | 14/60 [00:02<00:12,  3.71it/s]\u001b[A\r\n",
      " 25%|██████████▊                                | 15/60 [00:02<00:10,  4.28it/s]\u001b[A\r\n",
      " 27%|███████████▍                               | 16/60 [00:02<00:09,  4.78it/s]\u001b[A\r\n",
      " 28%|████████████▏                              | 17/60 [00:02<00:08,  5.23it/s]\u001b[A\r\n",
      " 30%|████████████▉                              | 18/60 [00:02<00:07,  5.59it/s]\u001b[A\r\n",
      " 32%|█████████████▌                             | 19/60 [00:02<00:06,  6.23it/s]\u001b[A\r\n",
      " 33%|██████████████▎                            | 20/60 [00:03<00:05,  6.84it/s]\u001b[A\r\n",
      " 35%|███████████████                            | 21/60 [00:03<00:05,  7.14it/s]\u001b[A\r\n",
      " 37%|███████████████▊                           | 22/60 [00:03<00:05,  6.94it/s]\u001b[A\r\n",
      " 38%|████████████████▍                          | 23/60 [00:03<00:05,  6.49it/s]\u001b[A\r\n",
      " 40%|█████████████████▏                         | 24/60 [00:04<00:10,  3.56it/s]\u001b[A\r\n",
      " 42%|█████████████████▉                         | 25/60 [00:04<00:08,  4.07it/s]\u001b[A\r\n",
      " 43%|██████████████████▋                        | 26/60 [00:04<00:07,  4.68it/s]\u001b[A\r\n",
      " 45%|███████████████████▎                       | 27/60 [00:04<00:08,  4.11it/s]\u001b[A\r\n",
      " 47%|████████████████████                       | 28/60 [00:04<00:07,  4.46it/s]\u001b[A\r\n",
      " 48%|████████████████████▊                      | 29/60 [00:05<00:06,  5.06it/s]\u001b[A\r\n",
      " 52%|██████████████████████▏                    | 31/60 [00:05<00:04,  6.51it/s]\u001b[A\r\n",
      " 53%|██████████████████████▉                    | 32/60 [00:05<00:04,  6.54it/s]\u001b[A\r\n",
      " 55%|███████████████████████▋                   | 33/60 [00:05<00:04,  6.16it/s]\u001b[A\r\n",
      " 57%|████████████████████████▎                  | 34/60 [00:05<00:04,  6.36it/s]\u001b[A\r\n",
      " 58%|█████████████████████████                  | 35/60 [00:05<00:03,  6.44it/s]\u001b[A\r\n",
      " 60%|█████████████████████████▊                 | 36/60 [00:06<00:03,  6.64it/s]\u001b[A\r\n",
      " 62%|██████████████████████████▌                | 37/60 [00:06<00:03,  7.17it/s]\u001b[A\r\n",
      " 63%|███████████████████████████▏               | 38/60 [00:06<00:02,  7.39it/s]\u001b[A\r\n",
      " 65%|███████████████████████████▉               | 39/60 [00:06<00:02,  7.29it/s]\u001b[A\r\n",
      " 67%|████████████████████████████▋              | 40/60 [00:06<00:02,  6.85it/s]\u001b[A\r\n",
      " 68%|█████████████████████████████▍             | 41/60 [00:06<00:02,  6.35it/s]\u001b[A\r\n",
      " 70%|██████████████████████████████             | 42/60 [00:06<00:02,  6.26it/s]\u001b[A\r\n",
      " 72%|██████████████████████████████▊            | 43/60 [00:07<00:02,  6.19it/s]\u001b[A\r\n",
      " 73%|███████████████████████████████▌           | 44/60 [00:07<00:02,  6.26it/s]\u001b[A\r\n",
      " 75%|████████████████████████████████▎          | 45/60 [00:07<00:02,  5.81it/s]\u001b[A\r\n",
      " 77%|████████████████████████████████▉          | 46/60 [00:07<00:02,  6.20it/s]\u001b[A\r\n",
      " 78%|█████████████████████████████████▋         | 47/60 [00:07<00:01,  6.76it/s]\u001b[A\r\n",
      " 80%|██████████████████████████████████▍        | 48/60 [00:07<00:01,  6.91it/s]\u001b[A\r\n",
      " 82%|███████████████████████████████████        | 49/60 [00:07<00:01,  7.35it/s]\u001b[A\r\n",
      " 83%|███████████████████████████████████▊       | 50/60 [00:08<00:01,  6.83it/s]\u001b[A\r\n",
      " 85%|████████████████████████████████████▌      | 51/60 [00:08<00:01,  6.72it/s]\u001b[A\r\n",
      " 87%|█████████████████████████████████████▎     | 52/60 [00:08<00:01,  6.38it/s]\u001b[A\r\n",
      " 88%|█████████████████████████████████████▉     | 53/60 [00:08<00:01,  6.63it/s]\u001b[A\r\n",
      " 90%|██████████████████████████████████████▋    | 54/60 [00:08<00:00,  6.22it/s]\u001b[A\r\n",
      " 92%|███████████████████████████████████████▍   | 55/60 [00:08<00:00,  6.29it/s]\u001b[A\r\n",
      " 93%|████████████████████████████████████████▏  | 56/60 [00:09<00:00,  6.50it/s]\u001b[A\r\n",
      " 95%|████████████████████████████████████████▊  | 57/60 [00:09<00:00,  6.76it/s]\u001b[A\r\n",
      " 97%|█████████████████████████████████████████▌ | 58/60 [00:09<00:00,  6.35it/s]\u001b[A\r\n",
      " 98%|██████████████████████████████████████████▎| 59/60 [00:09<00:00,  6.14it/s]\u001b[A\r\n",
      "\r\n",
      "\u001b[A{'eval_loss': 0.733927309513092, 'eval_runtime': 9.9255, 'eval_samples_per_second': 6.045, 'eval_steps_per_second': 6.045, 'epoch': 2.11}\r\n",
      " 70%|█████████████████████████▉           | 1000/1425 [1:23:15<35:07,  4.96s/it]\r\n",
      "100%|███████████████████████████████████████████| 60/60 [00:09<00:00,  6.55it/s]\u001b[A\r\n",
      "                                                                                \u001b[A[INFO|trainer.py:4309] 2026-01-02 20:01:59,814 >> Saving model checkpoint to /kaggle/working/models/qwen2vl-7b-vqa-grounded/checkpoint-1000\r\n",
      "[INFO|configuration_utils.py:765] 2026-01-02 20:01:59,962 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2-VL-7B-Instruct/snapshots/eed13092ef92e448dd6875b2a00151bd3f7db0ac/config.json\r\n",
      "[INFO|configuration_utils.py:839] 2026-01-02 20:01:59,963 >> Model config Qwen2VLConfig {\r\n",
      "  \"architectures\": [\r\n",
      "    \"Qwen2VLForConditionalGeneration\"\r\n",
      "  ],\r\n",
      "  \"attention_dropout\": 0.0,\r\n",
      "  \"bos_token_id\": 151643,\r\n",
      "  \"dtype\": \"bfloat16\",\r\n",
      "  \"eos_token_id\": 151645,\r\n",
      "  \"hidden_act\": \"silu\",\r\n",
      "  \"hidden_size\": 3584,\r\n",
      "  \"image_token_id\": 151655,\r\n",
      "  \"initializer_range\": 0.02,\r\n",
      "  \"intermediate_size\": 18944,\r\n",
      "  \"max_position_embeddings\": 32768,\r\n",
      "  \"max_window_layers\": 28,\r\n",
      "  \"model_type\": \"qwen2_vl\",\r\n",
      "  \"num_attention_heads\": 28,\r\n",
      "  \"num_hidden_layers\": 28,\r\n",
      "  \"num_key_value_heads\": 4,\r\n",
      "  \"rms_norm_eps\": 1e-06,\r\n",
      "  \"rope_scaling\": {\r\n",
      "    \"mrope_section\": [\r\n",
      "      16,\r\n",
      "      24,\r\n",
      "      24\r\n",
      "    ],\r\n",
      "    \"rope_type\": \"default\",\r\n",
      "    \"type\": \"default\"\r\n",
      "  },\r\n",
      "  \"rope_theta\": 1000000.0,\r\n",
      "  \"sliding_window\": 32768,\r\n",
      "  \"text_config\": {\r\n",
      "    \"architectures\": [\r\n",
      "      \"Qwen2VLForConditionalGeneration\"\r\n",
      "    ],\r\n",
      "    \"attention_dropout\": 0.0,\r\n",
      "    \"bos_token_id\": 151643,\r\n",
      "    \"dtype\": \"bfloat16\",\r\n",
      "    \"eos_token_id\": 151645,\r\n",
      "    \"hidden_act\": \"silu\",\r\n",
      "    \"hidden_size\": 3584,\r\n",
      "    \"initializer_range\": 0.02,\r\n",
      "    \"intermediate_size\": 18944,\r\n",
      "    \"layer_types\": [\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\"\r\n",
      "    ],\r\n",
      "    \"max_position_embeddings\": 32768,\r\n",
      "    \"max_window_layers\": 28,\r\n",
      "    \"model_type\": \"qwen2_vl_text\",\r\n",
      "    \"num_attention_heads\": 28,\r\n",
      "    \"num_hidden_layers\": 28,\r\n",
      "    \"num_key_value_heads\": 4,\r\n",
      "    \"rms_norm_eps\": 1e-06,\r\n",
      "    \"rope_scaling\": {\r\n",
      "      \"mrope_section\": [\r\n",
      "        16,\r\n",
      "        24,\r\n",
      "        24\r\n",
      "      ],\r\n",
      "      \"rope_type\": \"default\",\r\n",
      "      \"type\": \"default\"\r\n",
      "    },\r\n",
      "    \"rope_theta\": 1000000.0,\r\n",
      "    \"sliding_window\": null,\r\n",
      "    \"use_cache\": true,\r\n",
      "    \"use_sliding_window\": false,\r\n",
      "    \"vision_token_id\": 151654,\r\n",
      "    \"vocab_size\": 152064\r\n",
      "  },\r\n",
      "  \"tie_word_embeddings\": false,\r\n",
      "  \"transformers_version\": \"4.57.1\",\r\n",
      "  \"use_cache\": true,\r\n",
      "  \"use_sliding_window\": false,\r\n",
      "  \"video_token_id\": 151656,\r\n",
      "  \"vision_config\": {\r\n",
      "    \"depth\": 32,\r\n",
      "    \"embed_dim\": 1280,\r\n",
      "    \"hidden_act\": \"quick_gelu\",\r\n",
      "    \"hidden_size\": 3584,\r\n",
      "    \"in_channels\": 3,\r\n",
      "    \"in_chans\": 3,\r\n",
      "    \"initializer_range\": 0.02,\r\n",
      "    \"mlp_ratio\": 4,\r\n",
      "    \"model_type\": \"qwen2_vl\",\r\n",
      "    \"num_heads\": 16,\r\n",
      "    \"patch_size\": 14,\r\n",
      "    \"spatial_merge_size\": 2,\r\n",
      "    \"spatial_patch_size\": 14,\r\n",
      "    \"temporal_patch_size\": 2\r\n",
      "  },\r\n",
      "  \"vision_end_token_id\": 151653,\r\n",
      "  \"vision_start_token_id\": 151652,\r\n",
      "  \"vision_token_id\": 151654,\r\n",
      "  \"vocab_size\": 152064\r\n",
      "}\r\n",
      "\r\n",
      "[INFO|tokenization_utils_base.py:2421] 2026-01-02 20:02:00,580 >> chat template saved in /kaggle/working/models/qwen2vl-7b-vqa-grounded/checkpoint-1000/chat_template.jinja\r\n",
      "[INFO|tokenization_utils_base.py:2590] 2026-01-02 20:02:00,581 >> tokenizer config file saved in /kaggle/working/models/qwen2vl-7b-vqa-grounded/checkpoint-1000/tokenizer_config.json\r\n",
      "[INFO|tokenization_utils_base.py:2599] 2026-01-02 20:02:00,581 >> Special tokens file saved in /kaggle/working/models/qwen2vl-7b-vqa-grounded/checkpoint-1000/special_tokens_map.json\r\n",
      "[INFO|trainer.py:4418] 2026-01-02 20:02:01,676 >> Deleting older checkpoint [/kaggle/working/models/qwen2vl-7b-vqa-grounded/checkpoint-700] due to args.save_total_limit\r\n",
      "[INFO|image_processing_base.py:253] 2026-01-02 20:02:01,828 >> Image processor saved in /kaggle/working/models/qwen2vl-7b-vqa-grounded/checkpoint-1000/preprocessor_config.json\r\n",
      "[INFO|tokenization_utils_base.py:2421] 2026-01-02 20:02:01,829 >> chat template saved in /kaggle/working/models/qwen2vl-7b-vqa-grounded/checkpoint-1000/chat_template.jinja\r\n",
      "[INFO|tokenization_utils_base.py:2590] 2026-01-02 20:02:01,829 >> tokenizer config file saved in /kaggle/working/models/qwen2vl-7b-vqa-grounded/checkpoint-1000/tokenizer_config.json\r\n",
      "[INFO|tokenization_utils_base.py:2599] 2026-01-02 20:02:01,829 >> Special tokens file saved in /kaggle/working/models/qwen2vl-7b-vqa-grounded/checkpoint-1000/special_tokens_map.json\r\n",
      "[INFO|video_processing_utils.py:600] 2026-01-02 20:02:01,954 >> Video processor saved in /kaggle/working/models/qwen2vl-7b-vqa-grounded/checkpoint-1000/video_preprocessor_config.json\r\n",
      "[INFO|processing_utils.py:814] 2026-01-02 20:02:01,954 >> chat template saved in /kaggle/working/models/qwen2vl-7b-vqa-grounded/checkpoint-1000/chat_template.jinja\r\n",
      "{'loss': 0.5024, 'grad_norm': 1.5027579069137573, 'learning_rate': 1.1903599244835024e-05, 'epoch': 2.13}\r\n",
      " 71%|██████████████████████████▎          | 1013/1425 [1:24:22<34:16,  4.99s/it]/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\r\n",
      "  warnings.warn(\r\n",
      "{'loss': 0.5085, 'grad_norm': 1.5294604301452637, 'learning_rate': 1.1385736833396249e-05, 'epoch': 2.15}\r\n",
      "{'loss': 0.4915, 'grad_norm': 1.4388459920883179, 'learning_rate': 1.0876049578977868e-05, 'epoch': 2.17}\r\n",
      "{'loss': 0.5058, 'grad_norm': 1.388329029083252, 'learning_rate': 1.0374843540988668e-05, 'epoch': 2.19}\r\n",
      "{'loss': 0.5025, 'grad_norm': 1.4130522012710571, 'learning_rate': 9.8824196859966e-06, 'epoch': 2.21}\r\n",
      "{'loss': 0.5149, 'grad_norm': 1.594533085823059, 'learning_rate': 9.39907370700287e-06, 'epoch': 2.23}\r\n",
      "{'loss': 0.5048, 'grad_norm': 1.4967195987701416, 'learning_rate': 8.925095845882866e-06, 'epoch': 2.25}\r\n",
      "{'loss': 0.5131, 'grad_norm': 1.5153247117996216, 'learning_rate': 8.460770719100316e-06, 'epoch': 2.27}\r\n",
      "{'loss': 0.4955, 'grad_norm': 1.462934136390686, 'learning_rate': 8.006377146799477e-06, 'epoch': 2.29}\r\n",
      "{'loss': 0.4937, 'grad_norm': 1.4182324409484863, 'learning_rate': 7.562187985377878e-06, 'epoch': 2.32}\r\n",
      " 77%|████████████████████████████▌        | 1100/1425 [1:31:30<27:14,  5.03s/it][INFO|trainer.py:4643] 2026-01-02 20:10:14,508 >> \r\n",
      "***** Running Evaluation *****\r\n",
      "[INFO|trainer.py:4645] 2026-01-02 20:10:14,508 >>   Num examples = 60\r\n",
      "[INFO|trainer.py:4648] 2026-01-02 20:10:14,508 >>   Batch size = 1\r\n",
      "\r\n",
      "  0%|                                                    | 0/60 [00:00<?, ?it/s]\u001b[A\r\n",
      "  3%|█▍                                          | 2/60 [00:00<00:04, 11.78it/s]\u001b[A\r\n",
      "  7%|██▉                                         | 4/60 [00:00<00:06,  8.71it/s]\u001b[A\r\n",
      "  8%|███▋                                        | 5/60 [00:00<00:06,  8.69it/s]\u001b[A\r\n",
      " 10%|████▍                                       | 6/60 [00:00<00:06,  8.00it/s]\u001b[A\r\n",
      " 12%|█████▏                                      | 7/60 [00:00<00:06,  8.04it/s]\u001b[A\r\n",
      " 13%|█████▊                                      | 8/60 [00:00<00:06,  8.14it/s]\u001b[A\r\n",
      " 15%|██████▌                                     | 9/60 [00:01<00:07,  6.72it/s]\u001b[A\r\n",
      " 17%|███████▏                                   | 10/60 [00:01<00:07,  6.81it/s]\u001b[A\r\n",
      " 18%|███████▉                                   | 11/60 [00:01<00:06,  7.32it/s]\u001b[A\r\n",
      " 20%|████████▌                                  | 12/60 [00:01<00:06,  7.36it/s]\u001b[A\r\n",
      " 22%|█████████▎                                 | 13/60 [00:01<00:06,  6.96it/s]\u001b[A\r\n",
      " 23%|██████████                                 | 14/60 [00:02<00:12,  3.56it/s]\u001b[A\r\n",
      " 25%|██████████▊                                | 15/60 [00:02<00:10,  4.13it/s]\u001b[A\r\n",
      " 27%|███████████▍                               | 16/60 [00:02<00:09,  4.63it/s]\u001b[A\r\n",
      " 28%|████████████▏                              | 17/60 [00:02<00:08,  5.09it/s]\u001b[A\r\n",
      " 30%|████████████▉                              | 18/60 [00:02<00:07,  5.47it/s]\u001b[A\r\n",
      " 32%|█████████████▌                             | 19/60 [00:03<00:06,  6.12it/s]\u001b[A\r\n",
      " 33%|██████████████▎                            | 20/60 [00:03<00:05,  6.75it/s]\u001b[A\r\n",
      " 35%|███████████████                            | 21/60 [00:03<00:05,  7.06it/s]\u001b[A\r\n",
      " 37%|███████████████▊                           | 22/60 [00:03<00:05,  6.91it/s]\u001b[A\r\n",
      " 38%|████████████████▍                          | 23/60 [00:03<00:05,  6.46it/s]\u001b[A\r\n",
      " 40%|█████████████████▏                         | 24/60 [00:04<00:10,  3.41it/s]\u001b[A\r\n",
      " 42%|█████████████████▉                         | 25/60 [00:04<00:08,  3.92it/s]\u001b[A\r\n",
      " 43%|██████████████████▋                        | 26/60 [00:04<00:07,  4.53it/s]\u001b[A\r\n",
      " 45%|███████████████████▎                       | 27/60 [00:04<00:08,  3.97it/s]\u001b[A\r\n",
      " 47%|████████████████████                       | 28/60 [00:05<00:07,  4.33it/s]\u001b[A\r\n",
      " 48%|████████████████████▊                      | 29/60 [00:05<00:06,  4.94it/s]\u001b[A\r\n",
      " 50%|█████████████████████▌                     | 30/60 [00:05<00:05,  5.81it/s]\u001b[A\r\n",
      " 52%|██████████████████████▏                    | 31/60 [00:05<00:04,  6.55it/s]\u001b[A\r\n",
      " 53%|██████████████████████▉                    | 32/60 [00:05<00:04,  6.59it/s]\u001b[A\r\n",
      " 55%|███████████████████████▋                   | 33/60 [00:05<00:04,  5.93it/s]\u001b[A\r\n",
      " 57%|████████████████████████▎                  | 34/60 [00:05<00:04,  6.18it/s]\u001b[A\r\n",
      " 58%|█████████████████████████                  | 35/60 [00:06<00:03,  6.28it/s]\u001b[A\r\n",
      " 60%|█████████████████████████▊                 | 36/60 [00:06<00:03,  6.52it/s]\u001b[A\r\n",
      " 62%|██████████████████████████▌                | 37/60 [00:06<00:03,  7.09it/s]\u001b[A\r\n",
      " 63%|███████████████████████████▏               | 38/60 [00:06<00:03,  7.33it/s]\u001b[A\r\n",
      " 65%|███████████████████████████▉               | 39/60 [00:06<00:02,  7.20it/s]\u001b[A\r\n",
      " 67%|████████████████████████████▋              | 40/60 [00:06<00:02,  6.77it/s]\u001b[A\r\n",
      " 68%|█████████████████████████████▍             | 41/60 [00:06<00:03,  6.26it/s]\u001b[A\r\n",
      " 70%|██████████████████████████████             | 42/60 [00:07<00:02,  6.27it/s]\u001b[A\r\n",
      " 72%|██████████████████████████████▊            | 43/60 [00:07<00:02,  6.15it/s]\u001b[A\r\n",
      " 73%|███████████████████████████████▌           | 44/60 [00:07<00:02,  6.21it/s]\u001b[A\r\n",
      " 75%|████████████████████████████████▎          | 45/60 [00:07<00:02,  5.72it/s]\u001b[A\r\n",
      " 77%|████████████████████████████████▉          | 46/60 [00:07<00:02,  6.13it/s]\u001b[A\r\n",
      " 78%|█████████████████████████████████▋         | 47/60 [00:07<00:01,  6.60it/s]\u001b[A\r\n",
      " 80%|██████████████████████████████████▍        | 48/60 [00:08<00:01,  6.79it/s]\u001b[A\r\n",
      " 82%|███████████████████████████████████        | 49/60 [00:08<00:01,  7.24it/s]\u001b[A\r\n",
      " 83%|███████████████████████████████████▊       | 50/60 [00:08<00:01,  6.74it/s]\u001b[A\r\n",
      " 85%|████████████████████████████████████▌      | 51/60 [00:08<00:01,  6.62it/s]\u001b[A\r\n",
      " 87%|█████████████████████████████████████▎     | 52/60 [00:08<00:01,  6.28it/s]\u001b[A\r\n",
      " 88%|█████████████████████████████████████▉     | 53/60 [00:08<00:01,  6.55it/s]\u001b[A\r\n",
      " 90%|██████████████████████████████████████▋    | 54/60 [00:08<00:00,  6.12it/s]\u001b[A\r\n",
      " 92%|███████████████████████████████████████▍   | 55/60 [00:09<00:00,  6.21it/s]\u001b[A\r\n",
      " 93%|████████████████████████████████████████▏  | 56/60 [00:09<00:00,  6.41it/s]\u001b[A\r\n",
      " 95%|████████████████████████████████████████▊  | 57/60 [00:09<00:00,  6.67it/s]\u001b[A\r\n",
      " 97%|█████████████████████████████████████████▌ | 58/60 [00:09<00:00,  6.26it/s]\u001b[A\r\n",
      " 98%|██████████████████████████████████████████▎| 59/60 [00:09<00:00,  6.05it/s]\u001b[A\r\n",
      "100%|███████████████████████████████████████████| 60/60 [00:09<00:00,  6.49it/s]\u001b[A\r\n",
      "{'eval_loss': 0.7361970543861389, 'eval_runtime': 10.1096, 'eval_samples_per_second': 5.935, 'eval_steps_per_second': 5.935, 'epoch': 2.32}\r\n",
      "\r\n",
      " 77%|████████████████████████████▌        | 1100/1425 [1:31:40<27:14,  5.03s/it]\r\n",
      "                                                                                \u001b[A[INFO|trainer.py:4309] 2026-01-02 20:10:24,616 >> Saving model checkpoint to /kaggle/working/models/qwen2vl-7b-vqa-grounded/checkpoint-1100\r\n",
      "[INFO|configuration_utils.py:765] 2026-01-02 20:10:24,752 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2-VL-7B-Instruct/snapshots/eed13092ef92e448dd6875b2a00151bd3f7db0ac/config.json\r\n",
      "[INFO|configuration_utils.py:839] 2026-01-02 20:10:24,754 >> Model config Qwen2VLConfig {\r\n",
      "  \"architectures\": [\r\n",
      "    \"Qwen2VLForConditionalGeneration\"\r\n",
      "  ],\r\n",
      "  \"attention_dropout\": 0.0,\r\n",
      "  \"bos_token_id\": 151643,\r\n",
      "  \"dtype\": \"bfloat16\",\r\n",
      "  \"eos_token_id\": 151645,\r\n",
      "  \"hidden_act\": \"silu\",\r\n",
      "  \"hidden_size\": 3584,\r\n",
      "  \"image_token_id\": 151655,\r\n",
      "  \"initializer_range\": 0.02,\r\n",
      "  \"intermediate_size\": 18944,\r\n",
      "  \"max_position_embeddings\": 32768,\r\n",
      "  \"max_window_layers\": 28,\r\n",
      "  \"model_type\": \"qwen2_vl\",\r\n",
      "  \"num_attention_heads\": 28,\r\n",
      "  \"num_hidden_layers\": 28,\r\n",
      "  \"num_key_value_heads\": 4,\r\n",
      "  \"rms_norm_eps\": 1e-06,\r\n",
      "  \"rope_scaling\": {\r\n",
      "    \"mrope_section\": [\r\n",
      "      16,\r\n",
      "      24,\r\n",
      "      24\r\n",
      "    ],\r\n",
      "    \"rope_type\": \"default\",\r\n",
      "    \"type\": \"default\"\r\n",
      "  },\r\n",
      "  \"rope_theta\": 1000000.0,\r\n",
      "  \"sliding_window\": 32768,\r\n",
      "  \"text_config\": {\r\n",
      "    \"architectures\": [\r\n",
      "      \"Qwen2VLForConditionalGeneration\"\r\n",
      "    ],\r\n",
      "    \"attention_dropout\": 0.0,\r\n",
      "    \"bos_token_id\": 151643,\r\n",
      "    \"dtype\": \"bfloat16\",\r\n",
      "    \"eos_token_id\": 151645,\r\n",
      "    \"hidden_act\": \"silu\",\r\n",
      "    \"hidden_size\": 3584,\r\n",
      "    \"initializer_range\": 0.02,\r\n",
      "    \"intermediate_size\": 18944,\r\n",
      "    \"layer_types\": [\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\"\r\n",
      "    ],\r\n",
      "    \"max_position_embeddings\": 32768,\r\n",
      "    \"max_window_layers\": 28,\r\n",
      "    \"model_type\": \"qwen2_vl_text\",\r\n",
      "    \"num_attention_heads\": 28,\r\n",
      "    \"num_hidden_layers\": 28,\r\n",
      "    \"num_key_value_heads\": 4,\r\n",
      "    \"rms_norm_eps\": 1e-06,\r\n",
      "    \"rope_scaling\": {\r\n",
      "      \"mrope_section\": [\r\n",
      "        16,\r\n",
      "        24,\r\n",
      "        24\r\n",
      "      ],\r\n",
      "      \"rope_type\": \"default\",\r\n",
      "      \"type\": \"default\"\r\n",
      "    },\r\n",
      "    \"rope_theta\": 1000000.0,\r\n",
      "    \"sliding_window\": null,\r\n",
      "    \"use_cache\": true,\r\n",
      "    \"use_sliding_window\": false,\r\n",
      "    \"vision_token_id\": 151654,\r\n",
      "    \"vocab_size\": 152064\r\n",
      "  },\r\n",
      "  \"tie_word_embeddings\": false,\r\n",
      "  \"transformers_version\": \"4.57.1\",\r\n",
      "  \"use_cache\": true,\r\n",
      "  \"use_sliding_window\": false,\r\n",
      "  \"video_token_id\": 151656,\r\n",
      "  \"vision_config\": {\r\n",
      "    \"depth\": 32,\r\n",
      "    \"embed_dim\": 1280,\r\n",
      "    \"hidden_act\": \"quick_gelu\",\r\n",
      "    \"hidden_size\": 3584,\r\n",
      "    \"in_channels\": 3,\r\n",
      "    \"in_chans\": 3,\r\n",
      "    \"initializer_range\": 0.02,\r\n",
      "    \"mlp_ratio\": 4,\r\n",
      "    \"model_type\": \"qwen2_vl\",\r\n",
      "    \"num_heads\": 16,\r\n",
      "    \"patch_size\": 14,\r\n",
      "    \"spatial_merge_size\": 2,\r\n",
      "    \"spatial_patch_size\": 14,\r\n",
      "    \"temporal_patch_size\": 2\r\n",
      "  },\r\n",
      "  \"vision_end_token_id\": 151653,\r\n",
      "  \"vision_start_token_id\": 151652,\r\n",
      "  \"vision_token_id\": 151654,\r\n",
      "  \"vocab_size\": 152064\r\n",
      "}\r\n",
      "\r\n",
      "[INFO|tokenization_utils_base.py:2421] 2026-01-02 20:10:25,423 >> chat template saved in /kaggle/working/models/qwen2vl-7b-vqa-grounded/checkpoint-1100/chat_template.jinja\r\n",
      "[INFO|tokenization_utils_base.py:2590] 2026-01-02 20:10:25,423 >> tokenizer config file saved in /kaggle/working/models/qwen2vl-7b-vqa-grounded/checkpoint-1100/tokenizer_config.json\r\n",
      "[INFO|tokenization_utils_base.py:2599] 2026-01-02 20:10:25,423 >> Special tokens file saved in /kaggle/working/models/qwen2vl-7b-vqa-grounded/checkpoint-1100/special_tokens_map.json\r\n",
      "[INFO|trainer.py:4418] 2026-01-02 20:10:26,569 >> Deleting older checkpoint [/kaggle/working/models/qwen2vl-7b-vqa-grounded/checkpoint-800] due to args.save_total_limit\r\n",
      "[INFO|image_processing_base.py:253] 2026-01-02 20:10:26,735 >> Image processor saved in /kaggle/working/models/qwen2vl-7b-vqa-grounded/checkpoint-1100/preprocessor_config.json\r\n",
      "[INFO|tokenization_utils_base.py:2421] 2026-01-02 20:10:26,735 >> chat template saved in /kaggle/working/models/qwen2vl-7b-vqa-grounded/checkpoint-1100/chat_template.jinja\r\n",
      "[INFO|tokenization_utils_base.py:2590] 2026-01-02 20:10:26,735 >> tokenizer config file saved in /kaggle/working/models/qwen2vl-7b-vqa-grounded/checkpoint-1100/tokenizer_config.json\r\n",
      "[INFO|tokenization_utils_base.py:2599] 2026-01-02 20:10:26,736 >> Special tokens file saved in /kaggle/working/models/qwen2vl-7b-vqa-grounded/checkpoint-1100/special_tokens_map.json\r\n",
      "[INFO|video_processing_utils.py:600] 2026-01-02 20:10:26,863 >> Video processor saved in /kaggle/working/models/qwen2vl-7b-vqa-grounded/checkpoint-1100/video_preprocessor_config.json\r\n",
      "[INFO|processing_utils.py:814] 2026-01-02 20:10:26,863 >> chat template saved in /kaggle/working/models/qwen2vl-7b-vqa-grounded/checkpoint-1100/chat_template.jinja\r\n",
      " 78%|████████████████████████████▊        | 1108/1425 [1:32:22<27:13,  5.15s/it]/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\r\n",
      "  warnings.warn(\r\n",
      "{'loss': 0.5083, 'grad_norm': 1.487331509590149, 'learning_rate': 7.128469963640214e-06, 'epoch': 2.34}\r\n",
      "{'loss': 0.4948, 'grad_norm': 1.5967906713485718, 'learning_rate': 6.705483522631811e-06, 'epoch': 2.36}\r\n",
      "{'loss': 0.4916, 'grad_norm': 1.5427770614624023, 'learning_rate': 6.2934826592477096e-06, 'epoch': 2.38}\r\n",
      "{'loss': 0.4961, 'grad_norm': 1.5908321142196655, 'learning_rate': 5.892714773711455e-06, 'epoch': 2.4}\r\n",
      "{'loss': 0.5034, 'grad_norm': 1.5670170783996582, 'learning_rate': 5.503420521015002e-06, 'epoch': 2.42}\r\n",
      "{'loss': 0.5039, 'grad_norm': 1.581941843032837, 'learning_rate': 5.125833666409108e-06, 'epoch': 2.44}\r\n",
      "{'loss': 0.4911, 'grad_norm': 1.5564640760421753, 'learning_rate': 4.760180945030854e-06, 'epoch': 2.46}\r\n",
      "{'loss': 0.4918, 'grad_norm': 1.5005956888198853, 'learning_rate': 4.406681925752642e-06, 'epoch': 2.48}\r\n",
      "{'loss': 0.4903, 'grad_norm': 1.5417063236236572, 'learning_rate': 4.0655488793344715e-06, 'epoch': 2.51}\r\n",
      "{'loss': 0.5222, 'grad_norm': 1.6783729791641235, 'learning_rate': 3.7369866509585627e-06, 'epoch': 2.53}\r\n",
      " 84%|███████████████████████████████▏     | 1200/1425 [1:39:52<18:09,  4.84s/it][INFO|trainer.py:4643] 2026-01-02 20:18:36,955 >> \r\n",
      "***** Running Evaluation *****\r\n",
      "[INFO|trainer.py:4645] 2026-01-02 20:18:36,955 >>   Num examples = 60\r\n",
      "[INFO|trainer.py:4648] 2026-01-02 20:18:36,955 >>   Batch size = 1\r\n",
      "\r\n",
      "  0%|                                                    | 0/60 [00:00<?, ?it/s]\u001b[A\r\n",
      "  3%|█▍                                          | 2/60 [00:00<00:04, 11.75it/s]\u001b[A\r\n",
      "  7%|██▉                                         | 4/60 [00:00<00:06,  8.69it/s]\u001b[A\r\n",
      "  8%|███▋                                        | 5/60 [00:00<00:06,  8.70it/s]\u001b[A\r\n",
      " 10%|████▍                                       | 6/60 [00:00<00:06,  8.04it/s]\u001b[A\r\n",
      " 12%|█████▏                                      | 7/60 [00:00<00:06,  8.11it/s]\u001b[A\r\n",
      " 13%|█████▊                                      | 8/60 [00:00<00:06,  8.20it/s]\u001b[A\r\n",
      " 15%|██████▌                                     | 9/60 [00:01<00:07,  6.74it/s]\u001b[A\r\n",
      " 17%|███████▏                                   | 10/60 [00:01<00:07,  6.84it/s]\u001b[A\r\n",
      " 18%|███████▉                                   | 11/60 [00:01<00:06,  7.33it/s]\u001b[A\r\n",
      " 20%|████████▌                                  | 12/60 [00:01<00:06,  7.36it/s]\u001b[A\r\n",
      " 22%|█████████▎                                 | 13/60 [00:01<00:06,  7.04it/s]\u001b[A\r\n",
      " 23%|██████████                                 | 14/60 [00:02<00:12,  3.61it/s]\u001b[A\r\n",
      " 25%|██████████▊                                | 15/60 [00:02<00:10,  4.18it/s]\u001b[A\r\n",
      " 27%|███████████▍                               | 16/60 [00:02<00:09,  4.69it/s]\u001b[A\r\n",
      " 28%|████████████▏                              | 17/60 [00:02<00:08,  5.12it/s]\u001b[A\r\n",
      " 30%|████████████▉                              | 18/60 [00:02<00:07,  5.50it/s]\u001b[A\r\n",
      " 32%|█████████████▌                             | 19/60 [00:03<00:06,  6.16it/s]\u001b[A\r\n",
      " 33%|██████████████▎                            | 20/60 [00:03<00:05,  6.79it/s]\u001b[A\r\n",
      " 35%|███████████████                            | 21/60 [00:03<00:05,  7.11it/s]\u001b[A\r\n",
      " 37%|███████████████▊                           | 22/60 [00:03<00:05,  6.92it/s]\u001b[A\r\n",
      " 38%|████████████████▍                          | 23/60 [00:03<00:05,  6.48it/s]\u001b[A\r\n",
      " 40%|█████████████████▏                         | 24/60 [00:04<00:10,  3.55it/s]\u001b[A\r\n",
      " 42%|█████████████████▉                         | 25/60 [00:04<00:08,  4.05it/s]\u001b[A\r\n",
      " 43%|██████████████████▋                        | 26/60 [00:04<00:07,  4.62it/s]\u001b[A\r\n",
      " 45%|███████████████████▎                       | 27/60 [00:04<00:08,  4.06it/s]\u001b[A\r\n",
      " 47%|████████████████████                       | 28/60 [00:04<00:07,  4.41it/s]\u001b[A\r\n",
      " 48%|████████████████████▊                      | 29/60 [00:05<00:06,  5.02it/s]\u001b[A\r\n",
      " 50%|█████████████████████▌                     | 30/60 [00:05<00:05,  5.89it/s]\u001b[A\r\n",
      " 52%|██████████████████████▏                    | 31/60 [00:05<00:04,  6.63it/s]\u001b[A\r\n",
      " 53%|██████████████████████▉                    | 32/60 [00:05<00:04,  6.65it/s]\u001b[A\r\n",
      " 55%|███████████████████████▋                   | 33/60 [00:05<00:04,  6.14it/s]\u001b[A\r\n",
      " 57%|████████████████████████▎                  | 34/60 [00:05<00:04,  6.35it/s]\u001b[A\r\n",
      " 58%|█████████████████████████                  | 35/60 [00:05<00:03,  6.41it/s]\u001b[A\r\n",
      " 60%|█████████████████████████▊                 | 36/60 [00:06<00:03,  6.64it/s]\u001b[A\r\n",
      " 62%|██████████████████████████▌                | 37/60 [00:06<00:03,  7.21it/s]\u001b[A\r\n",
      " 63%|███████████████████████████▏               | 38/60 [00:06<00:02,  7.40it/s]\u001b[A\r\n",
      " 65%|███████████████████████████▉               | 39/60 [00:06<00:02,  7.27it/s]\u001b[A\r\n",
      " 67%|████████████████████████████▋              | 40/60 [00:06<00:02,  6.83it/s]\u001b[A\r\n",
      " 68%|█████████████████████████████▍             | 41/60 [00:06<00:03,  6.33it/s]\u001b[A\r\n",
      " 70%|██████████████████████████████             | 42/60 [00:06<00:02,  6.35it/s]\u001b[A\r\n",
      " 72%|██████████████████████████████▊            | 43/60 [00:07<00:02,  6.23it/s]\u001b[A\r\n",
      " 73%|███████████████████████████████▌           | 44/60 [00:07<00:02,  6.29it/s]\u001b[A\r\n",
      " 75%|████████████████████████████████▎          | 45/60 [00:07<00:02,  5.84it/s]\u001b[A\r\n",
      " 77%|████████████████████████████████▉          | 46/60 [00:07<00:02,  6.23it/s]\u001b[A\r\n",
      " 78%|█████████████████████████████████▋         | 47/60 [00:07<00:01,  6.78it/s]\u001b[A\r\n",
      " 80%|██████████████████████████████████▍        | 48/60 [00:07<00:01,  6.93it/s]\u001b[A\r\n",
      " 82%|███████████████████████████████████        | 49/60 [00:08<00:01,  7.36it/s]\u001b[A\r\n",
      " 83%|███████████████████████████████████▊       | 50/60 [00:08<00:01,  6.85it/s]\u001b[A\r\n",
      " 85%|████████████████████████████████████▌      | 51/60 [00:08<00:01,  6.70it/s]\u001b[A\r\n",
      " 87%|█████████████████████████████████████▎     | 52/60 [00:08<00:01,  6.37it/s]\u001b[A\r\n",
      " 88%|█████████████████████████████████████▉     | 53/60 [00:08<00:01,  6.61it/s]\u001b[A\r\n",
      " 90%|██████████████████████████████████████▋    | 54/60 [00:08<00:00,  6.18it/s]\u001b[A\r\n",
      " 92%|███████████████████████████████████████▍   | 55/60 [00:08<00:00,  6.25it/s]\u001b[A\r\n",
      " 93%|████████████████████████████████████████▏  | 56/60 [00:09<00:00,  6.43it/s]\u001b[A\r\n",
      " 95%|████████████████████████████████████████▊  | 57/60 [00:09<00:00,  6.68it/s]\u001b[A\r\n",
      " 97%|█████████████████████████████████████████▌ | 58/60 [00:09<00:00,  6.26it/s]\u001b[A\r\n",
      " 98%|██████████████████████████████████████████▎| 59/60 [00:09<00:00,  6.04it/s]\u001b[A\r\n",
      "100%|███████████████████████████████████████████| 60/60 [00:09<00:00,  6.48it/s]\u001b[A\r\n",
      "{'eval_loss': 0.7306582927703857, 'eval_runtime': 9.9907, 'eval_samples_per_second': 6.006, 'eval_steps_per_second': 6.006, 'epoch': 2.53}\r\n",
      "\r\n",
      " 84%|███████████████████████████████▏     | 1200/1425 [1:40:02<18:09,  4.84s/it]\r\n",
      "                                                                                \u001b[A[INFO|trainer.py:4309] 2026-01-02 20:18:46,944 >> Saving model checkpoint to /kaggle/working/models/qwen2vl-7b-vqa-grounded/checkpoint-1200\r\n",
      "[INFO|configuration_utils.py:765] 2026-01-02 20:18:47,077 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2-VL-7B-Instruct/snapshots/eed13092ef92e448dd6875b2a00151bd3f7db0ac/config.json\r\n",
      "[INFO|configuration_utils.py:839] 2026-01-02 20:18:47,079 >> Model config Qwen2VLConfig {\r\n",
      "  \"architectures\": [\r\n",
      "    \"Qwen2VLForConditionalGeneration\"\r\n",
      "  ],\r\n",
      "  \"attention_dropout\": 0.0,\r\n",
      "  \"bos_token_id\": 151643,\r\n",
      "  \"dtype\": \"bfloat16\",\r\n",
      "  \"eos_token_id\": 151645,\r\n",
      "  \"hidden_act\": \"silu\",\r\n",
      "  \"hidden_size\": 3584,\r\n",
      "  \"image_token_id\": 151655,\r\n",
      "  \"initializer_range\": 0.02,\r\n",
      "  \"intermediate_size\": 18944,\r\n",
      "  \"max_position_embeddings\": 32768,\r\n",
      "  \"max_window_layers\": 28,\r\n",
      "  \"model_type\": \"qwen2_vl\",\r\n",
      "  \"num_attention_heads\": 28,\r\n",
      "  \"num_hidden_layers\": 28,\r\n",
      "  \"num_key_value_heads\": 4,\r\n",
      "  \"rms_norm_eps\": 1e-06,\r\n",
      "  \"rope_scaling\": {\r\n",
      "    \"mrope_section\": [\r\n",
      "      16,\r\n",
      "      24,\r\n",
      "      24\r\n",
      "    ],\r\n",
      "    \"rope_type\": \"default\",\r\n",
      "    \"type\": \"default\"\r\n",
      "  },\r\n",
      "  \"rope_theta\": 1000000.0,\r\n",
      "  \"sliding_window\": 32768,\r\n",
      "  \"text_config\": {\r\n",
      "    \"architectures\": [\r\n",
      "      \"Qwen2VLForConditionalGeneration\"\r\n",
      "    ],\r\n",
      "    \"attention_dropout\": 0.0,\r\n",
      "    \"bos_token_id\": 151643,\r\n",
      "    \"dtype\": \"bfloat16\",\r\n",
      "    \"eos_token_id\": 151645,\r\n",
      "    \"hidden_act\": \"silu\",\r\n",
      "    \"hidden_size\": 3584,\r\n",
      "    \"initializer_range\": 0.02,\r\n",
      "    \"intermediate_size\": 18944,\r\n",
      "    \"layer_types\": [\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\"\r\n",
      "    ],\r\n",
      "    \"max_position_embeddings\": 32768,\r\n",
      "    \"max_window_layers\": 28,\r\n",
      "    \"model_type\": \"qwen2_vl_text\",\r\n",
      "    \"num_attention_heads\": 28,\r\n",
      "    \"num_hidden_layers\": 28,\r\n",
      "    \"num_key_value_heads\": 4,\r\n",
      "    \"rms_norm_eps\": 1e-06,\r\n",
      "    \"rope_scaling\": {\r\n",
      "      \"mrope_section\": [\r\n",
      "        16,\r\n",
      "        24,\r\n",
      "        24\r\n",
      "      ],\r\n",
      "      \"rope_type\": \"default\",\r\n",
      "      \"type\": \"default\"\r\n",
      "    },\r\n",
      "    \"rope_theta\": 1000000.0,\r\n",
      "    \"sliding_window\": null,\r\n",
      "    \"use_cache\": true,\r\n",
      "    \"use_sliding_window\": false,\r\n",
      "    \"vision_token_id\": 151654,\r\n",
      "    \"vocab_size\": 152064\r\n",
      "  },\r\n",
      "  \"tie_word_embeddings\": false,\r\n",
      "  \"transformers_version\": \"4.57.1\",\r\n",
      "  \"use_cache\": true,\r\n",
      "  \"use_sliding_window\": false,\r\n",
      "  \"video_token_id\": 151656,\r\n",
      "  \"vision_config\": {\r\n",
      "    \"depth\": 32,\r\n",
      "    \"embed_dim\": 1280,\r\n",
      "    \"hidden_act\": \"quick_gelu\",\r\n",
      "    \"hidden_size\": 3584,\r\n",
      "    \"in_channels\": 3,\r\n",
      "    \"in_chans\": 3,\r\n",
      "    \"initializer_range\": 0.02,\r\n",
      "    \"mlp_ratio\": 4,\r\n",
      "    \"model_type\": \"qwen2_vl\",\r\n",
      "    \"num_heads\": 16,\r\n",
      "    \"patch_size\": 14,\r\n",
      "    \"spatial_merge_size\": 2,\r\n",
      "    \"spatial_patch_size\": 14,\r\n",
      "    \"temporal_patch_size\": 2\r\n",
      "  },\r\n",
      "  \"vision_end_token_id\": 151653,\r\n",
      "  \"vision_start_token_id\": 151652,\r\n",
      "  \"vision_token_id\": 151654,\r\n",
      "  \"vocab_size\": 152064\r\n",
      "}\r\n",
      "\r\n",
      "[INFO|tokenization_utils_base.py:2421] 2026-01-02 20:18:47,737 >> chat template saved in /kaggle/working/models/qwen2vl-7b-vqa-grounded/checkpoint-1200/chat_template.jinja\r\n",
      "[INFO|tokenization_utils_base.py:2590] 2026-01-02 20:18:47,737 >> tokenizer config file saved in /kaggle/working/models/qwen2vl-7b-vqa-grounded/checkpoint-1200/tokenizer_config.json\r\n",
      "[INFO|tokenization_utils_base.py:2599] 2026-01-02 20:18:47,737 >> Special tokens file saved in /kaggle/working/models/qwen2vl-7b-vqa-grounded/checkpoint-1200/special_tokens_map.json\r\n",
      "[INFO|trainer.py:4418] 2026-01-02 20:18:48,834 >> Deleting older checkpoint [/kaggle/working/models/qwen2vl-7b-vqa-grounded/checkpoint-1000] due to args.save_total_limit\r\n",
      "[INFO|image_processing_base.py:253] 2026-01-02 20:18:48,990 >> Image processor saved in /kaggle/working/models/qwen2vl-7b-vqa-grounded/checkpoint-1200/preprocessor_config.json\r\n",
      "[INFO|tokenization_utils_base.py:2421] 2026-01-02 20:18:48,991 >> chat template saved in /kaggle/working/models/qwen2vl-7b-vqa-grounded/checkpoint-1200/chat_template.jinja\r\n",
      "[INFO|tokenization_utils_base.py:2590] 2026-01-02 20:18:48,991 >> tokenizer config file saved in /kaggle/working/models/qwen2vl-7b-vqa-grounded/checkpoint-1200/tokenizer_config.json\r\n",
      "[INFO|tokenization_utils_base.py:2599] 2026-01-02 20:18:48,991 >> Special tokens file saved in /kaggle/working/models/qwen2vl-7b-vqa-grounded/checkpoint-1200/special_tokens_map.json\r\n",
      "[INFO|video_processing_utils.py:600] 2026-01-02 20:18:49,118 >> Video processor saved in /kaggle/working/models/qwen2vl-7b-vqa-grounded/checkpoint-1200/video_preprocessor_config.json\r\n",
      "[INFO|processing_utils.py:814] 2026-01-02 20:18:49,118 >> chat template saved in /kaggle/working/models/qwen2vl-7b-vqa-grounded/checkpoint-1200/chat_template.jinja\r\n",
      "{'loss': 0.4966, 'grad_norm': 1.5938374996185303, 'learning_rate': 3.4211925372229974e-06, 'epoch': 2.55}\r\n",
      " 85%|███████████████████████████████▍     | 1212/1425 [1:41:04<17:23,  4.90s/it]/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\r\n",
      "  warnings.warn(\r\n",
      "{'loss': 0.509, 'grad_norm': 1.701583743095398, 'learning_rate': 3.1183561676680655e-06, 'epoch': 2.57}\r\n",
      "{'loss': 0.4785, 'grad_norm': 1.502013087272644, 'learning_rate': 2.8286593909066933e-06, 'epoch': 2.59}\r\n",
      "{'loss': 0.4896, 'grad_norm': 1.6189935207366943, 'learning_rate': 2.552276165427056e-06, 'epoch': 2.61}\r\n",
      "{'loss': 0.4915, 'grad_norm': 1.4440391063690186, 'learning_rate': 2.289372455133226e-06, 'epoch': 2.63}\r\n",
      "{'loss': 0.4893, 'grad_norm': 1.5235339403152466, 'learning_rate': 2.040106129686356e-06, 'epoch': 2.65}\r\n",
      "{'loss': 0.4979, 'grad_norm': 1.5881463289260864, 'learning_rate': 1.8046268697063467e-06, 'epoch': 2.67}\r\n",
      "{'loss': 0.4995, 'grad_norm': 1.5792852640151978, 'learning_rate': 1.583076076890963e-06, 'epoch': 2.69}\r\n",
      "{'loss': 0.4941, 'grad_norm': 1.6301630735397339, 'learning_rate': 1.37558678910622e-06, 'epoch': 2.72}\r\n",
      "{'loss': 0.5032, 'grad_norm': 1.5424152612686157, 'learning_rate': 1.1822836004992343e-06, 'epoch': 2.74}\r\n",
      " 91%|█████████████████████████████████▊   | 1300/1425 [1:48:09<10:02,  4.82s/it][INFO|trainer.py:4643] 2026-01-02 20:26:54,211 >> \r\n",
      "***** Running Evaluation *****\r\n",
      "[INFO|trainer.py:4645] 2026-01-02 20:26:54,211 >>   Num examples = 60\r\n",
      "[INFO|trainer.py:4648] 2026-01-02 20:26:54,211 >>   Batch size = 1\r\n",
      "\r\n",
      "  0%|                                                    | 0/60 [00:00<?, ?it/s]\u001b[A\r\n",
      "  3%|█▍                                          | 2/60 [00:00<00:04, 11.63it/s]\u001b[A\r\n",
      "  7%|██▉                                         | 4/60 [00:00<00:06,  8.61it/s]\u001b[A\r\n",
      "  8%|███▋                                        | 5/60 [00:00<00:06,  8.63it/s]\u001b[A\r\n",
      " 10%|████▍                                       | 6/60 [00:00<00:06,  7.97it/s]\u001b[A\r\n",
      " 12%|█████▏                                      | 7/60 [00:00<00:06,  8.05it/s]\u001b[A\r\n",
      " 13%|█████▊                                      | 8/60 [00:00<00:06,  8.15it/s]\u001b[A\r\n",
      " 15%|██████▌                                     | 9/60 [00:01<00:07,  6.72it/s]\u001b[A\r\n",
      " 17%|███████▏                                   | 10/60 [00:01<00:07,  6.82it/s]\u001b[A\r\n",
      " 18%|███████▉                                   | 11/60 [00:01<00:06,  7.33it/s]\u001b[A\r\n",
      " 20%|████████▌                                  | 12/60 [00:01<00:06,  7.37it/s]\u001b[A\r\n",
      " 22%|█████████▎                                 | 13/60 [00:01<00:06,  7.04it/s]\u001b[A\r\n",
      " 23%|██████████                                 | 14/60 [00:02<00:12,  3.72it/s]\u001b[A\r\n",
      " 25%|██████████▊                                | 15/60 [00:02<00:10,  4.29it/s]\u001b[A\r\n",
      " 27%|███████████▍                               | 16/60 [00:02<00:09,  4.77it/s]\u001b[A\r\n",
      " 28%|████████████▏                              | 17/60 [00:02<00:08,  5.22it/s]\u001b[A\r\n",
      " 30%|████████████▉                              | 18/60 [00:02<00:07,  5.58it/s]\u001b[A\r\n",
      " 32%|█████████████▌                             | 19/60 [00:02<00:06,  6.24it/s]\u001b[A\r\n",
      " 33%|██████████████▎                            | 20/60 [00:03<00:05,  6.85it/s]\u001b[A\r\n",
      " 35%|███████████████                            | 21/60 [00:03<00:05,  7.16it/s]\u001b[A\r\n",
      " 37%|███████████████▊                           | 22/60 [00:03<00:05,  6.93it/s]\u001b[A\r\n",
      " 38%|████████████████▍                          | 23/60 [00:03<00:05,  6.50it/s]\u001b[A\r\n",
      " 40%|█████████████████▏                         | 24/60 [00:04<00:10,  3.46it/s]\u001b[A\r\n",
      " 42%|█████████████████▉                         | 25/60 [00:04<00:08,  3.97it/s]\u001b[A\r\n",
      " 43%|██████████████████▋                        | 26/60 [00:04<00:07,  4.58it/s]\u001b[A\r\n",
      " 45%|███████████████████▎                       | 27/60 [00:04<00:08,  4.06it/s]\u001b[A\r\n",
      " 47%|████████████████████                       | 28/60 [00:04<00:07,  4.41it/s]\u001b[A\r\n",
      " 48%|████████████████████▊                      | 29/60 [00:05<00:06,  5.00it/s]\u001b[A\r\n",
      " 52%|██████████████████████▏                    | 31/60 [00:05<00:04,  6.45it/s]\u001b[A\r\n",
      " 53%|██████████████████████▉                    | 32/60 [00:05<00:04,  6.45it/s]\u001b[A\r\n",
      " 55%|███████████████████████▋                   | 33/60 [00:05<00:04,  6.08it/s]\u001b[A\r\n",
      " 57%|████████████████████████▎                  | 34/60 [00:05<00:04,  6.28it/s]\u001b[A\r\n",
      " 58%|█████████████████████████                  | 35/60 [00:05<00:03,  6.36it/s]\u001b[A\r\n",
      " 60%|█████████████████████████▊                 | 36/60 [00:06<00:03,  6.58it/s]\u001b[A\r\n",
      " 62%|██████████████████████████▌                | 37/60 [00:06<00:03,  7.12it/s]\u001b[A\r\n",
      " 63%|███████████████████████████▏               | 38/60 [00:06<00:02,  7.36it/s]\u001b[A\r\n",
      " 65%|███████████████████████████▉               | 39/60 [00:06<00:02,  7.27it/s]\u001b[A\r\n",
      " 67%|████████████████████████████▋              | 40/60 [00:06<00:02,  6.81it/s]\u001b[A\r\n",
      " 68%|█████████████████████████████▍             | 41/60 [00:06<00:03,  6.31it/s]\u001b[A\r\n",
      " 70%|██████████████████████████████             | 42/60 [00:06<00:02,  6.32it/s]\u001b[A\r\n",
      " 72%|██████████████████████████████▊            | 43/60 [00:07<00:02,  6.20it/s]\u001b[A\r\n",
      " 73%|███████████████████████████████▌           | 44/60 [00:07<00:02,  6.25it/s]\u001b[A\r\n",
      " 75%|████████████████████████████████▎          | 45/60 [00:07<00:02,  5.80it/s]\u001b[A\r\n",
      " 77%|████████████████████████████████▉          | 46/60 [00:07<00:02,  6.19it/s]\u001b[A\r\n",
      " 78%|█████████████████████████████████▋         | 47/60 [00:07<00:01,  6.71it/s]\u001b[A\r\n",
      " 80%|██████████████████████████████████▍        | 48/60 [00:07<00:01,  6.87it/s]\u001b[A\r\n",
      " 82%|███████████████████████████████████        | 49/60 [00:08<00:01,  7.28it/s]\u001b[A\r\n",
      " 83%|███████████████████████████████████▊       | 50/60 [00:08<00:01,  6.77it/s]\u001b[A\r\n",
      " 85%|████████████████████████████████████▌      | 51/60 [00:08<00:01,  6.66it/s]\u001b[A\r\n",
      " 87%|█████████████████████████████████████▎     | 52/60 [00:08<00:01,  6.34it/s]\u001b[A\r\n",
      " 88%|█████████████████████████████████████▉     | 53/60 [00:08<00:01,  6.60it/s]\u001b[A\r\n",
      " 90%|██████████████████████████████████████▋    | 54/60 [00:08<00:00,  6.19it/s]\u001b[A\r\n",
      " 92%|███████████████████████████████████████▍   | 55/60 [00:08<00:00,  6.26it/s]\u001b[A\r\n",
      " 93%|████████████████████████████████████████▏  | 56/60 [00:09<00:00,  6.44it/s]\u001b[A\r\n",
      " 95%|████████████████████████████████████████▊  | 57/60 [00:09<00:00,  6.68it/s]\u001b[A\r\n",
      " 97%|█████████████████████████████████████████▌ | 58/60 [00:09<00:00,  6.28it/s]\u001b[A\r\n",
      " 98%|██████████████████████████████████████████▎| 59/60 [00:09<00:00,  6.05it/s]\u001b[A\r\n",
      "100%|███████████████████████████████████████████| 60/60 [00:09<00:00,  6.49it/s]\u001b[A\r\n",
      "{'eval_loss': 0.7295172214508057, 'eval_runtime': 9.9983, 'eval_samples_per_second': 6.001, 'eval_steps_per_second': 6.001, 'epoch': 2.74}\r\n",
      "\r\n",
      " 91%|█████████████████████████████████▊   | 1300/1425 [1:48:19<10:02,  4.82s/it]\r\n",
      "                                                                                \u001b[A[INFO|trainer.py:4309] 2026-01-02 20:27:04,207 >> Saving model checkpoint to /kaggle/working/models/qwen2vl-7b-vqa-grounded/checkpoint-1300\r\n",
      "[INFO|configuration_utils.py:765] 2026-01-02 20:27:04,343 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2-VL-7B-Instruct/snapshots/eed13092ef92e448dd6875b2a00151bd3f7db0ac/config.json\r\n",
      "[INFO|configuration_utils.py:839] 2026-01-02 20:27:04,345 >> Model config Qwen2VLConfig {\r\n",
      "  \"architectures\": [\r\n",
      "    \"Qwen2VLForConditionalGeneration\"\r\n",
      "  ],\r\n",
      "  \"attention_dropout\": 0.0,\r\n",
      "  \"bos_token_id\": 151643,\r\n",
      "  \"dtype\": \"bfloat16\",\r\n",
      "  \"eos_token_id\": 151645,\r\n",
      "  \"hidden_act\": \"silu\",\r\n",
      "  \"hidden_size\": 3584,\r\n",
      "  \"image_token_id\": 151655,\r\n",
      "  \"initializer_range\": 0.02,\r\n",
      "  \"intermediate_size\": 18944,\r\n",
      "  \"max_position_embeddings\": 32768,\r\n",
      "  \"max_window_layers\": 28,\r\n",
      "  \"model_type\": \"qwen2_vl\",\r\n",
      "  \"num_attention_heads\": 28,\r\n",
      "  \"num_hidden_layers\": 28,\r\n",
      "  \"num_key_value_heads\": 4,\r\n",
      "  \"rms_norm_eps\": 1e-06,\r\n",
      "  \"rope_scaling\": {\r\n",
      "    \"mrope_section\": [\r\n",
      "      16,\r\n",
      "      24,\r\n",
      "      24\r\n",
      "    ],\r\n",
      "    \"rope_type\": \"default\",\r\n",
      "    \"type\": \"default\"\r\n",
      "  },\r\n",
      "  \"rope_theta\": 1000000.0,\r\n",
      "  \"sliding_window\": 32768,\r\n",
      "  \"text_config\": {\r\n",
      "    \"architectures\": [\r\n",
      "      \"Qwen2VLForConditionalGeneration\"\r\n",
      "    ],\r\n",
      "    \"attention_dropout\": 0.0,\r\n",
      "    \"bos_token_id\": 151643,\r\n",
      "    \"dtype\": \"bfloat16\",\r\n",
      "    \"eos_token_id\": 151645,\r\n",
      "    \"hidden_act\": \"silu\",\r\n",
      "    \"hidden_size\": 3584,\r\n",
      "    \"initializer_range\": 0.02,\r\n",
      "    \"intermediate_size\": 18944,\r\n",
      "    \"layer_types\": [\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\"\r\n",
      "    ],\r\n",
      "    \"max_position_embeddings\": 32768,\r\n",
      "    \"max_window_layers\": 28,\r\n",
      "    \"model_type\": \"qwen2_vl_text\",\r\n",
      "    \"num_attention_heads\": 28,\r\n",
      "    \"num_hidden_layers\": 28,\r\n",
      "    \"num_key_value_heads\": 4,\r\n",
      "    \"rms_norm_eps\": 1e-06,\r\n",
      "    \"rope_scaling\": {\r\n",
      "      \"mrope_section\": [\r\n",
      "        16,\r\n",
      "        24,\r\n",
      "        24\r\n",
      "      ],\r\n",
      "      \"rope_type\": \"default\",\r\n",
      "      \"type\": \"default\"\r\n",
      "    },\r\n",
      "    \"rope_theta\": 1000000.0,\r\n",
      "    \"sliding_window\": null,\r\n",
      "    \"use_cache\": true,\r\n",
      "    \"use_sliding_window\": false,\r\n",
      "    \"vision_token_id\": 151654,\r\n",
      "    \"vocab_size\": 152064\r\n",
      "  },\r\n",
      "  \"tie_word_embeddings\": false,\r\n",
      "  \"transformers_version\": \"4.57.1\",\r\n",
      "  \"use_cache\": true,\r\n",
      "  \"use_sliding_window\": false,\r\n",
      "  \"video_token_id\": 151656,\r\n",
      "  \"vision_config\": {\r\n",
      "    \"depth\": 32,\r\n",
      "    \"embed_dim\": 1280,\r\n",
      "    \"hidden_act\": \"quick_gelu\",\r\n",
      "    \"hidden_size\": 3584,\r\n",
      "    \"in_channels\": 3,\r\n",
      "    \"in_chans\": 3,\r\n",
      "    \"initializer_range\": 0.02,\r\n",
      "    \"mlp_ratio\": 4,\r\n",
      "    \"model_type\": \"qwen2_vl\",\r\n",
      "    \"num_heads\": 16,\r\n",
      "    \"patch_size\": 14,\r\n",
      "    \"spatial_merge_size\": 2,\r\n",
      "    \"spatial_patch_size\": 14,\r\n",
      "    \"temporal_patch_size\": 2\r\n",
      "  },\r\n",
      "  \"vision_end_token_id\": 151653,\r\n",
      "  \"vision_start_token_id\": 151652,\r\n",
      "  \"vision_token_id\": 151654,\r\n",
      "  \"vocab_size\": 152064\r\n",
      "}\r\n",
      "\r\n",
      "[INFO|tokenization_utils_base.py:2421] 2026-01-02 20:27:05,005 >> chat template saved in /kaggle/working/models/qwen2vl-7b-vqa-grounded/checkpoint-1300/chat_template.jinja\r\n",
      "[INFO|tokenization_utils_base.py:2590] 2026-01-02 20:27:05,006 >> tokenizer config file saved in /kaggle/working/models/qwen2vl-7b-vqa-grounded/checkpoint-1300/tokenizer_config.json\r\n",
      "[INFO|tokenization_utils_base.py:2599] 2026-01-02 20:27:05,006 >> Special tokens file saved in /kaggle/working/models/qwen2vl-7b-vqa-grounded/checkpoint-1300/special_tokens_map.json\r\n",
      "[INFO|trainer.py:4418] 2026-01-02 20:27:06,121 >> Deleting older checkpoint [/kaggle/working/models/qwen2vl-7b-vqa-grounded/checkpoint-1100] due to args.save_total_limit\r\n",
      "[INFO|image_processing_base.py:253] 2026-01-02 20:27:06,276 >> Image processor saved in /kaggle/working/models/qwen2vl-7b-vqa-grounded/checkpoint-1300/preprocessor_config.json\r\n",
      "[INFO|tokenization_utils_base.py:2421] 2026-01-02 20:27:06,276 >> chat template saved in /kaggle/working/models/qwen2vl-7b-vqa-grounded/checkpoint-1300/chat_template.jinja\r\n",
      "[INFO|tokenization_utils_base.py:2590] 2026-01-02 20:27:06,277 >> tokenizer config file saved in /kaggle/working/models/qwen2vl-7b-vqa-grounded/checkpoint-1300/tokenizer_config.json\r\n",
      "[INFO|tokenization_utils_base.py:2599] 2026-01-02 20:27:06,277 >> Special tokens file saved in /kaggle/working/models/qwen2vl-7b-vqa-grounded/checkpoint-1300/special_tokens_map.json\r\n",
      "[INFO|video_processing_utils.py:600] 2026-01-02 20:27:06,404 >> Video processor saved in /kaggle/working/models/qwen2vl-7b-vqa-grounded/checkpoint-1300/video_preprocessor_config.json\r\n",
      "[INFO|processing_utils.py:814] 2026-01-02 20:27:06,404 >> chat template saved in /kaggle/working/models/qwen2vl-7b-vqa-grounded/checkpoint-1300/chat_template.jinja\r\n",
      " 91%|█████████████████████████████████▊   | 1302/1425 [1:48:32<15:32,  7.58s/it]/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\r\n",
      "  warnings.warn(\r\n",
      "{'loss': 0.4956, 'grad_norm': 1.5741957426071167, 'learning_rate': 1.003282586681295e-06, 'epoch': 2.76}\r\n",
      "{'loss': 0.5006, 'grad_norm': 1.4869754314422607, 'learning_rate': 8.386912350262565e-07, 'epoch': 2.78}\r\n",
      "{'loss': 0.4716, 'grad_norm': 1.5614088773727417, 'learning_rate': 6.886083801260157e-07, 'epoch': 2.8}\r\n",
      "{'loss': 0.5009, 'grad_norm': 1.5691893100738525, 'learning_rate': 5.531241444418328e-07, 'epoch': 2.82}\r\n",
      "{'loss': 0.4763, 'grad_norm': 1.3997939825057983, 'learning_rate': 4.323198841871878e-07, 'epoch': 2.84}\r\n",
      "{'loss': 0.4951, 'grad_norm': 1.6549872159957886, 'learning_rate': 3.262681404746004e-07, 'epoch': 2.86}\r\n",
      "{'loss': 0.4954, 'grad_norm': 1.5326265096664429, 'learning_rate': 2.3503259575582137e-07, 'epoch': 2.88}\r\n",
      "{'loss': 0.477, 'grad_norm': 1.6144647598266602, 'learning_rate': 1.5866803558146625e-07, 'epoch': 2.91}\r\n",
      "{'loss': 0.4892, 'grad_norm': 1.6707826852798462, 'learning_rate': 9.722031570316147e-08, 'epoch': 2.93}\r\n",
      "{'loss': 0.5143, 'grad_norm': 1.633400559425354, 'learning_rate': 5.072633453783171e-08, 'epoch': 2.95}\r\n",
      " 98%|████████████████████████████████████▎| 1400/1425 [1:56:30<02:01,  4.85s/it][INFO|trainer.py:4643] 2026-01-02 20:35:14,968 >> \r\n",
      "***** Running Evaluation *****\r\n",
      "[INFO|trainer.py:4645] 2026-01-02 20:35:14,968 >>   Num examples = 60\r\n",
      "[INFO|trainer.py:4648] 2026-01-02 20:35:14,968 >>   Batch size = 1\r\n",
      "\r\n",
      "  0%|                                                    | 0/60 [00:00<?, ?it/s]\u001b[A\r\n",
      "  3%|█▍                                          | 2/60 [00:00<00:04, 11.66it/s]\u001b[A\r\n",
      "  7%|██▉                                         | 4/60 [00:00<00:06,  8.62it/s]\u001b[A\r\n",
      "  8%|███▋                                        | 5/60 [00:00<00:06,  8.56it/s]\u001b[A\r\n",
      " 10%|████▍                                       | 6/60 [00:00<00:06,  7.92it/s]\u001b[A\r\n",
      " 12%|█████▏                                      | 7/60 [00:00<00:06,  8.00it/s]\u001b[A\r\n",
      " 13%|█████▊                                      | 8/60 [00:00<00:06,  8.11it/s]\u001b[A\r\n",
      " 15%|██████▌                                     | 9/60 [00:01<00:07,  6.72it/s]\u001b[A\r\n",
      " 17%|███████▏                                   | 10/60 [00:01<00:07,  6.82it/s]\u001b[A\r\n",
      " 18%|███████▉                                   | 11/60 [00:01<00:06,  7.31it/s]\u001b[A\r\n",
      " 20%|████████▌                                  | 12/60 [00:01<00:06,  7.32it/s]\u001b[A\r\n",
      " 22%|█████████▎                                 | 13/60 [00:01<00:06,  6.99it/s]\u001b[A\r\n",
      " 23%|██████████                                 | 14/60 [00:02<00:12,  3.68it/s]\u001b[A\r\n",
      " 25%|██████████▊                                | 15/60 [00:02<00:10,  4.25it/s]\u001b[A\r\n",
      " 27%|███████████▍                               | 16/60 [00:02<00:09,  4.74it/s]\u001b[A\r\n",
      " 28%|████████████▏                              | 17/60 [00:02<00:08,  5.20it/s]\u001b[A\r\n",
      " 30%|████████████▉                              | 18/60 [00:02<00:07,  5.56it/s]\u001b[A\r\n",
      " 32%|█████████████▌                             | 19/60 [00:03<00:06,  6.21it/s]\u001b[A\r\n",
      " 33%|██████████████▎                            | 20/60 [00:03<00:05,  6.82it/s]\u001b[A\r\n",
      " 35%|███████████████                            | 21/60 [00:03<00:05,  7.12it/s]\u001b[A\r\n",
      " 37%|███████████████▊                           | 22/60 [00:03<00:05,  6.97it/s]\u001b[A\r\n",
      " 38%|████████████████▍                          | 23/60 [00:03<00:05,  6.49it/s]\u001b[A\r\n",
      " 40%|█████████████████▏                         | 24/60 [00:04<00:10,  3.48it/s]\u001b[A\r\n",
      " 42%|█████████████████▉                         | 25/60 [00:04<00:08,  3.98it/s]\u001b[A\r\n",
      " 43%|██████████████████▋                        | 26/60 [00:04<00:07,  4.59it/s]\u001b[A\r\n",
      " 45%|███████████████████▎                       | 27/60 [00:04<00:08,  3.98it/s]\u001b[A\r\n",
      " 47%|████████████████████                       | 28/60 [00:04<00:07,  4.35it/s]\u001b[A\r\n",
      " 48%|████████████████████▊                      | 29/60 [00:05<00:06,  4.96it/s]\u001b[A\r\n",
      " 50%|█████████████████████▌                     | 30/60 [00:05<00:05,  5.83it/s]\u001b[A\r\n",
      " 52%|██████████████████████▏                    | 31/60 [00:05<00:04,  6.58it/s]\u001b[A\r\n",
      " 53%|██████████████████████▉                    | 32/60 [00:05<00:04,  6.60it/s]\u001b[A\r\n",
      " 55%|███████████████████████▋                   | 33/60 [00:05<00:04,  6.14it/s]\u001b[A\r\n",
      " 57%|████████████████████████▎                  | 34/60 [00:05<00:04,  6.35it/s]\u001b[A\r\n",
      " 58%|█████████████████████████                  | 35/60 [00:05<00:03,  6.42it/s]\u001b[A\r\n",
      " 60%|█████████████████████████▊                 | 36/60 [00:06<00:03,  6.64it/s]\u001b[A\r\n",
      " 62%|██████████████████████████▌                | 37/60 [00:06<00:03,  7.19it/s]\u001b[A\r\n",
      " 63%|███████████████████████████▏               | 38/60 [00:06<00:02,  7.41it/s]\u001b[A\r\n",
      " 65%|███████████████████████████▉               | 39/60 [00:06<00:02,  7.27it/s]\u001b[A\r\n",
      " 67%|████████████████████████████▋              | 40/60 [00:06<00:02,  6.82it/s]\u001b[A\r\n",
      " 68%|█████████████████████████████▍             | 41/60 [00:06<00:02,  6.35it/s]\u001b[A\r\n",
      " 70%|██████████████████████████████             | 42/60 [00:06<00:02,  6.36it/s]\u001b[A\r\n",
      " 72%|██████████████████████████████▊            | 43/60 [00:07<00:02,  6.23it/s]\u001b[A\r\n",
      " 73%|███████████████████████████████▌           | 44/60 [00:07<00:02,  6.29it/s]\u001b[A\r\n",
      " 75%|████████████████████████████████▎          | 45/60 [00:07<00:02,  5.80it/s]\u001b[A\r\n",
      " 77%|████████████████████████████████▉          | 46/60 [00:07<00:02,  6.20it/s]\u001b[A\r\n",
      " 78%|█████████████████████████████████▋         | 47/60 [00:07<00:01,  6.74it/s]\u001b[A\r\n",
      " 80%|██████████████████████████████████▍        | 48/60 [00:07<00:01,  6.90it/s]\u001b[A\r\n",
      " 82%|███████████████████████████████████        | 49/60 [00:08<00:01,  7.34it/s]\u001b[A\r\n",
      " 83%|███████████████████████████████████▊       | 50/60 [00:08<00:01,  6.81it/s]\u001b[A\r\n",
      " 85%|████████████████████████████████████▌      | 51/60 [00:08<00:01,  6.67it/s]\u001b[A\r\n",
      " 87%|█████████████████████████████████████▎     | 52/60 [00:08<00:01,  6.31it/s]\u001b[A\r\n",
      " 88%|█████████████████████████████████████▉     | 53/60 [00:08<00:01,  6.57it/s]\u001b[A\r\n",
      " 90%|██████████████████████████████████████▋    | 54/60 [00:08<00:00,  6.14it/s]\u001b[A\r\n",
      " 92%|███████████████████████████████████████▍   | 55/60 [00:09<00:00,  6.23it/s]\u001b[A\r\n",
      " 93%|████████████████████████████████████████▏  | 56/60 [00:09<00:00,  6.43it/s]\u001b[A\r\n",
      " 95%|████████████████████████████████████████▊  | 57/60 [00:09<00:00,  6.69it/s]\u001b[A\r\n",
      " 97%|█████████████████████████████████████████▌ | 58/60 [00:09<00:00,  6.28it/s]\u001b[A\r\n",
      " 98%|██████████████████████████████████████████▎| 59/60 [00:09<00:00,  6.06it/s]\u001b[A\r\n",
      "\r\n",
      "\u001b[A{'eval_loss': 0.7291681170463562, 'eval_runtime': 10.0102, 'eval_samples_per_second': 5.994, 'eval_steps_per_second': 5.994, 'epoch': 2.95}\r\n",
      " 98%|████████████████████████████████████▎| 1400/1425 [1:56:40<02:01,  4.85s/it]\r\n",
      "100%|███████████████████████████████████████████| 60/60 [00:09<00:00,  6.50it/s]\u001b[A\r\n",
      "                                                                                \u001b[A[INFO|trainer.py:4309] 2026-01-02 20:35:24,977 >> Saving model checkpoint to /kaggle/working/models/qwen2vl-7b-vqa-grounded/checkpoint-1400\r\n",
      "[INFO|configuration_utils.py:765] 2026-01-02 20:35:25,099 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2-VL-7B-Instruct/snapshots/eed13092ef92e448dd6875b2a00151bd3f7db0ac/config.json\r\n",
      "[INFO|configuration_utils.py:839] 2026-01-02 20:35:25,101 >> Model config Qwen2VLConfig {\r\n",
      "  \"architectures\": [\r\n",
      "    \"Qwen2VLForConditionalGeneration\"\r\n",
      "  ],\r\n",
      "  \"attention_dropout\": 0.0,\r\n",
      "  \"bos_token_id\": 151643,\r\n",
      "  \"dtype\": \"bfloat16\",\r\n",
      "  \"eos_token_id\": 151645,\r\n",
      "  \"hidden_act\": \"silu\",\r\n",
      "  \"hidden_size\": 3584,\r\n",
      "  \"image_token_id\": 151655,\r\n",
      "  \"initializer_range\": 0.02,\r\n",
      "  \"intermediate_size\": 18944,\r\n",
      "  \"max_position_embeddings\": 32768,\r\n",
      "  \"max_window_layers\": 28,\r\n",
      "  \"model_type\": \"qwen2_vl\",\r\n",
      "  \"num_attention_heads\": 28,\r\n",
      "  \"num_hidden_layers\": 28,\r\n",
      "  \"num_key_value_heads\": 4,\r\n",
      "  \"rms_norm_eps\": 1e-06,\r\n",
      "  \"rope_scaling\": {\r\n",
      "    \"mrope_section\": [\r\n",
      "      16,\r\n",
      "      24,\r\n",
      "      24\r\n",
      "    ],\r\n",
      "    \"rope_type\": \"default\",\r\n",
      "    \"type\": \"default\"\r\n",
      "  },\r\n",
      "  \"rope_theta\": 1000000.0,\r\n",
      "  \"sliding_window\": 32768,\r\n",
      "  \"text_config\": {\r\n",
      "    \"architectures\": [\r\n",
      "      \"Qwen2VLForConditionalGeneration\"\r\n",
      "    ],\r\n",
      "    \"attention_dropout\": 0.0,\r\n",
      "    \"bos_token_id\": 151643,\r\n",
      "    \"dtype\": \"bfloat16\",\r\n",
      "    \"eos_token_id\": 151645,\r\n",
      "    \"hidden_act\": \"silu\",\r\n",
      "    \"hidden_size\": 3584,\r\n",
      "    \"initializer_range\": 0.02,\r\n",
      "    \"intermediate_size\": 18944,\r\n",
      "    \"layer_types\": [\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\"\r\n",
      "    ],\r\n",
      "    \"max_position_embeddings\": 32768,\r\n",
      "    \"max_window_layers\": 28,\r\n",
      "    \"model_type\": \"qwen2_vl_text\",\r\n",
      "    \"num_attention_heads\": 28,\r\n",
      "    \"num_hidden_layers\": 28,\r\n",
      "    \"num_key_value_heads\": 4,\r\n",
      "    \"rms_norm_eps\": 1e-06,\r\n",
      "    \"rope_scaling\": {\r\n",
      "      \"mrope_section\": [\r\n",
      "        16,\r\n",
      "        24,\r\n",
      "        24\r\n",
      "      ],\r\n",
      "      \"rope_type\": \"default\",\r\n",
      "      \"type\": \"default\"\r\n",
      "    },\r\n",
      "    \"rope_theta\": 1000000.0,\r\n",
      "    \"sliding_window\": null,\r\n",
      "    \"use_cache\": true,\r\n",
      "    \"use_sliding_window\": false,\r\n",
      "    \"vision_token_id\": 151654,\r\n",
      "    \"vocab_size\": 152064\r\n",
      "  },\r\n",
      "  \"tie_word_embeddings\": false,\r\n",
      "  \"transformers_version\": \"4.57.1\",\r\n",
      "  \"use_cache\": true,\r\n",
      "  \"use_sliding_window\": false,\r\n",
      "  \"video_token_id\": 151656,\r\n",
      "  \"vision_config\": {\r\n",
      "    \"depth\": 32,\r\n",
      "    \"embed_dim\": 1280,\r\n",
      "    \"hidden_act\": \"quick_gelu\",\r\n",
      "    \"hidden_size\": 3584,\r\n",
      "    \"in_channels\": 3,\r\n",
      "    \"in_chans\": 3,\r\n",
      "    \"initializer_range\": 0.02,\r\n",
      "    \"mlp_ratio\": 4,\r\n",
      "    \"model_type\": \"qwen2_vl\",\r\n",
      "    \"num_heads\": 16,\r\n",
      "    \"patch_size\": 14,\r\n",
      "    \"spatial_merge_size\": 2,\r\n",
      "    \"spatial_patch_size\": 14,\r\n",
      "    \"temporal_patch_size\": 2\r\n",
      "  },\r\n",
      "  \"vision_end_token_id\": 151653,\r\n",
      "  \"vision_start_token_id\": 151652,\r\n",
      "  \"vision_token_id\": 151654,\r\n",
      "  \"vocab_size\": 152064\r\n",
      "}\r\n",
      "\r\n",
      "[INFO|tokenization_utils_base.py:2421] 2026-01-02 20:35:25,764 >> chat template saved in /kaggle/working/models/qwen2vl-7b-vqa-grounded/checkpoint-1400/chat_template.jinja\r\n",
      "[INFO|tokenization_utils_base.py:2590] 2026-01-02 20:35:25,764 >> tokenizer config file saved in /kaggle/working/models/qwen2vl-7b-vqa-grounded/checkpoint-1400/tokenizer_config.json\r\n",
      "[INFO|tokenization_utils_base.py:2599] 2026-01-02 20:35:25,764 >> Special tokens file saved in /kaggle/working/models/qwen2vl-7b-vqa-grounded/checkpoint-1400/special_tokens_map.json\r\n",
      "[INFO|trainer.py:4418] 2026-01-02 20:35:26,895 >> Deleting older checkpoint [/kaggle/working/models/qwen2vl-7b-vqa-grounded/checkpoint-1200] due to args.save_total_limit\r\n",
      "[INFO|image_processing_base.py:253] 2026-01-02 20:35:27,055 >> Image processor saved in /kaggle/working/models/qwen2vl-7b-vqa-grounded/checkpoint-1400/preprocessor_config.json\r\n",
      "[INFO|tokenization_utils_base.py:2421] 2026-01-02 20:35:27,055 >> chat template saved in /kaggle/working/models/qwen2vl-7b-vqa-grounded/checkpoint-1400/chat_template.jinja\r\n",
      "[INFO|tokenization_utils_base.py:2590] 2026-01-02 20:35:27,055 >> tokenizer config file saved in /kaggle/working/models/qwen2vl-7b-vqa-grounded/checkpoint-1400/tokenizer_config.json\r\n",
      "[INFO|tokenization_utils_base.py:2599] 2026-01-02 20:35:27,055 >> Special tokens file saved in /kaggle/working/models/qwen2vl-7b-vqa-grounded/checkpoint-1400/special_tokens_map.json\r\n",
      "[INFO|video_processing_utils.py:600] 2026-01-02 20:35:27,184 >> Video processor saved in /kaggle/working/models/qwen2vl-7b-vqa-grounded/checkpoint-1400/video_preprocessor_config.json\r\n",
      "[INFO|processing_utils.py:814] 2026-01-02 20:35:27,184 >> chat template saved in /kaggle/working/models/qwen2vl-7b-vqa-grounded/checkpoint-1400/chat_template.jinja\r\n",
      " 98%|████████████████████████████████████▍| 1401/1425 [1:56:48<03:28,  8.69s/it]/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\r\n",
      "  warnings.warn(\r\n",
      "{'loss': 0.5027, 'grad_norm': 1.573544979095459, 'learning_rate': 1.9214011010790233e-08, 'epoch': 2.97}\r\n",
      "{'loss': 0.4906, 'grad_norm': 1.6668771505355835, 'learning_rate': 2.702267790846702e-09, 'epoch': 2.99}\r\n",
      "100%|█████████████████████████████████████| 1425/1425 [1:58:44<00:00,  4.68s/it][INFO|trainer.py:4309] 2026-01-02 20:37:29,021 >> Saving model checkpoint to /kaggle/working/models/qwen2vl-7b-vqa-grounded/checkpoint-1425\r\n",
      "[INFO|configuration_utils.py:765] 2026-01-02 20:37:29,081 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2-VL-7B-Instruct/snapshots/eed13092ef92e448dd6875b2a00151bd3f7db0ac/config.json\r\n",
      "[INFO|configuration_utils.py:839] 2026-01-02 20:37:29,083 >> Model config Qwen2VLConfig {\r\n",
      "  \"architectures\": [\r\n",
      "    \"Qwen2VLForConditionalGeneration\"\r\n",
      "  ],\r\n",
      "  \"attention_dropout\": 0.0,\r\n",
      "  \"bos_token_id\": 151643,\r\n",
      "  \"dtype\": \"bfloat16\",\r\n",
      "  \"eos_token_id\": 151645,\r\n",
      "  \"hidden_act\": \"silu\",\r\n",
      "  \"hidden_size\": 3584,\r\n",
      "  \"image_token_id\": 151655,\r\n",
      "  \"initializer_range\": 0.02,\r\n",
      "  \"intermediate_size\": 18944,\r\n",
      "  \"max_position_embeddings\": 32768,\r\n",
      "  \"max_window_layers\": 28,\r\n",
      "  \"model_type\": \"qwen2_vl\",\r\n",
      "  \"num_attention_heads\": 28,\r\n",
      "  \"num_hidden_layers\": 28,\r\n",
      "  \"num_key_value_heads\": 4,\r\n",
      "  \"rms_norm_eps\": 1e-06,\r\n",
      "  \"rope_scaling\": {\r\n",
      "    \"mrope_section\": [\r\n",
      "      16,\r\n",
      "      24,\r\n",
      "      24\r\n",
      "    ],\r\n",
      "    \"rope_type\": \"default\",\r\n",
      "    \"type\": \"default\"\r\n",
      "  },\r\n",
      "  \"rope_theta\": 1000000.0,\r\n",
      "  \"sliding_window\": 32768,\r\n",
      "  \"text_config\": {\r\n",
      "    \"architectures\": [\r\n",
      "      \"Qwen2VLForConditionalGeneration\"\r\n",
      "    ],\r\n",
      "    \"attention_dropout\": 0.0,\r\n",
      "    \"bos_token_id\": 151643,\r\n",
      "    \"dtype\": \"bfloat16\",\r\n",
      "    \"eos_token_id\": 151645,\r\n",
      "    \"hidden_act\": \"silu\",\r\n",
      "    \"hidden_size\": 3584,\r\n",
      "    \"initializer_range\": 0.02,\r\n",
      "    \"intermediate_size\": 18944,\r\n",
      "    \"layer_types\": [\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\"\r\n",
      "    ],\r\n",
      "    \"max_position_embeddings\": 32768,\r\n",
      "    \"max_window_layers\": 28,\r\n",
      "    \"model_type\": \"qwen2_vl_text\",\r\n",
      "    \"num_attention_heads\": 28,\r\n",
      "    \"num_hidden_layers\": 28,\r\n",
      "    \"num_key_value_heads\": 4,\r\n",
      "    \"rms_norm_eps\": 1e-06,\r\n",
      "    \"rope_scaling\": {\r\n",
      "      \"mrope_section\": [\r\n",
      "        16,\r\n",
      "        24,\r\n",
      "        24\r\n",
      "      ],\r\n",
      "      \"rope_type\": \"default\",\r\n",
      "      \"type\": \"default\"\r\n",
      "    },\r\n",
      "    \"rope_theta\": 1000000.0,\r\n",
      "    \"sliding_window\": null,\r\n",
      "    \"use_cache\": true,\r\n",
      "    \"use_sliding_window\": false,\r\n",
      "    \"vision_token_id\": 151654,\r\n",
      "    \"vocab_size\": 152064\r\n",
      "  },\r\n",
      "  \"tie_word_embeddings\": false,\r\n",
      "  \"transformers_version\": \"4.57.1\",\r\n",
      "  \"use_cache\": true,\r\n",
      "  \"use_sliding_window\": false,\r\n",
      "  \"video_token_id\": 151656,\r\n",
      "  \"vision_config\": {\r\n",
      "    \"depth\": 32,\r\n",
      "    \"embed_dim\": 1280,\r\n",
      "    \"hidden_act\": \"quick_gelu\",\r\n",
      "    \"hidden_size\": 3584,\r\n",
      "    \"in_channels\": 3,\r\n",
      "    \"in_chans\": 3,\r\n",
      "    \"initializer_range\": 0.02,\r\n",
      "    \"mlp_ratio\": 4,\r\n",
      "    \"model_type\": \"qwen2_vl\",\r\n",
      "    \"num_heads\": 16,\r\n",
      "    \"patch_size\": 14,\r\n",
      "    \"spatial_merge_size\": 2,\r\n",
      "    \"spatial_patch_size\": 14,\r\n",
      "    \"temporal_patch_size\": 2\r\n",
      "  },\r\n",
      "  \"vision_end_token_id\": 151653,\r\n",
      "  \"vision_start_token_id\": 151652,\r\n",
      "  \"vision_token_id\": 151654,\r\n",
      "  \"vocab_size\": 152064\r\n",
      "}\r\n",
      "\r\n",
      "[INFO|tokenization_utils_base.py:2421] 2026-01-02 20:37:29,720 >> chat template saved in /kaggle/working/models/qwen2vl-7b-vqa-grounded/checkpoint-1425/chat_template.jinja\r\n",
      "[INFO|tokenization_utils_base.py:2590] 2026-01-02 20:37:29,720 >> tokenizer config file saved in /kaggle/working/models/qwen2vl-7b-vqa-grounded/checkpoint-1425/tokenizer_config.json\r\n",
      "[INFO|tokenization_utils_base.py:2599] 2026-01-02 20:37:29,720 >> Special tokens file saved in /kaggle/working/models/qwen2vl-7b-vqa-grounded/checkpoint-1425/special_tokens_map.json\r\n",
      "[INFO|trainer.py:4418] 2026-01-02 20:37:30,862 >> Deleting older checkpoint [/kaggle/working/models/qwen2vl-7b-vqa-grounded/checkpoint-1300] due to args.save_total_limit\r\n",
      "[INFO|image_processing_base.py:253] 2026-01-02 20:37:31,023 >> Image processor saved in /kaggle/working/models/qwen2vl-7b-vqa-grounded/checkpoint-1425/preprocessor_config.json\r\n",
      "[INFO|tokenization_utils_base.py:2421] 2026-01-02 20:37:31,024 >> chat template saved in /kaggle/working/models/qwen2vl-7b-vqa-grounded/checkpoint-1425/chat_template.jinja\r\n",
      "[INFO|tokenization_utils_base.py:2590] 2026-01-02 20:37:31,024 >> tokenizer config file saved in /kaggle/working/models/qwen2vl-7b-vqa-grounded/checkpoint-1425/tokenizer_config.json\r\n",
      "[INFO|tokenization_utils_base.py:2599] 2026-01-02 20:37:31,024 >> Special tokens file saved in /kaggle/working/models/qwen2vl-7b-vqa-grounded/checkpoint-1425/special_tokens_map.json\r\n",
      "[INFO|video_processing_utils.py:600] 2026-01-02 20:37:31,155 >> Video processor saved in /kaggle/working/models/qwen2vl-7b-vqa-grounded/checkpoint-1425/video_preprocessor_config.json\r\n",
      "[INFO|processing_utils.py:814] 2026-01-02 20:37:31,156 >> chat template saved in /kaggle/working/models/qwen2vl-7b-vqa-grounded/checkpoint-1425/chat_template.jinja\r\n",
      "[INFO|trainer.py:2810] 2026-01-02 20:37:31,478 >> \r\n",
      "\r\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\r\n",
      "\r\n",
      "\r\n",
      "[INFO|trainer.py:3033] 2026-01-02 20:37:31,478 >> Loading best model from /kaggle/working/models/qwen2vl-7b-vqa-grounded/checkpoint-900 (score: 0.7160892486572266).\r\n",
      "{'train_runtime': 7127.3635, 'train_samples_per_second': 3.198, 'train_steps_per_second': 0.2, 'train_loss': 0.697361976723922, 'epoch': 3.0}\r\n",
      "100%|█████████████████████████████████████| 1425/1425 [1:58:47<00:00,  5.00s/it]\r\n",
      "[INFO|image_processing_base.py:253] 2026-01-02 20:37:31,639 >> Image processor saved in /kaggle/working/models/qwen2vl-7b-vqa-grounded/preprocessor_config.json\r\n",
      "[INFO|tokenization_utils_base.py:2421] 2026-01-02 20:37:31,640 >> chat template saved in /kaggle/working/models/qwen2vl-7b-vqa-grounded/chat_template.jinja\r\n",
      "[INFO|tokenization_utils_base.py:2590] 2026-01-02 20:37:31,640 >> tokenizer config file saved in /kaggle/working/models/qwen2vl-7b-vqa-grounded/tokenizer_config.json\r\n",
      "[INFO|tokenization_utils_base.py:2599] 2026-01-02 20:37:31,640 >> Special tokens file saved in /kaggle/working/models/qwen2vl-7b-vqa-grounded/special_tokens_map.json\r\n",
      "[INFO|video_processing_utils.py:600] 2026-01-02 20:37:31,764 >> Video processor saved in /kaggle/working/models/qwen2vl-7b-vqa-grounded/video_preprocessor_config.json\r\n",
      "[INFO|processing_utils.py:814] 2026-01-02 20:37:31,764 >> chat template saved in /kaggle/working/models/qwen2vl-7b-vqa-grounded/chat_template.jinja\r\n",
      "[INFO|trainer.py:4309] 2026-01-02 20:37:32,085 >> Saving model checkpoint to /kaggle/working/models/qwen2vl-7b-vqa-grounded\r\n",
      "[INFO|configuration_utils.py:765] 2026-01-02 20:37:32,144 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2-VL-7B-Instruct/snapshots/eed13092ef92e448dd6875b2a00151bd3f7db0ac/config.json\r\n",
      "[INFO|configuration_utils.py:839] 2026-01-02 20:37:32,146 >> Model config Qwen2VLConfig {\r\n",
      "  \"architectures\": [\r\n",
      "    \"Qwen2VLForConditionalGeneration\"\r\n",
      "  ],\r\n",
      "  \"attention_dropout\": 0.0,\r\n",
      "  \"bos_token_id\": 151643,\r\n",
      "  \"dtype\": \"bfloat16\",\r\n",
      "  \"eos_token_id\": 151645,\r\n",
      "  \"hidden_act\": \"silu\",\r\n",
      "  \"hidden_size\": 3584,\r\n",
      "  \"image_token_id\": 151655,\r\n",
      "  \"initializer_range\": 0.02,\r\n",
      "  \"intermediate_size\": 18944,\r\n",
      "  \"max_position_embeddings\": 32768,\r\n",
      "  \"max_window_layers\": 28,\r\n",
      "  \"model_type\": \"qwen2_vl\",\r\n",
      "  \"num_attention_heads\": 28,\r\n",
      "  \"num_hidden_layers\": 28,\r\n",
      "  \"num_key_value_heads\": 4,\r\n",
      "  \"rms_norm_eps\": 1e-06,\r\n",
      "  \"rope_scaling\": {\r\n",
      "    \"mrope_section\": [\r\n",
      "      16,\r\n",
      "      24,\r\n",
      "      24\r\n",
      "    ],\r\n",
      "    \"rope_type\": \"default\",\r\n",
      "    \"type\": \"default\"\r\n",
      "  },\r\n",
      "  \"rope_theta\": 1000000.0,\r\n",
      "  \"sliding_window\": 32768,\r\n",
      "  \"text_config\": {\r\n",
      "    \"architectures\": [\r\n",
      "      \"Qwen2VLForConditionalGeneration\"\r\n",
      "    ],\r\n",
      "    \"attention_dropout\": 0.0,\r\n",
      "    \"bos_token_id\": 151643,\r\n",
      "    \"dtype\": \"bfloat16\",\r\n",
      "    \"eos_token_id\": 151645,\r\n",
      "    \"hidden_act\": \"silu\",\r\n",
      "    \"hidden_size\": 3584,\r\n",
      "    \"initializer_range\": 0.02,\r\n",
      "    \"intermediate_size\": 18944,\r\n",
      "    \"layer_types\": [\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\",\r\n",
      "      \"full_attention\"\r\n",
      "    ],\r\n",
      "    \"max_position_embeddings\": 32768,\r\n",
      "    \"max_window_layers\": 28,\r\n",
      "    \"model_type\": \"qwen2_vl_text\",\r\n",
      "    \"num_attention_heads\": 28,\r\n",
      "    \"num_hidden_layers\": 28,\r\n",
      "    \"num_key_value_heads\": 4,\r\n",
      "    \"rms_norm_eps\": 1e-06,\r\n",
      "    \"rope_scaling\": {\r\n",
      "      \"mrope_section\": [\r\n",
      "        16,\r\n",
      "        24,\r\n",
      "        24\r\n",
      "      ],\r\n",
      "      \"rope_type\": \"default\",\r\n",
      "      \"type\": \"default\"\r\n",
      "    },\r\n",
      "    \"rope_theta\": 1000000.0,\r\n",
      "    \"sliding_window\": null,\r\n",
      "    \"use_cache\": true,\r\n",
      "    \"use_sliding_window\": false,\r\n",
      "    \"vision_token_id\": 151654,\r\n",
      "    \"vocab_size\": 152064\r\n",
      "  },\r\n",
      "  \"tie_word_embeddings\": false,\r\n",
      "  \"transformers_version\": \"4.57.1\",\r\n",
      "  \"use_cache\": true,\r\n",
      "  \"use_sliding_window\": false,\r\n",
      "  \"video_token_id\": 151656,\r\n",
      "  \"vision_config\": {\r\n",
      "    \"depth\": 32,\r\n",
      "    \"embed_dim\": 1280,\r\n",
      "    \"hidden_act\": \"quick_gelu\",\r\n",
      "    \"hidden_size\": 3584,\r\n",
      "    \"in_channels\": 3,\r\n",
      "    \"in_chans\": 3,\r\n",
      "    \"initializer_range\": 0.02,\r\n",
      "    \"mlp_ratio\": 4,\r\n",
      "    \"model_type\": \"qwen2_vl\",\r\n",
      "    \"num_heads\": 16,\r\n",
      "    \"patch_size\": 14,\r\n",
      "    \"spatial_merge_size\": 2,\r\n",
      "    \"spatial_patch_size\": 14,\r\n",
      "    \"temporal_patch_size\": 2\r\n",
      "  },\r\n",
      "  \"vision_end_token_id\": 151653,\r\n",
      "  \"vision_start_token_id\": 151652,\r\n",
      "  \"vision_token_id\": 151654,\r\n",
      "  \"vocab_size\": 152064\r\n",
      "}\r\n",
      "\r\n",
      "[INFO|tokenization_utils_base.py:2421] 2026-01-02 20:37:32,802 >> chat template saved in /kaggle/working/models/qwen2vl-7b-vqa-grounded/chat_template.jinja\r\n",
      "[INFO|tokenization_utils_base.py:2590] 2026-01-02 20:37:32,802 >> tokenizer config file saved in /kaggle/working/models/qwen2vl-7b-vqa-grounded/tokenizer_config.json\r\n",
      "[INFO|tokenization_utils_base.py:2599] 2026-01-02 20:37:32,802 >> Special tokens file saved in /kaggle/working/models/qwen2vl-7b-vqa-grounded/special_tokens_map.json\r\n",
      "***** train metrics *****\r\n",
      "  epoch                    =          3.0\r\n",
      "  total_flos               = 1380630198GF\r\n",
      "  train_loss               =       0.6974\r\n",
      "  train_runtime            =   1:58:47.36\r\n",
      "  train_samples_per_second =        3.198\r\n",
      "  train_steps_per_second   =          0.2\r\n",
      "Figure saved at: /kaggle/working/models/qwen2vl-7b-vqa-grounded/training_loss.png\r\n",
      "Figure saved at: /kaggle/working/models/qwen2vl-7b-vqa-grounded/training_eval_loss.png\r\n",
      "[WARNING|2026-01-02 20:37:33] llamafactory.extras.ploting:148 >> No metric eval_accuracy to plot.\r\n",
      "[INFO|trainer.py:4643] 2026-01-02 20:37:33,087 >> \r\n",
      "***** Running Evaluation *****\r\n",
      "[INFO|trainer.py:4645] 2026-01-02 20:37:33,087 >>   Num examples = 60\r\n",
      "[INFO|trainer.py:4648] 2026-01-02 20:37:33,087 >>   Batch size = 1\r\n",
      "100%|███████████████████████████████████████████| 60/60 [00:09<00:00,  6.16it/s]\r\n",
      "***** eval metrics *****\r\n",
      "  epoch                   =        3.0\r\n",
      "  eval_loss               =     0.7161\r\n",
      "  eval_runtime            = 0:00:09.96\r\n",
      "  eval_samples_per_second =      6.022\r\n",
      "  eval_steps_per_second   =      6.022\r\n",
      "[INFO|modelcard.py:456] 2026-01-02 20:37:43,048 >> Dropping the following result as it does not have all the necessary fields:\r\n",
      "{'task': {'name': 'Causal Language Modeling', 'type': 'text-generation'}}\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# Start training\n",
    "print(\" Starting fine-tuning...\")\n",
    "print(f\"   Config: {CONFIG_PATH}\")\n",
    "print(f\"   Output: {OUTPUT_DIR}\")\n",
    "print()\n",
    "\n",
    "!llamafactory-cli train {CONFIG_PATH}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fc625324",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-02T20:37:46.439321Z",
     "iopub.status.busy": "2026-01-02T20:37:46.438888Z",
     "iopub.status.idle": "2026-01-02T20:37:46.591464Z",
     "shell.execute_reply": "2026-01-02T20:37:46.590968Z"
    },
    "papermill": {
     "duration": 0.22485,
     "end_time": "2026-01-02T20:37:46.592770",
     "exception": false,
     "start_time": "2026-01-02T20:37:46.367920",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output directory: /kaggle/working/models/qwen2vl-7b-vqa-grounded\n",
      "\n",
      "Contents:\n",
      "total 632M\r\n",
      "-rw-r--r-- 1 root root  938 Jan  2 20:37 adapter_config.json\r\n",
      "-rw-r--r-- 1 root root 617M Jan  2 20:37 adapter_model.safetensors\r\n",
      "-rw-r--r-- 1 root root  392 Jan  2 20:37 added_tokens.json\r\n",
      "-rw-r--r-- 1 root root  344 Jan  2 20:37 all_results.json\r\n",
      "-rw-r--r-- 1 root root 1017 Jan  2 20:37 chat_template.jinja\r\n",
      "drwxr-xr-x 2 root root 4.0K Jan  2 20:35 checkpoint-1400\r\n",
      "drwxr-xr-x 2 root root 4.0K Jan  2 20:37 checkpoint-1425\r\n",
      "drwxr-xr-x 2 root root 4.0K Jan  2 19:53 checkpoint-900\r\n",
      "-rw-r--r-- 1 root root  159 Jan  2 20:37 eval_results.json\r\n",
      "-rw-r--r-- 1 root root 1.6M Jan  2 20:37 merges.txt\r\n",
      "-rw-r--r-- 1 root root  826 Jan  2 20:37 preprocessor_config.json\r\n",
      "-rw-r--r-- 1 root root 2.3K Jan  2 20:37 README.md\r\n",
      "-rw-r--r-- 1 root root  613 Jan  2 20:37 special_tokens_map.json\r\n",
      "-rw-r--r-- 1 root root 3.3K Jan  2 20:37 tokenizer_config.json\r\n",
      "-rw-r--r-- 1 root root  11M Jan  2 20:37 tokenizer.json\r\n",
      "-rw-r--r-- 1 root root  30K Jan  2 20:37 trainer_log.jsonl\r\n",
      "-rw-r--r-- 1 root root  28K Jan  2 20:37 trainer_state.json\r\n",
      "-rw-r--r-- 1 root root 6.1K Jan  2 20:37 training_args.bin\r\n",
      "-rw-r--r-- 1 root root  37K Jan  2 20:37 training_eval_loss.png\r\n",
      "-rw-r--r-- 1 root root  41K Jan  2 20:37 training_loss.png\r\n",
      "-rw-r--r-- 1 root root  205 Jan  2 20:37 train_results.json\r\n",
      "-rw-r--r-- 1 root root  910 Jan  2 20:37 video_preprocessor_config.json\r\n",
      "-rw-r--r-- 1 root root 2.7M Jan  2 20:37 vocab.json\r\n"
     ]
    }
   ],
   "source": [
    "# Check output directory\n",
    "output_dir = BASE_DIR / \"models\" / \"qwen2vl-7b-vqa-grounded\"\n",
    "\n",
    "if output_dir.exists():\n",
    "    print(f\"Output directory: {output_dir}\")\n",
    "    print(\"\\nContents:\")\n",
    "    !ls -lh {output_dir}\n",
    "else:\n",
    "    print(f\"Training not started yet. Output will be at: {output_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3655c0a2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-02T20:37:46.794000Z",
     "iopub.status.busy": "2026-01-02T20:37:46.793572Z",
     "iopub.status.idle": "2026-01-02T20:37:47.166015Z",
     "shell.execute_reply": "2026-01-02T20:37:47.165632Z"
    },
    "papermill": {
     "duration": 0.502673,
     "end_time": "2026-01-02T20:37:47.167194",
     "exception": false,
     "start_time": "2026-01-02T20:37:46.664521",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Latest loss: nan\n",
      "Steps completed: 1425\n"
     ]
    }
   ],
   "source": [
    "# Plot training loss if available\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "trainer_log = output_dir / \"trainer_log.jsonl\"\n",
    "\n",
    "if trainer_log.exists():\n",
    "    logs = []\n",
    "    with open(trainer_log, 'r') as f:\n",
    "        for line in f:\n",
    "            logs.append(json.loads(line))\n",
    "    \n",
    "    df = pd.DataFrame(logs)\n",
    "    \n",
    "    if 'loss' in df.columns:\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.plot(df['current_steps'], df['loss'], label='Training Loss')\n",
    "        plt.xlabel('Steps')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.title('Training Progress')\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.show()\n",
    "        \n",
    "        print(f\"\\nLatest loss: {df['loss'].iloc[-1]:.4f}\")\n",
    "        print(f\"Steps completed: {df['current_steps'].iloc[-1]}\")\n",
    "    else:\n",
    "        print(\"No loss data yet\")\n",
    "else:\n",
    "    print(\"No training log found yet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "323b5679",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-02T20:37:47.312645Z",
     "iopub.status.busy": "2026-01-02T20:37:47.312247Z",
     "iopub.status.idle": "2026-01-02T20:37:47.316063Z",
     "shell.execute_reply": "2026-01-02T20:37:47.315670Z"
    },
    "papermill": {
     "duration": 0.077148,
     "end_time": "2026-01-02T20:37:47.316942",
     "exception": false,
     "start_time": "2026-01-02T20:37:47.239794",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Created export config: /kaggle/working/config/export_model.yaml\n"
     ]
    }
   ],
   "source": [
    "# Export config with dynamic paths\n",
    "export_config = f\"\"\"### Model\n",
    "model_name_or_path: Qwen/Qwen2-VL-7B-Instruct\n",
    "adapter_name_or_path: {BASE_DIR / 'models' / 'qwen2vl-7b-vqa-grounded'}\n",
    "template: qwen2_vl\n",
    "finetuning_type: lora\n",
    "trust_remote_code: true\n",
    "\n",
    "### Export\n",
    "export_dir: {BASE_DIR / 'models' / 'qwen2vl-7b-vqa-grounded-merged'}\n",
    "export_size: 2\n",
    "export_device: cpu\n",
    "export_legacy_format: false\n",
    "\"\"\"\n",
    "\n",
    "EXPORT_CONFIG_PATH = BASE_DIR / \"config\" / \"export_model.yaml\"\n",
    "with open(EXPORT_CONFIG_PATH, 'w') as f:\n",
    "    f.write(export_config)\n",
    "\n",
    "print(f\" Created export config: {EXPORT_CONFIG_PATH}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaH100",
   "dataSources": [
    {
     "databundleVersionId": 14559231,
     "sourceId": 118448,
     "sourceType": "competition"
    },
    {
     "datasetId": 8972384,
     "sourceId": 14090910,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 9177038,
     "sourceId": 14370802,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 9180143,
     "sourceId": 14374890,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31236,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 7404.566739,
   "end_time": "2026-01-02T20:37:47.905252",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2026-01-02T18:34:23.338513",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
